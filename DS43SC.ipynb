{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS43SC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrittonWinterrose/DS-Unit-4-Sprint-3-Neural-Networks/blob/master/DS43SC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Y6SKlgYrpcym",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Networks Sprint Challenge"
      ]
    },
    {
      "metadata": {
        "id": "BrEbRrjVphPM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1) Define the following terms:\n",
        "\n",
        "- Neuron\n",
        "- Input Layer\n",
        "- Hidden Layer\n",
        "- Output Layer\n",
        "- Activation\n",
        "- Backpropagation"
      ]
    },
    {
      "metadata": {
        "id": "Q5EksLqnp4oB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Neuron: A Neuron is a brain / nerve cell that serves as a logic gate in our Brain. An Artificial Neuron is a mathematical function model of the cell. It calculates some equations on the input and decides to return a 1 or 0. In similar fashion a brain neuron receives multiple stimuli and then triggers the sending of a signal when appropriate (and sometimes when not appropriate).\n",
        "\n",
        "* Input layer: The input layer is the input variables, sometimes called the \"visable layer\".\n",
        "\n",
        "* Hidden Layer: The one or more processing layers of varying sizes and configurations that make up the MLP or deep learning model. Hidden layers are required if and only if the data must be separated non-linearly. By adding additional layers we can handle increasingly complex data relationships .\n",
        "\n",
        "* Output Layer: The collection of output nodes that are responsible for computations and transferring information from the network to the outside world. These evaluate the combinations from the weights and hidden layer outputs and assign a final score. \n",
        "\n",
        "* Activation: Activation functions are used to determine how an input signal is pushed forward by a node. It does this by applying the activation function which maps the input value against an established thresholding function that constrains the output within the desired range (usually 0, 1 or -1, 1). By doing so each node can then produce a constrained output.\n",
        "\n",
        "* Backpropagation:  In backpropagation we take the error (the \"cost\" that we compute by comparing the calculated output and the known, correct target output) and we then use it to update the model parameters. We calculate the total error at the output nodes and propagate these errors back through the network in each layer. This causes our network to perform better when calculating gradients than before since the weights have now been adjusted to minimize the error in prediction."
      ]
    },
    {
      "metadata": {
        "id": "Ri_gRA2Jp728",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2) Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 1  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 1  | 0 |"
      ]
    },
    {
      "metadata": {
        "id": "Ig6ZTH8tpQ19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "60ba6c08-87d7-44b8-be18-5ec2bc2364bb"
      },
      "cell_type": "code",
      "source": [
        "# Start by creating weights and bias\n",
        "weight1 = 0.3334\n",
        "weight2 = 0.3334\n",
        "weight3 = 0.3334\n",
        "bias = -1\n",
        "\n",
        "\n",
        "# Add inputs and outputs\n",
        "test_inputs = [(1, 1, 1), (1, 0, 1), (0, 1, 1), (0, 0, 1), (1, 1, 0), (1, 0, 0), (0,0,0)]\n",
        "correct_outputs = [True, False, False, False]\n",
        "outputs = []\n",
        "\n",
        "# Generate and check output\n",
        "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
        "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + weight3 * test_input[2] + bias\n",
        "    output = int(linear_combination >= 0)\n",
        "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
        "    outputs.append([test_input[0], test_input[1],  test_input[2], linear_combination, output, is_correct_string])\n",
        "\n",
        "# Print output\n",
        "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', 'Input 3','  Linear Combination', '  Activation Output', '  Is Correct'])\n",
        "print(output_frame.to_string(index=False))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input 1    Input 2  Input 3    Linear Combination    Activation Output   Is Correct\n",
            "      1          1        1                0.0002                    1          Yes\n",
            "      1          0        1               -0.3332                    0          Yes\n",
            "      0          1        1               -0.3332                    0          Yes\n",
            "      0          0        1               -0.6666                    0          Yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "86HyRi8Osr3U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3) Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. \n",
        "- Your network must have one hidden layer. \n",
        "- You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
        "- Train your model on the Heart Disease dataset from UCI:\n",
        "\n",
        "[Github Dataset](https://github.com/ryanleeallred/datasets/blob/master/heart.csv)\n",
        "\n",
        "[Raw File on Github](https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv)\n"
      ]
    },
    {
      "metadata": {
        "id": "CNfiajv3v4Ed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "6c3b2e4d-65a7-4077-8cfe-82b2b5ef0265"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = \"https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv\"\n",
        "\n",
        "df = pd.read_csv(data, header=0)\n",
        "display(df.shape)\n",
        "df = df.dropna(axis=0, how='any')\n",
        "display(df.shape)\n",
        "display(df.head(5))\n",
        "display(df.target.value_counts())\n",
        "\n",
        "display(\"Now we preprocess the data.\")\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "y = df.target.copy()\n",
        "X = df.drop(columns = \"target\")\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "display(X.shape)\n",
        "display(y.shape)\n",
        "\n",
        "seed = 42\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(303, 14)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(303, 14)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1    165\n",
              "0    138\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Now we preprocess the data.'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(303, 13)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cjBbnvecRw05",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNetMLP(object):\n",
        "    \"\"\"\n",
        "    Feed forward nueral network / multi-layer perceptron classifier\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_hidden : int (default: 30)\n",
        "        Number of hidden units\n",
        "    l2 : float (default 0.)\n",
        "        Lambda value for l2 normalization\n",
        "    epochs : int (default: 100)\n",
        "        Number of training epochs\n",
        "    eta : float (default = 0.001)\n",
        "        Learning rate\n",
        "    shuffle : bool (default: True)\n",
        "        Shuffles the training data every epoch if True\n",
        "    minibatch_size : int (default : 1)\n",
        "        Number of training samples per minibatch\n",
        "    seed : int (default: None)\n",
        "        Random seed for initalizing weights and shuffling\n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    eval_ : dict\n",
        "        Dictionary collecting the cost, training accuracy,\n",
        "        and validation accuracy for each epoch during training\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_hidden=30, l2=0.,\n",
        "                epochs=100, eta=0.001,\n",
        "                shuffle=True, minibatch_size=1, seed=None):\n",
        "        self.random = np.random.RandomState(seed)\n",
        "        self.n_hidden = n_hidden\n",
        "        self.l2 = l2\n",
        "        self.epochs = epochs\n",
        "        self.eta = eta\n",
        "        self.shuffle = shuffle\n",
        "        self.minibatch_size = minibatch_size\n",
        "        \n",
        "    def _onehot(self, y, n_classes):\n",
        "        \"\"\"\n",
        "        Encode labels into one hot representation\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        y : array, shape = [n_samples]\n",
        "            Target values\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        onehot : array, shape = (n_samples, n_labels)\n",
        "        \"\"\"\n",
        "        \n",
        "        onehot = np.zeros((n_classes, y.shape[0]))\n",
        "        for idx, val in enumerate(y.astype(int)):\n",
        "            onehot[val, idx] = 1.\n",
        "        return onehot.T\n",
        "    \n",
        "    def _sigmoid(self, z):\n",
        "        \"\"\"\n",
        "        Compute logistic function (sigmoid)\n",
        "        \"\"\"\n",
        "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
        "    \n",
        "    def _forward(self, X):\n",
        "        \"\"\"\n",
        "        Compute forward propogation step\n",
        "        \"\"\"\n",
        "        # step 1: net input of hidden layer\n",
        "        z_h = np.dot(X, self.w_h) + self.b_h\n",
        "        \n",
        "        # step 2: activation of hidden layer\n",
        "        a_h = self._sigmoid(z_h)\n",
        "        \n",
        "        # step 3: net input of output layer\n",
        "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
        "        \n",
        "        # step 4: activation layer output\n",
        "        a_out = self._sigmoid(z_out)\n",
        "        \n",
        "        return z_h, a_h, z_out, a_out\n",
        "    \n",
        "    def _compute_cost(self, y_enc, output):\n",
        "        \"\"\"\n",
        "        Compute cost function\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        y_enc : array, shape = (n_samples, n_labels)\n",
        "            one-hot encoded class labels\n",
        "        output : array, shape = [n_samples, n_output_units]\n",
        "            Activation of the output layer (forward propoagation)\n",
        "        Returns\n",
        "        -------\n",
        "        cost : float\n",
        "            Regularized cost\n",
        "        \"\"\"\n",
        "        e = 0.000000001\n",
        "        L2_term = (self.l2 *\n",
        "                  (np.sum(self.w_h ** 2.) + \n",
        "                  np.sum(self.w_out ** 2.)))\n",
        "        term1 = -y_enc * (np.log(output + e))\n",
        "        term2 = (1. - y_enc) * np.log(1. - output + e)\n",
        "        cost = np.sum(term1 - term2) + L2_term\n",
        "        return cost\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict class labels\n",
        "        \n",
        "        Paramters\n",
        "        ---------\n",
        "        X : array, shape = [n_samples, n_features]\n",
        "            Input layer with original features\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        y_pred : array, shape = [n_samples]\n",
        "            Predicted class labels\n",
        "        \"\"\"\n",
        "        z_h, a_h, z_out, a_out = self._forward(X)\n",
        "        y_pred = np.argmax(z_out, axis=1)\n",
        "        return y_pred\n",
        "    \n",
        "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
        "        \"\"\"\n",
        "        Learn weights from training data\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X_train : array, shape = [n_samples, n_features]\n",
        "            Input layer with original features\n",
        "        y_train : array, shape = [n_samples]\n",
        "            Target class labels\n",
        "        X_test : array, shape = [n_samples, n_features]\n",
        "            Sample features for validation during training\n",
        "        y_test : array, shape = [n_samples]\n",
        "            Samples test class labels for validation during training\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        self\n",
        "        \"\"\"\n",
        "        n_output = np.unique(y_train).shape[0]\n",
        "        n_features = X_train.shape[1]\n",
        "        \n",
        "        #######################\n",
        "        # Weight Initialization\n",
        "        #######################\n",
        "        \n",
        "        # weights for input -> hidden\n",
        "        self.b_h = np.zeros(self.n_hidden)\n",
        "        self.w_h = self.random.normal(loc=0.0,\n",
        "                                     scale=0.1,\n",
        "                                     size=(n_features,\n",
        "                                          self.n_hidden))\n",
        "        \n",
        "        # weights for hidden -> output\n",
        "        self.b_out = np.zeros(n_output)\n",
        "        self.w_out = self.random.normal(loc=0.0,\n",
        "                                       scale=0.1,\n",
        "                                       size=(self.n_hidden,\n",
        "                                       n_output))\n",
        "        \n",
        "        epoch_strlen = len(str(self.epochs)) # for progr. format\n",
        "        self.eval_ = {'cost' : [],\n",
        "                     'train_acc' : [],\n",
        "                     'valid_acc' : []}\n",
        "        \n",
        "        y_train_enc = self._onehot(y_train, n_output)\n",
        "        \n",
        "        # iterate over training epochs\n",
        "        for i in range(self.epochs):\n",
        "            \n",
        "            # iterate over mini batches\n",
        "            indices = np.arange(X_train.shape[0])\n",
        "            \n",
        "            if self.shuffle:\n",
        "                self.random.shuffle(indices)\n",
        "            \n",
        "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size):\n",
        "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
        "                \n",
        "                # forward propagation\n",
        "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
        "                \n",
        "                #################\n",
        "                # Backpropagation\n",
        "                #################\n",
        "                \n",
        "                # [n_samples, n_classlabels]\n",
        "                sigma_out = a_out - y_train_enc[batch_idx]\n",
        "                \n",
        "                # [n_samples, n_hidden]\n",
        "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
        "                \n",
        "                # [n_samples, n_classlabels] dot [n_classlabels, n_hidden]\n",
        "                # -> [n_samples, n_hidden]\n",
        "                sigma_h = (np.dot(sigma_out, self.w_out.T) * sigmoid_derivative_h)\n",
        "                \n",
        "                # [n_features, n_samples] dot [n_samples, n_hidden]\n",
        "                # -> [n_features, n_hidden]\n",
        "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
        "                grad_b_h = np.sum(sigma_h, axis=0)\n",
        "                \n",
        "                # [n_hidden, n_samples] dot [n_samples, n_classlabels]\n",
        "                # -> [n_hidden, n_classlabels]\n",
        "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
        "                grad_b_out = np.sum(sigma_out, axis=0)\n",
        "                \n",
        "                # Regularization and weight updates\n",
        "                delta_w_h = (grad_w_h + self.l2 * self.w_h)\n",
        "                delta_b_h = grad_b_h # bias is not regularized\n",
        "                self.w_h -= self.eta * delta_w_h\n",
        "                self.b_h -= self.eta * delta_b_h\n",
        "                \n",
        "                delta_w_out = grad_w_out + self.l2 * self.w_out\n",
        "                delta_b_out = grad_b_out # bias is not regularized\n",
        "                self.w_out -= self.eta * delta_w_out\n",
        "                self.b_out -= self.eta * delta_b_out\n",
        "                \n",
        "            ############\n",
        "            # Evaluation\n",
        "            ############\n",
        "\n",
        "            # evaluation after each epoch during training\n",
        "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
        "            \n",
        "            cost = self._compute_cost(y_enc=y_train_enc, output=a_out)\n",
        "            \n",
        "            y_train_pred = self.predict(X_train)\n",
        "            y_valid_pred = self.predict(X_valid)\n",
        "            \n",
        "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[0])\n",
        "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[0])\n",
        "            \n",
        "            sys.stderr.write('\\r%0*d/%d | Cost: %.2f | Train/Valid Acc: %.2f%%/%.2f%%'\n",
        "                            % (epoch_strlen, i+1, self.epochs, cost, train_acc*100, valid_acc*100))\n",
        "            sys.stderr.flush()\n",
        "            \n",
        "            self.eval_['cost'].append(cost)\n",
        "            self.eval_['train_acc'].append(train_acc)\n",
        "            self.eval_['valid_acc'].append(valid_acc)\n",
        "            \n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4DKfn83QYOHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "33643aaf-578d-461b-e990-36edf7f9a12b"
      },
      "cell_type": "code",
      "source": [
        "# Test Train Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = seed)\n",
        "print (X_test.shape, y_test.shape)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = .20, random_state = seed)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_valid.shape, y_valid.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(61, 13) (61,)\n",
            "(193, 13) (193,)\n",
            "(49, 13) (49,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "815E5qeQSnh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "e659d167-102c-43eb-8364-211c4f0b4258"
      },
      "cell_type": "code",
      "source": [
        "# Initialize a new MLP\n",
        "mlp = NeuralNetMLP(n_hidden= 52,\n",
        "                   l2= 0.01,\n",
        "                   epochs= 1500,\n",
        "                   eta= 0.0005,\n",
        "                   minibatch_size= 25,\n",
        "                   shuffle = True,\n",
        "                   seed = 42)\n",
        "\n",
        "# Run the MLP\n",
        "mlp.fit(X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(mlp.epochs), mlp.eval_['cost'])\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500/1500 | Cost: 133.07 | Train/Valid Acc: 87.05%/77.55%"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFYCAYAAACoFn5YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERC/v/wTqUiAs0XF0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WLm1Y7f5YB6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "daee75ac-8a8f-4706-9b0e-ba72fd7bf40e"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(range(mlp.epochs), mlp.eval_['train_acc'], label = \"Training\")\n",
        "plt.plot(range(mlp.epochs), mlp.eval_[\"valid_acc\"], label = \"Validation\", linestyle = '--')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni/j/cESJBg9XDR0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kllZ4THia75a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a3c4257-5021-4da9-8b71-ba0a373cf033"
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = mlp.predict(X_test)\n",
        "acc = (np.sum(y_test == y_test_pred).astype(np.float) / X_test.shape[0])\n",
        "print(\"Training accuracy: %.2f%%\" % (acc * 100))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 85.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGT1oRzXw3H9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4) Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy. \n",
        "\n",
        "- Use the Heart Disease Dataset (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network. \n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "- When hyperparameter tuning, show you work by adding code cells for each new experiment. \n",
        "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "- You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
      ]
    },
    {
      "metadata": {
        "id": "mwr-CVDHi27A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8ff2b53e-8e4a-49e1-be95-5c4ea51329e9"
      },
      "cell_type": "code",
      "source": [
        "# Test Train Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = seed)\n",
        "print (X_train.shape, y_train.shape)\n",
        "print (X_test.shape, y_test.shape)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(242, 13) (242,)\n",
            "(61, 13) (61,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XWw4IYxLxKwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13719
        },
        "outputId": "f71e9791-b439-4794-c43e-4eecae640b15"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def baseline(optimizer = \"adam\", init = \"uniform\", activation='relu'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(39, input_dim=X.shape[1], activation=activation))\n",
        "  model.add(Dense(39, activation=activation))\n",
        "  model.add(Dense(1, activation=activation))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=baseline, epochs=100, batch_size=5, verbose=1)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "193/193 [==============================] - 3s 15ms/step - loss: 1.7591 - acc: 0.4819\n",
            "Epoch 2/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.5998 - acc: 0.7098\n",
            "Epoch 3/80\n",
            "193/193 [==============================] - 0s 423us/step - loss: 0.5016 - acc: 0.7513\n",
            "Epoch 4/80\n",
            "193/193 [==============================] - 0s 373us/step - loss: 0.4528 - acc: 0.7617\n",
            "Epoch 5/80\n",
            "193/193 [==============================] - 0s 365us/step - loss: 0.4144 - acc: 0.7824\n",
            "Epoch 6/80\n",
            "193/193 [==============================] - 0s 381us/step - loss: 0.3879 - acc: 0.7927\n",
            "Epoch 7/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.3782 - acc: 0.8187\n",
            "Epoch 8/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.3611 - acc: 0.8031\n",
            "Epoch 9/80\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.3637 - acc: 0.8083\n",
            "Epoch 10/80\n",
            "193/193 [==============================] - 0s 387us/step - loss: 0.3420 - acc: 0.8342\n",
            "Epoch 11/80\n",
            "193/193 [==============================] - 0s 362us/step - loss: 0.3344 - acc: 0.8290\n",
            "Epoch 12/80\n",
            "193/193 [==============================] - 0s 386us/step - loss: 0.3257 - acc: 0.8290\n",
            "Epoch 13/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.3638 - acc: 0.8083\n",
            "Epoch 14/80\n",
            "193/193 [==============================] - 0s 393us/step - loss: 0.3384 - acc: 0.8187\n",
            "Epoch 15/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.3148 - acc: 0.8394\n",
            "Epoch 16/80\n",
            "193/193 [==============================] - 0s 368us/step - loss: 0.3175 - acc: 0.8342\n",
            "Epoch 17/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.2944 - acc: 0.8342\n",
            "Epoch 18/80\n",
            "193/193 [==============================] - 0s 399us/step - loss: 0.2926 - acc: 0.8394\n",
            "Epoch 19/80\n",
            "193/193 [==============================] - 0s 377us/step - loss: 0.2972 - acc: 0.8342\n",
            "Epoch 20/80\n",
            "193/193 [==============================] - 0s 385us/step - loss: 0.2823 - acc: 0.8653\n",
            "Epoch 21/80\n",
            "193/193 [==============================] - 0s 368us/step - loss: 0.2858 - acc: 0.8290\n",
            "Epoch 22/80\n",
            "193/193 [==============================] - 0s 388us/step - loss: 0.2656 - acc: 0.8549\n",
            "Epoch 23/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.2651 - acc: 0.8653\n",
            "Epoch 24/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.2680 - acc: 0.8497\n",
            "Epoch 25/80\n",
            "193/193 [==============================] - 0s 413us/step - loss: 0.2473 - acc: 0.8601\n",
            "Epoch 26/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.2384 - acc: 0.8756\n",
            "Epoch 27/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.2348 - acc: 0.8705\n",
            "Epoch 28/80\n",
            "193/193 [==============================] - 0s 375us/step - loss: 0.2281 - acc: 0.8549\n",
            "Epoch 29/80\n",
            "193/193 [==============================] - 0s 411us/step - loss: 0.2157 - acc: 0.8808\n",
            "Epoch 30/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.2182 - acc: 0.8808\n",
            "Epoch 31/80\n",
            "193/193 [==============================] - 0s 375us/step - loss: 0.2082 - acc: 0.8808\n",
            "Epoch 32/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.2069 - acc: 0.8808\n",
            "Epoch 33/80\n",
            "193/193 [==============================] - 0s 371us/step - loss: 0.1943 - acc: 0.8756\n",
            "Epoch 34/80\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.1933 - acc: 0.8860\n",
            "Epoch 35/80\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.1839 - acc: 0.8860\n",
            "Epoch 36/80\n",
            "193/193 [==============================] - 0s 387us/step - loss: 0.1855 - acc: 0.8601\n",
            "Epoch 37/80\n",
            "193/193 [==============================] - 0s 386us/step - loss: 0.1752 - acc: 0.8912\n",
            "Epoch 38/80\n",
            "193/193 [==============================] - 0s 359us/step - loss: 0.1740 - acc: 0.8653\n",
            "Epoch 39/80\n",
            "193/193 [==============================] - 0s 387us/step - loss: 0.1628 - acc: 0.8549\n",
            "Epoch 40/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.1623 - acc: 0.8446\n",
            "Epoch 41/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.1676 - acc: 0.8290\n",
            "Epoch 42/80\n",
            "193/193 [==============================] - 0s 404us/step - loss: 0.1544 - acc: 0.8653\n",
            "Epoch 43/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.1439 - acc: 0.8756\n",
            "Epoch 44/80\n",
            "193/193 [==============================] - 0s 373us/step - loss: 0.1564 - acc: 0.8290\n",
            "Epoch 45/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.1697 - acc: 0.8808\n",
            "Epoch 46/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.1383 - acc: 0.8705\n",
            "Epoch 47/80\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.1331 - acc: 0.8549\n",
            "Epoch 48/80\n",
            "193/193 [==============================] - 0s 384us/step - loss: 0.1320 - acc: 0.8394\n",
            "Epoch 49/80\n",
            "193/193 [==============================] - 0s 393us/step - loss: 0.1256 - acc: 0.8601\n",
            "Epoch 50/80\n",
            "193/193 [==============================] - 0s 373us/step - loss: 0.1224 - acc: 0.8446\n",
            "Epoch 51/80\n",
            "193/193 [==============================] - 0s 378us/step - loss: 0.1165 - acc: 0.8653\n",
            "Epoch 52/80\n",
            "193/193 [==============================] - 0s 375us/step - loss: 0.1159 - acc: 0.8342\n",
            "Epoch 53/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.1117 - acc: 0.8601\n",
            "Epoch 54/80\n",
            "193/193 [==============================] - 0s 400us/step - loss: 0.1080 - acc: 0.8601\n",
            "Epoch 55/80\n",
            "193/193 [==============================] - 0s 433us/step - loss: 0.1044 - acc: 0.8549\n",
            "Epoch 56/80\n",
            "193/193 [==============================] - 0s 381us/step - loss: 0.0975 - acc: 0.8549\n",
            "Epoch 57/80\n",
            "193/193 [==============================] - 0s 373us/step - loss: 0.1015 - acc: 0.8394\n",
            "Epoch 58/80\n",
            "193/193 [==============================] - 0s 384us/step - loss: 0.0927 - acc: 0.8601\n",
            "Epoch 59/80\n",
            "193/193 [==============================] - 0s 385us/step - loss: 0.0894 - acc: 0.8497\n",
            "Epoch 60/80\n",
            "193/193 [==============================] - 0s 370us/step - loss: 0.0924 - acc: 0.8756\n",
            "Epoch 61/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.0894 - acc: 0.8394\n",
            "Epoch 62/80\n",
            "193/193 [==============================] - 0s 362us/step - loss: 0.0819 - acc: 0.8601\n",
            "Epoch 63/80\n",
            "193/193 [==============================] - 0s 385us/step - loss: 0.0779 - acc: 0.8446\n",
            "Epoch 64/80\n",
            "193/193 [==============================] - 0s 363us/step - loss: 0.0746 - acc: 0.8394\n",
            "Epoch 65/80\n",
            "193/193 [==============================] - 0s 388us/step - loss: 0.0738 - acc: 0.8238\n",
            "Epoch 66/80\n",
            "193/193 [==============================] - 0s 401us/step - loss: 0.0843 - acc: 0.8653\n",
            "Epoch 67/80\n",
            "193/193 [==============================] - 0s 386us/step - loss: 0.0861 - acc: 0.8446\n",
            "Epoch 68/80\n",
            "193/193 [==============================] - 0s 396us/step - loss: 0.0718 - acc: 0.8187\n",
            "Epoch 69/80\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.0677 - acc: 0.7979\n",
            "Epoch 70/80\n",
            "193/193 [==============================] - 0s 404us/step - loss: 0.0652 - acc: 0.7772\n",
            "Epoch 71/80\n",
            "193/193 [==============================] - 0s 387us/step - loss: 0.0616 - acc: 0.7927\n",
            "Epoch 72/80\n",
            "193/193 [==============================] - 0s 372us/step - loss: 0.0591 - acc: 0.8083\n",
            "Epoch 73/80\n",
            "193/193 [==============================] - 0s 370us/step - loss: 0.0564 - acc: 0.8083\n",
            "Epoch 74/80\n",
            "193/193 [==============================] - 0s 359us/step - loss: 0.0576 - acc: 0.8031\n",
            "Epoch 75/80\n",
            "193/193 [==============================] - 0s 355us/step - loss: 0.0588 - acc: 0.7876\n",
            "Epoch 76/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.0534 - acc: 0.7668\n",
            "Epoch 77/80\n",
            "193/193 [==============================] - 0s 363us/step - loss: 0.0555 - acc: 0.7772\n",
            "Epoch 78/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.0523 - acc: 0.7824\n",
            "Epoch 79/80\n",
            "193/193 [==============================] - 0s 386us/step - loss: 0.0500 - acc: 0.7927\n",
            "Epoch 80/80\n",
            "193/193 [==============================] - 0s 384us/step - loss: 0.0460 - acc: 0.7824\n",
            "49/49 [==============================] - 1s 20ms/step\n",
            "Epoch 1/80\n",
            "193/193 [==============================] - 2s 13ms/step - loss: 6.8678 - acc: 0.4560\n",
            "Epoch 2/80\n",
            "193/193 [==============================] - 0s 372us/step - loss: 0.4939 - acc: 0.7565\n",
            "Epoch 3/80\n",
            "193/193 [==============================] - 0s 388us/step - loss: 0.4192 - acc: 0.8135\n",
            "Epoch 4/80\n",
            "193/193 [==============================] - 0s 368us/step - loss: 0.4434 - acc: 0.8238\n",
            "Epoch 5/80\n",
            "193/193 [==============================] - 0s 407us/step - loss: 0.4352 - acc: 0.8187\n",
            "Epoch 6/80\n",
            "193/193 [==============================] - 0s 361us/step - loss: 0.3585 - acc: 0.8238\n",
            "Epoch 7/80\n",
            "193/193 [==============================] - 0s 372us/step - loss: 0.4110 - acc: 0.8549\n",
            "Epoch 8/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.3923 - acc: 0.8549\n",
            "Epoch 9/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.3904 - acc: 0.8497\n",
            "Epoch 10/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.4015 - acc: 0.8446\n",
            "Epoch 11/80\n",
            "193/193 [==============================] - 0s 395us/step - loss: 0.3787 - acc: 0.8756\n",
            "Epoch 12/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.3707 - acc: 0.8705\n",
            "Epoch 13/80\n",
            "193/193 [==============================] - 0s 354us/step - loss: 0.3754 - acc: 0.8653\n",
            "Epoch 14/80\n",
            "193/193 [==============================] - 0s 367us/step - loss: 0.5196 - acc: 0.8031\n",
            "Epoch 15/80\n",
            "193/193 [==============================] - 0s 373us/step - loss: 0.4945 - acc: 0.8135\n",
            "Epoch 16/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.4175 - acc: 0.8187\n",
            "Epoch 17/80\n",
            "193/193 [==============================] - 0s 418us/step - loss: 0.2986 - acc: 0.8601\n",
            "Epoch 18/80\n",
            "193/193 [==============================] - 0s 404us/step - loss: 0.2911 - acc: 0.8705\n",
            "Epoch 19/80\n",
            "193/193 [==============================] - 0s 367us/step - loss: 0.2819 - acc: 0.8860\n",
            "Epoch 20/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.2757 - acc: 0.8964\n",
            "Epoch 21/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.2686 - acc: 0.8756\n",
            "Epoch 22/80\n",
            "193/193 [==============================] - 0s 385us/step - loss: 0.2963 - acc: 0.8497\n",
            "Epoch 23/80\n",
            "193/193 [==============================] - 0s 365us/step - loss: 0.3327 - acc: 0.8342\n",
            "Epoch 24/80\n",
            "193/193 [==============================] - 0s 386us/step - loss: 0.2735 - acc: 0.8808\n",
            "Epoch 25/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.2572 - acc: 0.9067\n",
            "Epoch 26/80\n",
            "193/193 [==============================] - 0s 362us/step - loss: 0.2434 - acc: 0.8912\n",
            "Epoch 27/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.2435 - acc: 0.8912\n",
            "Epoch 28/80\n",
            "193/193 [==============================] - 0s 388us/step - loss: 0.2473 - acc: 0.8860\n",
            "Epoch 29/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.2330 - acc: 0.9119\n",
            "Epoch 30/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.2295 - acc: 0.9171\n",
            "Epoch 31/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.2205 - acc: 0.8860\n",
            "Epoch 32/80\n",
            "193/193 [==============================] - 0s 421us/step - loss: 0.2154 - acc: 0.8860\n",
            "Epoch 33/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.2156 - acc: 0.9119\n",
            "Epoch 34/80\n",
            "193/193 [==============================] - 0s 359us/step - loss: 0.2042 - acc: 0.9171\n",
            "Epoch 35/80\n",
            "193/193 [==============================] - 0s 384us/step - loss: 0.2042 - acc: 0.8808\n",
            "Epoch 36/80\n",
            "193/193 [==============================] - 0s 363us/step - loss: 0.2036 - acc: 0.9067\n",
            "Epoch 37/80\n",
            "193/193 [==============================] - 0s 373us/step - loss: 0.2011 - acc: 0.9067\n",
            "Epoch 38/80\n",
            "193/193 [==============================] - 0s 402us/step - loss: 0.2009 - acc: 0.9223\n",
            "Epoch 39/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.1849 - acc: 0.9326\n",
            "Epoch 40/80\n",
            "193/193 [==============================] - 0s 372us/step - loss: 0.1890 - acc: 0.9171\n",
            "Epoch 41/80\n",
            "193/193 [==============================] - 0s 349us/step - loss: 0.1848 - acc: 0.9326\n",
            "Epoch 42/80\n",
            "193/193 [==============================] - 0s 357us/step - loss: 0.1794 - acc: 0.9016\n",
            "Epoch 43/80\n",
            "193/193 [==============================] - 0s 360us/step - loss: 0.1766 - acc: 0.9067\n",
            "Epoch 44/80\n",
            "193/193 [==============================] - 0s 373us/step - loss: 0.1738 - acc: 0.9223\n",
            "Epoch 45/80\n",
            "193/193 [==============================] - 0s 389us/step - loss: 0.1709 - acc: 0.9119\n",
            "Epoch 46/80\n",
            "193/193 [==============================] - 0s 385us/step - loss: 0.1592 - acc: 0.9275\n",
            "Epoch 47/80\n",
            "193/193 [==============================] - 0s 365us/step - loss: 0.1630 - acc: 0.9171\n",
            "Epoch 48/80\n",
            "193/193 [==============================] - 0s 386us/step - loss: 0.1527 - acc: 0.9223\n",
            "Epoch 49/80\n",
            "193/193 [==============================] - 0s 388us/step - loss: 0.1565 - acc: 0.9275\n",
            "Epoch 50/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.1576 - acc: 0.9171\n",
            "Epoch 51/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.1397 - acc: 0.9275\n",
            "Epoch 52/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.1381 - acc: 0.9223\n",
            "Epoch 53/80\n",
            "193/193 [==============================] - 0s 358us/step - loss: 0.1328 - acc: 0.9223\n",
            "Epoch 54/80\n",
            "193/193 [==============================] - 0s 370us/step - loss: 0.1328 - acc: 0.9326\n",
            "Epoch 55/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.1291 - acc: 0.9378\n",
            "Epoch 56/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.1262 - acc: 0.9171\n",
            "Epoch 57/80\n",
            "193/193 [==============================] - 0s 362us/step - loss: 0.1301 - acc: 0.9275\n",
            "Epoch 58/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.1194 - acc: 0.9067\n",
            "Epoch 59/80\n",
            "193/193 [==============================] - 0s 441us/step - loss: 0.1305 - acc: 0.9119\n",
            "Epoch 60/80\n",
            "193/193 [==============================] - 0s 370us/step - loss: 0.1963 - acc: 0.9016\n",
            "Epoch 61/80\n",
            "193/193 [==============================] - 0s 387us/step - loss: 0.1150 - acc: 0.8860\n",
            "Epoch 62/80\n",
            "193/193 [==============================] - 0s 383us/step - loss: 0.1233 - acc: 0.8653\n",
            "Epoch 63/80\n",
            "193/193 [==============================] - 0s 359us/step - loss: 0.1232 - acc: 0.8549\n",
            "Epoch 64/80\n",
            "193/193 [==============================] - 0s 367us/step - loss: 0.1211 - acc: 0.8964\n",
            "Epoch 65/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.1205 - acc: 0.8912\n",
            "Epoch 66/80\n",
            "193/193 [==============================] - 0s 375us/step - loss: 0.1037 - acc: 0.8964\n",
            "Epoch 67/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.0978 - acc: 0.8912\n",
            "Epoch 68/80\n",
            "193/193 [==============================] - 0s 368us/step - loss: 0.0932 - acc: 0.8964\n",
            "Epoch 69/80\n",
            "193/193 [==============================] - 0s 363us/step - loss: 0.0949 - acc: 0.8912\n",
            "Epoch 70/80\n",
            "193/193 [==============================] - 0s 373us/step - loss: 0.0888 - acc: 0.8497\n",
            "Epoch 71/80\n",
            "193/193 [==============================] - 0s 386us/step - loss: 0.0878 - acc: 0.8756\n",
            "Epoch 72/80\n",
            "193/193 [==============================] - 0s 394us/step - loss: 0.0845 - acc: 0.8912\n",
            "Epoch 73/80\n",
            "193/193 [==============================] - 0s 371us/step - loss: 0.0881 - acc: 0.8446\n",
            "Epoch 74/80\n",
            "193/193 [==============================] - 0s 363us/step - loss: 0.0854 - acc: 0.8756\n",
            "Epoch 75/80\n",
            "193/193 [==============================] - 0s 375us/step - loss: 0.0933 - acc: 0.8342\n",
            "Epoch 76/80\n",
            "193/193 [==============================] - 0s 377us/step - loss: 0.0764 - acc: 0.8705\n",
            "Epoch 77/80\n",
            "193/193 [==============================] - 0s 377us/step - loss: 0.0824 - acc: 0.8549\n",
            "Epoch 78/80\n",
            "193/193 [==============================] - 0s 397us/step - loss: 0.0810 - acc: 0.8808\n",
            "Epoch 79/80\n",
            "193/193 [==============================] - 0s 405us/step - loss: 0.0839 - acc: 0.8394\n",
            "Epoch 80/80\n",
            "193/193 [==============================] - 0s 385us/step - loss: 0.0709 - acc: 0.8394\n",
            "49/49 [==============================] - 1s 20ms/step\n",
            "Epoch 1/80\n",
            "193/193 [==============================] - 2s 13ms/step - loss: 3.7956 - acc: 0.4249\n",
            "Epoch 2/80\n",
            "193/193 [==============================] - 0s 369us/step - loss: 0.7453 - acc: 0.4508\n",
            "Epoch 3/80\n",
            "193/193 [==============================] - 0s 372us/step - loss: 0.6353 - acc: 0.6736\n",
            "Epoch 4/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.5414 - acc: 0.7824\n",
            "Epoch 5/80\n",
            "193/193 [==============================] - 0s 358us/step - loss: 0.4574 - acc: 0.8238\n",
            "Epoch 6/80\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.4703 - acc: 0.8394\n",
            "Epoch 7/80\n",
            "193/193 [==============================] - 0s 372us/step - loss: 0.4616 - acc: 0.8342\n",
            "Epoch 8/80\n",
            "193/193 [==============================] - 0s 388us/step - loss: 0.4377 - acc: 0.8497\n",
            "Epoch 9/80\n",
            "193/193 [==============================] - 0s 417us/step - loss: 0.4235 - acc: 0.8446\n",
            "Epoch 10/80\n",
            "193/193 [==============================] - 0s 370us/step - loss: 0.4109 - acc: 0.8446\n",
            "Epoch 11/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.6032 - acc: 0.7668\n",
            "Epoch 12/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.4715 - acc: 0.7876\n",
            "Epoch 13/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.4422 - acc: 0.8653\n",
            "Epoch 14/80\n",
            "193/193 [==============================] - 0s 395us/step - loss: 0.4008 - acc: 0.8394\n",
            "Epoch 15/80\n",
            "193/193 [==============================] - 0s 402us/step - loss: 0.3933 - acc: 0.8549\n",
            "Epoch 16/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.3882 - acc: 0.8497\n",
            "Epoch 17/80\n",
            "193/193 [==============================] - 0s 375us/step - loss: 0.3709 - acc: 0.8497\n",
            "Epoch 18/80\n",
            "193/193 [==============================] - 0s 370us/step - loss: 0.3644 - acc: 0.8497\n",
            "Epoch 19/80\n",
            "193/193 [==============================] - 0s 370us/step - loss: 0.3545 - acc: 0.8497\n",
            "Epoch 20/80\n",
            "193/193 [==============================] - 0s 365us/step - loss: 0.3615 - acc: 0.8705\n",
            "Epoch 21/80\n",
            "193/193 [==============================] - 0s 385us/step - loss: 0.3488 - acc: 0.8549\n",
            "Epoch 22/80\n",
            "193/193 [==============================] - 0s 386us/step - loss: 0.3423 - acc: 0.8549\n",
            "Epoch 23/80\n",
            "193/193 [==============================] - 0s 365us/step - loss: 0.3509 - acc: 0.8653\n",
            "Epoch 24/80\n",
            "193/193 [==============================] - 0s 362us/step - loss: 0.3346 - acc: 0.8549\n",
            "Epoch 25/80\n",
            "193/193 [==============================] - 0s 399us/step - loss: 0.3228 - acc: 0.8705\n",
            "Epoch 26/80\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.3249 - acc: 0.8446\n",
            "Epoch 27/80\n",
            "193/193 [==============================] - 0s 387us/step - loss: 0.3173 - acc: 0.8601\n",
            "Epoch 28/80\n",
            "193/193 [==============================] - 0s 401us/step - loss: 0.3082 - acc: 0.8394\n",
            "Epoch 29/80\n",
            "193/193 [==============================] - 0s 368us/step - loss: 0.3046 - acc: 0.8601\n",
            "Epoch 30/80\n",
            "193/193 [==============================] - 0s 394us/step - loss: 0.3949 - acc: 0.8394\n",
            "Epoch 31/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.3087 - acc: 0.8290\n",
            "Epoch 32/80\n",
            "193/193 [==============================] - 0s 379us/step - loss: 0.2970 - acc: 0.8601\n",
            "Epoch 33/80\n",
            "193/193 [==============================] - 0s 392us/step - loss: 0.2968 - acc: 0.8808\n",
            "Epoch 34/80\n",
            "193/193 [==============================] - 0s 362us/step - loss: 0.2871 - acc: 0.8653\n",
            "Epoch 35/80\n",
            "193/193 [==============================] - 0s 397us/step - loss: 0.2819 - acc: 0.8135\n",
            "Epoch 36/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.2824 - acc: 0.8290\n",
            "Epoch 37/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.2734 - acc: 0.8238\n",
            "Epoch 38/80\n",
            "193/193 [==============================] - 0s 377us/step - loss: 0.2712 - acc: 0.8601\n",
            "Epoch 39/80\n",
            "193/193 [==============================] - 0s 378us/step - loss: 0.2718 - acc: 0.8187\n",
            "Epoch 40/80\n",
            "193/193 [==============================] - 0s 375us/step - loss: 0.2570 - acc: 0.8135\n",
            "Epoch 41/80\n",
            "193/193 [==============================] - 0s 388us/step - loss: 0.2641 - acc: 0.8342\n",
            "Epoch 42/80\n",
            "193/193 [==============================] - 0s 365us/step - loss: 0.2808 - acc: 0.8808\n",
            "Epoch 43/80\n",
            "193/193 [==============================] - 0s 368us/step - loss: 0.2528 - acc: 0.8290\n",
            "Epoch 44/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.2457 - acc: 0.8135\n",
            "Epoch 45/80\n",
            "193/193 [==============================] - 0s 392us/step - loss: 0.2395 - acc: 0.8083\n",
            "Epoch 46/80\n",
            "193/193 [==============================] - 0s 358us/step - loss: 0.2458 - acc: 0.7979\n",
            "Epoch 47/80\n",
            "193/193 [==============================] - 0s 387us/step - loss: 0.2394 - acc: 0.8187\n",
            "Epoch 48/80\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.2300 - acc: 0.8238\n",
            "Epoch 49/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.2350 - acc: 0.8083\n",
            "Epoch 50/80\n",
            "193/193 [==============================] - 0s 382us/step - loss: 0.2270 - acc: 0.8031\n",
            "Epoch 51/80\n",
            "193/193 [==============================] - 0s 368us/step - loss: 0.2217 - acc: 0.8238\n",
            "Epoch 52/80\n",
            "193/193 [==============================] - 0s 385us/step - loss: 0.2194 - acc: 0.8290\n",
            "Epoch 53/80\n",
            "193/193 [==============================] - 0s 379us/step - loss: 0.2194 - acc: 0.8135\n",
            "Epoch 54/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.2161 - acc: 0.8135\n",
            "Epoch 55/80\n",
            "193/193 [==============================] - 0s 377us/step - loss: 0.2113 - acc: 0.8135\n",
            "Epoch 56/80\n",
            "193/193 [==============================] - 0s 388us/step - loss: 0.2234 - acc: 0.8290\n",
            "Epoch 57/80\n",
            "193/193 [==============================] - 0s 381us/step - loss: 0.2087 - acc: 0.8187\n",
            "Epoch 58/80\n",
            "193/193 [==============================] - 0s 377us/step - loss: 0.2110 - acc: 0.7979\n",
            "Epoch 59/80\n",
            "193/193 [==============================] - 0s 377us/step - loss: 0.1986 - acc: 0.8135\n",
            "Epoch 60/80\n",
            "193/193 [==============================] - 0s 375us/step - loss: 0.2013 - acc: 0.8290\n",
            "Epoch 61/80\n",
            "193/193 [==============================] - 0s 376us/step - loss: 0.1963 - acc: 0.7979\n",
            "Epoch 62/80\n",
            "193/193 [==============================] - 0s 379us/step - loss: 0.2007 - acc: 0.8083\n",
            "Epoch 63/80\n",
            "193/193 [==============================] - 0s 387us/step - loss: 0.2071 - acc: 0.8238\n",
            "Epoch 64/80\n",
            "193/193 [==============================] - 0s 401us/step - loss: 0.1927 - acc: 0.7927\n",
            "Epoch 65/80\n",
            "193/193 [==============================] - 0s 374us/step - loss: 0.1858 - acc: 0.8031\n",
            "Epoch 66/80\n",
            "193/193 [==============================] - 0s 396us/step - loss: 0.2028 - acc: 0.8238\n",
            "Epoch 67/80\n",
            "193/193 [==============================] - 0s 372us/step - loss: 0.1921 - acc: 0.8031\n",
            "Epoch 68/80\n",
            "193/193 [==============================] - 0s 389us/step - loss: 0.1860 - acc: 0.8083\n",
            "Epoch 69/80\n",
            "193/193 [==============================] - 0s 358us/step - loss: 0.1909 - acc: 0.7979\n",
            "Epoch 70/80\n",
            "193/193 [==============================] - 0s 360us/step - loss: 0.2224 - acc: 0.7927\n",
            "Epoch 71/80\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.1881 - acc: 0.8031\n",
            "Epoch 72/80\n",
            "193/193 [==============================] - 0s 384us/step - loss: 0.1831 - acc: 0.7979\n",
            "Epoch 73/80\n",
            "193/193 [==============================] - 0s 406us/step - loss: 0.1711 - acc: 0.7824\n",
            "Epoch 74/80\n",
            "193/193 [==============================] - 0s 380us/step - loss: 0.1719 - acc: 0.7979\n",
            "Epoch 75/80\n",
            "193/193 [==============================] - 0s 371us/step - loss: 0.1835 - acc: 0.7876\n",
            "Epoch 76/80\n",
            "193/193 [==============================] - 0s 392us/step - loss: 0.1787 - acc: 0.7772\n",
            "Epoch 77/80\n",
            "193/193 [==============================] - 0s 372us/step - loss: 0.1660 - acc: 0.7927\n",
            "Epoch 78/80\n",
            "193/193 [==============================] - 0s 390us/step - loss: 0.1614 - acc: 0.8031\n",
            "Epoch 79/80\n",
            "193/193 [==============================] - 0s 359us/step - loss: 0.1618 - acc: 0.7668\n",
            "Epoch 80/80\n",
            "193/193 [==============================] - 0s 367us/step - loss: 0.1596 - acc: 0.7876\n",
            "49/49 [==============================] - 1s 20ms/step\n",
            "Epoch 1/80\n",
            "194/194 [==============================] - 3s 13ms/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 2/80\n",
            "194/194 [==============================] - 0s 372us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 3/80\n",
            "194/194 [==============================] - 0s 375us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 4/80\n",
            "194/194 [==============================] - 0s 371us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 5/80\n",
            "194/194 [==============================] - 0s 388us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 6/80\n",
            "194/194 [==============================] - 0s 369us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 7/80\n",
            "194/194 [==============================] - 0s 369us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 8/80\n",
            "194/194 [==============================] - 0s 420us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 9/80\n",
            "194/194 [==============================] - 0s 392us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 10/80\n",
            "194/194 [==============================] - 0s 421us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 11/80\n",
            "194/194 [==============================] - 0s 386us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 12/80\n",
            "194/194 [==============================] - 0s 399us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 13/80\n",
            "194/194 [==============================] - 0s 370us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 14/80\n",
            "194/194 [==============================] - 0s 366us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 15/80\n",
            "194/194 [==============================] - 0s 366us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 16/80\n",
            "194/194 [==============================] - 0s 365us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 17/80\n",
            "194/194 [==============================] - 0s 408us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 18/80\n",
            "194/194 [==============================] - 0s 381us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 19/80\n",
            "194/194 [==============================] - 0s 367us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 20/80\n",
            "194/194 [==============================] - 0s 389us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 21/80\n",
            "194/194 [==============================] - 0s 410us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 22/80\n",
            "194/194 [==============================] - 0s 366us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 23/80\n",
            "194/194 [==============================] - 0s 387us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 24/80\n",
            "194/194 [==============================] - 0s 362us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 25/80\n",
            "194/194 [==============================] - 0s 378us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 26/80\n",
            "194/194 [==============================] - 0s 386us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 27/80\n",
            "194/194 [==============================] - 0s 360us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 28/80\n",
            "194/194 [==============================] - 0s 381us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 29/80\n",
            "194/194 [==============================] - 0s 376us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 30/80\n",
            "194/194 [==============================] - 0s 381us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 31/80\n",
            "194/194 [==============================] - 0s 371us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 32/80\n",
            "194/194 [==============================] - 0s 381us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 33/80\n",
            "194/194 [==============================] - 0s 400us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 34/80\n",
            "194/194 [==============================] - 0s 366us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 35/80\n",
            "194/194 [==============================] - 0s 415us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 36/80\n",
            "194/194 [==============================] - 0s 413us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 37/80\n",
            "194/194 [==============================] - 0s 377us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 38/80\n",
            "194/194 [==============================] - 0s 383us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 39/80\n",
            "194/194 [==============================] - 0s 379us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 40/80\n",
            "194/194 [==============================] - 0s 382us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 41/80\n",
            "194/194 [==============================] - 0s 378us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 42/80\n",
            "194/194 [==============================] - 0s 380us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 43/80\n",
            "194/194 [==============================] - 0s 361us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 44/80\n",
            "194/194 [==============================] - 0s 383us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 45/80\n",
            "194/194 [==============================] - 0s 382us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 46/80\n",
            "194/194 [==============================] - 0s 377us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 47/80\n",
            "194/194 [==============================] - 0s 409us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 48/80\n",
            "194/194 [==============================] - 0s 383us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 49/80\n",
            "194/194 [==============================] - 0s 386us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 50/80\n",
            "194/194 [==============================] - 0s 369us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 51/80\n",
            "194/194 [==============================] - 0s 390us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 52/80\n",
            "194/194 [==============================] - 0s 370us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 53/80\n",
            "194/194 [==============================] - 0s 384us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 54/80\n",
            "194/194 [==============================] - 0s 383us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 55/80\n",
            "194/194 [==============================] - 0s 418us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 56/80\n",
            "194/194 [==============================] - 0s 383us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 57/80\n",
            "194/194 [==============================] - 0s 359us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 58/80\n",
            "194/194 [==============================] - 0s 354us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 59/80\n",
            "194/194 [==============================] - 0s 385us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 60/80\n",
            "194/194 [==============================] - 0s 384us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 61/80\n",
            "194/194 [==============================] - 0s 364us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 62/80\n",
            "194/194 [==============================] - 0s 371us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 63/80\n",
            "194/194 [==============================] - 0s 434us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 64/80\n",
            "194/194 [==============================] - 0s 367us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 65/80\n",
            "194/194 [==============================] - 0s 368us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 66/80\n",
            "194/194 [==============================] - 0s 400us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 67/80\n",
            "194/194 [==============================] - 0s 368us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 68/80\n",
            "194/194 [==============================] - 0s 386us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 69/80\n",
            "194/194 [==============================] - 0s 358us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 70/80\n",
            "194/194 [==============================] - 0s 390us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 71/80\n",
            "194/194 [==============================] - 0s 359us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 72/80\n",
            "194/194 [==============================] - 0s 369us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 73/80\n",
            "194/194 [==============================] - 0s 368us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 74/80\n",
            "194/194 [==============================] - 0s 387us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 75/80\n",
            "194/194 [==============================] - 0s 397us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 76/80\n",
            "194/194 [==============================] - 0s 392us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 77/80\n",
            "194/194 [==============================] - 0s 374us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 78/80\n",
            "194/194 [==============================] - 0s 388us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 79/80\n",
            "194/194 [==============================] - 0s 404us/step - loss: 8.8899 - acc: 0.4485\n",
            "Epoch 80/80\n",
            "194/194 [==============================] - 0s 375us/step - loss: 8.8899 - acc: 0.4485\n",
            "48/48 [==============================] - 1s 22ms/step\n",
            "Epoch 1/80\n",
            "195/195 [==============================] - 3s 13ms/step - loss: 0.7858 - acc: 0.5846\n",
            "Epoch 2/80\n",
            "195/195 [==============================] - 0s 387us/step - loss: 0.6052 - acc: 0.7641\n",
            "Epoch 3/80\n",
            "195/195 [==============================] - 0s 382us/step - loss: 0.4723 - acc: 0.7795\n",
            "Epoch 4/80\n",
            "195/195 [==============================] - 0s 391us/step - loss: 0.4923 - acc: 0.7744\n",
            "Epoch 5/80\n",
            "195/195 [==============================] - 0s 387us/step - loss: 0.5795 - acc: 0.7487\n",
            "Epoch 6/80\n",
            "195/195 [==============================] - 0s 389us/step - loss: 0.3996 - acc: 0.8103\n",
            "Epoch 7/80\n",
            "195/195 [==============================] - 0s 375us/step - loss: 0.3848 - acc: 0.8154\n",
            "Epoch 8/80\n",
            "195/195 [==============================] - 0s 388us/step - loss: 0.4436 - acc: 0.7487\n",
            "Epoch 9/80\n",
            "195/195 [==============================] - 0s 381us/step - loss: 0.3744 - acc: 0.8103\n",
            "Epoch 10/80\n",
            "195/195 [==============================] - 0s 359us/step - loss: 0.3520 - acc: 0.8051\n",
            "Epoch 11/80\n",
            "195/195 [==============================] - 0s 380us/step - loss: 0.3392 - acc: 0.8256\n",
            "Epoch 12/80\n",
            "195/195 [==============================] - 0s 375us/step - loss: 0.3307 - acc: 0.8256\n",
            "Epoch 13/80\n",
            "195/195 [==============================] - 0s 387us/step - loss: 0.3343 - acc: 0.8462\n",
            "Epoch 14/80\n",
            "195/195 [==============================] - 0s 362us/step - loss: 0.3134 - acc: 0.8103\n",
            "Epoch 15/80\n",
            "195/195 [==============================] - 0s 363us/step - loss: 0.3146 - acc: 0.8103\n",
            "Epoch 16/80\n",
            "195/195 [==============================] - 0s 386us/step - loss: 0.3006 - acc: 0.8205\n",
            "Epoch 17/80\n",
            "195/195 [==============================] - 0s 374us/step - loss: 0.2975 - acc: 0.8103\n",
            "Epoch 18/80\n",
            "195/195 [==============================] - 0s 365us/step - loss: 0.3103 - acc: 0.8051\n",
            "Epoch 19/80\n",
            "195/195 [==============================] - 0s 373us/step - loss: 0.3448 - acc: 0.7795\n",
            "Epoch 20/80\n",
            "195/195 [==============================] - 0s 392us/step - loss: 0.2975 - acc: 0.8462\n",
            "Epoch 21/80\n",
            "195/195 [==============================] - 0s 391us/step - loss: 0.2773 - acc: 0.7897\n",
            "Epoch 22/80\n",
            "195/195 [==============================] - 0s 407us/step - loss: 0.2708 - acc: 0.7641\n",
            "Epoch 23/80\n",
            "195/195 [==============================] - 0s 372us/step - loss: 0.2618 - acc: 0.7692\n",
            "Epoch 24/80\n",
            "195/195 [==============================] - 0s 381us/step - loss: 0.2549 - acc: 0.7949\n",
            "Epoch 25/80\n",
            "195/195 [==============================] - 0s 393us/step - loss: 0.2610 - acc: 0.7744\n",
            "Epoch 26/80\n",
            "195/195 [==============================] - 0s 380us/step - loss: 0.2628 - acc: 0.7590\n",
            "Epoch 27/80\n",
            "195/195 [==============================] - 0s 383us/step - loss: 0.2591 - acc: 0.7846\n",
            "Epoch 28/80\n",
            "195/195 [==============================] - 0s 384us/step - loss: 0.2436 - acc: 0.7692\n",
            "Epoch 29/80\n",
            "195/195 [==============================] - 0s 393us/step - loss: 0.3319 - acc: 0.7538\n",
            "Epoch 30/80\n",
            "195/195 [==============================] - 0s 381us/step - loss: 2.7293 - acc: 0.6513\n",
            "Epoch 31/80\n",
            "195/195 [==============================] - 0s 373us/step - loss: 0.3380 - acc: 0.7077\n",
            "Epoch 32/80\n",
            "195/195 [==============================] - 0s 378us/step - loss: 0.3089 - acc: 0.7590\n",
            "Epoch 33/80\n",
            "195/195 [==============================] - 0s 378us/step - loss: 0.2813 - acc: 0.7692\n",
            "Epoch 34/80\n",
            "195/195 [==============================] - 0s 388us/step - loss: 0.2645 - acc: 0.7897\n",
            "Epoch 35/80\n",
            "195/195 [==============================] - 0s 410us/step - loss: 0.2582 - acc: 0.7692\n",
            "Epoch 36/80\n",
            "195/195 [==============================] - 0s 415us/step - loss: 0.2446 - acc: 0.7590\n",
            "Epoch 37/80\n",
            "195/195 [==============================] - 0s 399us/step - loss: 0.2443 - acc: 0.7487\n",
            "Epoch 38/80\n",
            "195/195 [==============================] - 0s 387us/step - loss: 0.2503 - acc: 0.7949\n",
            "Epoch 39/80\n",
            "195/195 [==============================] - 0s 369us/step - loss: 0.2364 - acc: 0.7538\n",
            "Epoch 40/80\n",
            "195/195 [==============================] - 0s 359us/step - loss: 0.2336 - acc: 0.7641\n",
            "Epoch 41/80\n",
            "195/195 [==============================] - 0s 392us/step - loss: 0.2413 - acc: 0.7436\n",
            "Epoch 42/80\n",
            "195/195 [==============================] - 0s 375us/step - loss: 0.2270 - acc: 0.7487\n",
            "Epoch 43/80\n",
            "195/195 [==============================] - 0s 385us/step - loss: 0.2226 - acc: 0.7590\n",
            "Epoch 44/80\n",
            "195/195 [==============================] - 0s 391us/step - loss: 0.2202 - acc: 0.7846\n",
            "Epoch 45/80\n",
            "195/195 [==============================] - 0s 428us/step - loss: 0.2210 - acc: 0.7590\n",
            "Epoch 46/80\n",
            "195/195 [==============================] - 0s 373us/step - loss: 0.2167 - acc: 0.7795\n",
            "Epoch 47/80\n",
            "195/195 [==============================] - 0s 393us/step - loss: 0.2020 - acc: 0.7692\n",
            "Epoch 48/80\n",
            "195/195 [==============================] - 0s 428us/step - loss: 0.2004 - acc: 0.7590\n",
            "Epoch 49/80\n",
            "195/195 [==============================] - 0s 404us/step - loss: 0.1965 - acc: 0.7795\n",
            "Epoch 50/80\n",
            "195/195 [==============================] - 0s 386us/step - loss: 0.1904 - acc: 0.7744\n",
            "Epoch 51/80\n",
            "195/195 [==============================] - 0s 418us/step - loss: 0.1882 - acc: 0.7744\n",
            "Epoch 52/80\n",
            "195/195 [==============================] - 0s 382us/step - loss: 0.1846 - acc: 0.7692\n",
            "Epoch 53/80\n",
            "195/195 [==============================] - 0s 384us/step - loss: 0.1835 - acc: 0.7744\n",
            "Epoch 54/80\n",
            "195/195 [==============================] - 0s 388us/step - loss: 0.1837 - acc: 0.7692\n",
            "Epoch 55/80\n",
            "195/195 [==============================] - 0s 379us/step - loss: 0.1815 - acc: 0.7846\n",
            "Epoch 56/80\n",
            "195/195 [==============================] - 0s 408us/step - loss: 0.1744 - acc: 0.7641\n",
            "Epoch 57/80\n",
            "195/195 [==============================] - 0s 400us/step - loss: 0.1766 - acc: 0.7538\n",
            "Epoch 58/80\n",
            "195/195 [==============================] - 0s 413us/step - loss: 0.1665 - acc: 0.7692\n",
            "Epoch 59/80\n",
            "195/195 [==============================] - 0s 389us/step - loss: 0.1611 - acc: 0.7795\n",
            "Epoch 60/80\n",
            "195/195 [==============================] - 0s 424us/step - loss: 0.1561 - acc: 0.7744\n",
            "Epoch 61/80\n",
            "195/195 [==============================] - 0s 388us/step - loss: 0.1829 - acc: 0.7436\n",
            "Epoch 62/80\n",
            "195/195 [==============================] - 0s 377us/step - loss: 0.1668 - acc: 0.7436\n",
            "Epoch 63/80\n",
            "195/195 [==============================] - 0s 382us/step - loss: 0.1500 - acc: 0.7692\n",
            "Epoch 64/80\n",
            "195/195 [==============================] - 0s 371us/step - loss: 0.1439 - acc: 0.7692\n",
            "Epoch 65/80\n",
            "195/195 [==============================] - 0s 364us/step - loss: 0.1451 - acc: 0.7795\n",
            "Epoch 66/80\n",
            "195/195 [==============================] - 0s 390us/step - loss: 0.1436 - acc: 0.7692\n",
            "Epoch 67/80\n",
            "195/195 [==============================] - 0s 374us/step - loss: 0.1406 - acc: 0.7538\n",
            "Epoch 68/80\n",
            "195/195 [==============================] - 0s 379us/step - loss: 0.1326 - acc: 0.7744\n",
            "Epoch 69/80\n",
            "195/195 [==============================] - 0s 367us/step - loss: 0.1307 - acc: 0.7795\n",
            "Epoch 70/80\n",
            "195/195 [==============================] - 0s 374us/step - loss: 0.1230 - acc: 0.7641\n",
            "Epoch 71/80\n",
            "195/195 [==============================] - 0s 384us/step - loss: 0.1218 - acc: 0.7692\n",
            "Epoch 72/80\n",
            "195/195 [==============================] - 0s 385us/step - loss: 0.1168 - acc: 0.7692\n",
            "Epoch 73/80\n",
            "195/195 [==============================] - 0s 409us/step - loss: 0.1221 - acc: 0.7692\n",
            "Epoch 74/80\n",
            "195/195 [==============================] - 0s 395us/step - loss: 0.1188 - acc: 0.7487\n",
            "Epoch 75/80\n",
            "195/195 [==============================] - 0s 396us/step - loss: 0.1133 - acc: 0.7641\n",
            "Epoch 76/80\n",
            "195/195 [==============================] - 0s 389us/step - loss: 0.1116 - acc: 0.7538\n",
            "Epoch 77/80\n",
            "195/195 [==============================] - 0s 396us/step - loss: 0.1130 - acc: 0.7846\n",
            "Epoch 78/80\n",
            "195/195 [==============================] - 0s 395us/step - loss: 0.1130 - acc: 0.7744\n",
            "Epoch 79/80\n",
            "195/195 [==============================] - 0s 372us/step - loss: 0.1086 - acc: 0.7692\n",
            "Epoch 80/80\n",
            "195/195 [==============================] - 0s 398us/step - loss: 0.1062 - acc: 0.7538\n",
            "47/47 [==============================] - 1s 23ms/step\n",
            "Results: 56.86% (11.32%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CoiJGhNad0-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34428
        },
        "outputId": "8c9fb50a-6932-4397-dead-9e2062f81074"
      },
      "cell_type": "code",
      "source": [
        "# Gridsearch Tune Optimizer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# This one will tune my inits. \n",
        "inits = ['glorot_uniform', 'normal', 'uniform']\n",
        "optimizers = ['adam']\n",
        "activations = [\"relu\"]\n",
        "epochs = [100]\n",
        "batches = [5]\n",
        "\n",
        "\n",
        "def baseline(optimizer = \"adam\", init = \"uniform\", activation='relu'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(39, input_dim=X.shape[1], activation=activation))\n",
        "  model.add(Dense(39, activation=activation))\n",
        "  model.add(Dense(1, activation=activation))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=baseline, verbose = 1)\n",
        "\n",
        "param_grid = dict(optimizer=optimizers, activation=activations epochs=epochs, batch_size=batches, init=inits)\n",
        "print(param_grid)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, )\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "161/161 [==============================] - 6s 36ms/step - loss: 8.9103 - acc: 0.4472\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 579us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 552us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 601us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 588us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 610us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 584us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 591us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 587us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 597us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 583us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 572us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 719us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 657us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 624us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 601us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 666us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 653us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 575us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 597us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 592us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 601us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 587us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 586us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 590us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 601us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 595us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 607us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 583us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 680us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 580us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 607us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 695us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 579us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 591us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 8.9100 - acc: 0.4472\n",
            "81/81 [==============================] - 2s 29ms/step\n",
            "161/161 [==============================] - 0s 476us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 6s 36ms/step - loss: 1.3653 - acc: 0.5093\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.5749 - acc: 0.7019\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 605us/step - loss: 0.4571 - acc: 0.8199\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.3728 - acc: 0.8571\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.3753 - acc: 0.8509\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.7701 - acc: 0.6335\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.4495 - acc: 0.7391\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.3796 - acc: 0.8571\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.3414 - acc: 0.8758\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 649us/step - loss: 0.3253 - acc: 0.8758\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.3061 - acc: 0.8882\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.2954 - acc: 0.8944\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.2787 - acc: 0.9068\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.2652 - acc: 0.9130\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 582us/step - loss: 0.2622 - acc: 0.9068\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 596us/step - loss: 0.2495 - acc: 0.9068\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.2434 - acc: 0.9193\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.2344 - acc: 0.9255\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.2275 - acc: 0.9193\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 599us/step - loss: 0.2252 - acc: 0.9255\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.2134 - acc: 0.9317\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.2109 - acc: 0.9193\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.2064 - acc: 0.9317\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 596us/step - loss: 0.1982 - acc: 0.9317\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 0.1931 - acc: 0.9317\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 593us/step - loss: 0.1882 - acc: 0.9193\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.1879 - acc: 0.9130\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.1862 - acc: 0.9193\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.1752 - acc: 0.9130\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 0.1702 - acc: 0.8944\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 590us/step - loss: 0.1659 - acc: 0.8882\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 716us/step - loss: 0.1688 - acc: 0.9441\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.1619 - acc: 0.9255\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.1547 - acc: 0.9255\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 597us/step - loss: 0.1557 - acc: 0.8882\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.1478 - acc: 0.8758\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.1495 - acc: 0.9068\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 607us/step - loss: 0.1425 - acc: 0.8820\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1361 - acc: 0.8634\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 591us/step - loss: 0.1324 - acc: 0.8634\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.1309 - acc: 0.8758\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.1270 - acc: 0.8882\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.1291 - acc: 0.8634\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.1196 - acc: 0.8634\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.1188 - acc: 0.8696\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 606us/step - loss: 0.1165 - acc: 0.8634\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.1217 - acc: 0.8571\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.1117 - acc: 0.8571\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.1149 - acc: 0.8634\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.1092 - acc: 0.8820\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.1071 - acc: 0.8696\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.1069 - acc: 0.8447\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.0998 - acc: 0.8634\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.0951 - acc: 0.8696\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 595us/step - loss: 0.1036 - acc: 0.8696\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.0950 - acc: 0.8571\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 599us/step - loss: 0.0898 - acc: 0.8634\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.1112 - acc: 0.8509\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 599us/step - loss: 0.0870 - acc: 0.8696\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.0869 - acc: 0.8571\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 584us/step - loss: 0.0826 - acc: 0.8696\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.0807 - acc: 0.8571\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.0750 - acc: 0.8447\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.0761 - acc: 0.8447\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.0717 - acc: 0.8571\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 587us/step - loss: 0.0705 - acc: 0.8447\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 595us/step - loss: 0.0708 - acc: 0.8385\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 585us/step - loss: 0.0672 - acc: 0.8385\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 588us/step - loss: 0.0665 - acc: 0.8385\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 597us/step - loss: 0.0646 - acc: 0.8261\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.0642 - acc: 0.8323\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.0661 - acc: 0.8323\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.0698 - acc: 0.8199\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.0609 - acc: 0.8261\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.0589 - acc: 0.8199\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.0695 - acc: 0.8137\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.0619 - acc: 0.8199\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.0581 - acc: 0.8261\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 593us/step - loss: 0.0527 - acc: 0.8137\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 0.0537 - acc: 0.8137\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.0501 - acc: 0.8075\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.0526 - acc: 0.8012\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 576us/step - loss: 0.0649 - acc: 0.8137\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.0543 - acc: 0.8199\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.0454 - acc: 0.8199\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.0480 - acc: 0.8137\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.0458 - acc: 0.8075\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.0433 - acc: 0.8137\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 653us/step - loss: 0.0465 - acc: 0.8075\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.0410 - acc: 0.7888\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 605us/step - loss: 0.0444 - acc: 0.8137\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 671us/step - loss: 0.0407 - acc: 0.7888\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.0399 - acc: 0.7950\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 597us/step - loss: 0.0434 - acc: 0.7950\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 0.0460 - acc: 0.7888\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.0368 - acc: 0.7888\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.0423 - acc: 0.7950\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 601us/step - loss: 0.0450 - acc: 0.7950\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.0438 - acc: 0.7640\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 598us/step - loss: 0.0364 - acc: 0.8012\n",
            "81/81 [==============================] - 2s 30ms/step\n",
            "161/161 [==============================] - 0s 453us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 6s 36ms/step - loss: 1.0357 - acc: 0.5679\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 591us/step - loss: 0.5096 - acc: 0.7593\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 580us/step - loss: 0.4342 - acc: 0.7901\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 625us/step - loss: 0.4295 - acc: 0.8086\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.4086 - acc: 0.8086\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 739us/step - loss: 0.3801 - acc: 0.8272\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.3622 - acc: 0.8457\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 590us/step - loss: 0.3445 - acc: 0.8642\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 643us/step - loss: 0.3336 - acc: 0.8704\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 610us/step - loss: 0.3402 - acc: 0.8642\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 0.3298 - acc: 0.8333\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 0.3078 - acc: 0.8642\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 594us/step - loss: 0.3049 - acc: 0.8580\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.2949 - acc: 0.8704\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 602us/step - loss: 0.2935 - acc: 0.8580\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 577us/step - loss: 0.2751 - acc: 0.8519\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 579us/step - loss: 0.3007 - acc: 0.8457\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 571us/step - loss: 0.2772 - acc: 0.8704\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.2759 - acc: 0.8580\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.2579 - acc: 0.8704\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 658us/step - loss: 0.2587 - acc: 0.8333\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 620us/step - loss: 0.2514 - acc: 0.8457\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 572us/step - loss: 0.2397 - acc: 0.8519\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 655us/step - loss: 0.2276 - acc: 0.8272\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 609us/step - loss: 0.2273 - acc: 0.8148\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 596us/step - loss: 0.2153 - acc: 0.8210\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 643us/step - loss: 0.2126 - acc: 0.8148\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 584us/step - loss: 0.2039 - acc: 0.8210\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 609us/step - loss: 0.2013 - acc: 0.8025\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 588us/step - loss: 0.2023 - acc: 0.8272\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 625us/step - loss: 0.2130 - acc: 0.7963\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 593us/step - loss: 0.1893 - acc: 0.8457\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 609us/step - loss: 0.2041 - acc: 0.7654\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 0.1801 - acc: 0.7778\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 0.1757 - acc: 0.7778\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 613us/step - loss: 0.1693 - acc: 0.7716\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 640us/step - loss: 0.1642 - acc: 0.7901\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 618us/step - loss: 0.1664 - acc: 0.7840\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 599us/step - loss: 0.1694 - acc: 0.8086\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 595us/step - loss: 0.1661 - acc: 0.7654\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 583us/step - loss: 0.1489 - acc: 0.7778\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 605us/step - loss: 0.1470 - acc: 0.8025\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 590us/step - loss: 0.1539 - acc: 0.7531\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 680us/step - loss: 0.1498 - acc: 0.7654\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 586us/step - loss: 0.1257 - acc: 0.7716\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 577us/step - loss: 0.1211 - acc: 0.7840\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 559us/step - loss: 0.1154 - acc: 0.7716\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 554us/step - loss: 0.1205 - acc: 0.7963\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 564us/step - loss: 0.1167 - acc: 0.7654\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 583us/step - loss: 0.1423 - acc: 0.7469\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 577us/step - loss: 0.1351 - acc: 0.7840\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 566us/step - loss: 0.1043 - acc: 0.7654\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 580us/step - loss: 0.1043 - acc: 0.7469\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 573us/step - loss: 0.0956 - acc: 0.7654\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 576us/step - loss: 0.0963 - acc: 0.7654\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 590us/step - loss: 0.0913 - acc: 0.7593\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 588us/step - loss: 0.0854 - acc: 0.7654\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 602us/step - loss: 0.0793 - acc: 0.7531\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.0837 - acc: 0.7654\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 582us/step - loss: 0.0904 - acc: 0.7531\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 603us/step - loss: 0.0868 - acc: 0.7407\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 596us/step - loss: 0.0737 - acc: 0.7407\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 620us/step - loss: 0.0729 - acc: 0.7346\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 672us/step - loss: 0.0664 - acc: 0.7469\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 601us/step - loss: 0.0704 - acc: 0.7531\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 641us/step - loss: 0.0745 - acc: 0.7222\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 597us/step - loss: 0.0663 - acc: 0.7284\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 608us/step - loss: 0.0616 - acc: 0.7593\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 629us/step - loss: 0.0658 - acc: 0.7407\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 605us/step - loss: 0.0610 - acc: 0.7407\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 579us/step - loss: 0.0807 - acc: 0.7037\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.0646 - acc: 0.7284\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 644us/step - loss: 0.0597 - acc: 0.7346\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 637us/step - loss: 0.0527 - acc: 0.7346\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 627us/step - loss: 0.0581 - acc: 0.7346\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 611us/step - loss: 0.0566 - acc: 0.7222\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 644us/step - loss: 0.0537 - acc: 0.7222\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 579us/step - loss: 0.0579 - acc: 0.7284\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 648us/step - loss: 0.0607 - acc: 0.7099\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 599us/step - loss: 0.0530 - acc: 0.7099\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 656us/step - loss: 0.0602 - acc: 0.7160\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 617us/step - loss: 0.0804 - acc: 0.7160\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.0521 - acc: 0.7346\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 594us/step - loss: 0.0509 - acc: 0.7222\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 678us/step - loss: 0.0471 - acc: 0.6728\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 662us/step - loss: 0.0485 - acc: 0.6914\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 597us/step - loss: 0.0412 - acc: 0.7222\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 587us/step - loss: 0.0425 - acc: 0.7037\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 647us/step - loss: 0.0516 - acc: 0.7222\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 565us/step - loss: 0.0462 - acc: 0.7099\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 608us/step - loss: 0.0475 - acc: 0.6914\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 642us/step - loss: 0.0389 - acc: 0.7222\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.0412 - acc: 0.7160\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 657us/step - loss: 0.0449 - acc: 0.6914\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 604us/step - loss: 0.0368 - acc: 0.6975\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 670us/step - loss: 0.0349 - acc: 0.7037\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 638us/step - loss: 0.0368 - acc: 0.6914\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 621us/step - loss: 0.0348 - acc: 0.6975\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 636us/step - loss: 0.0367 - acc: 0.6852\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 589us/step - loss: 0.0350 - acc: 0.6790\n",
            "80/80 [==============================] - 2s 31ms/step\n",
            "162/162 [==============================] - 0s 454us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 6s 36ms/step - loss: 0.6527 - acc: 0.6025\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.4943 - acc: 0.7826\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.4346 - acc: 0.7950\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.4142 - acc: 0.8261\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 665us/step - loss: 0.4118 - acc: 0.7888\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.3715 - acc: 0.8261\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.3550 - acc: 0.8323\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 657us/step - loss: 0.3518 - acc: 0.8509\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.3474 - acc: 0.8447\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.3276 - acc: 0.8447\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.3180 - acc: 0.8634\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.3494 - acc: 0.8261\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.3166 - acc: 0.8571\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 590us/step - loss: 0.3015 - acc: 0.8571\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 691us/step - loss: 0.3215 - acc: 0.8509\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.3294 - acc: 0.8447\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.2890 - acc: 0.8509\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.3218 - acc: 0.8509\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.2940 - acc: 0.8385\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.2755 - acc: 0.8571\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 649us/step - loss: 0.2685 - acc: 0.8882\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.2720 - acc: 0.8509\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.2627 - acc: 0.8758\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.2598 - acc: 0.9068\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.2511 - acc: 0.8696\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.2500 - acc: 0.8758\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.2521 - acc: 0.8944\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 0.2485 - acc: 0.8820\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.2507 - acc: 0.8634\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.2431 - acc: 0.8758\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 595us/step - loss: 0.2424 - acc: 0.9006\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.2420 - acc: 0.8634\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.2200 - acc: 0.9130\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.2351 - acc: 0.8882\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.2105 - acc: 0.9068\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 605us/step - loss: 0.2082 - acc: 0.8820\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 653us/step - loss: 0.2039 - acc: 0.9006\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 0.2083 - acc: 0.8696\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.1904 - acc: 0.9130\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 575us/step - loss: 0.1974 - acc: 0.8882\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.1879 - acc: 0.9006\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.1926 - acc: 0.8758\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.1813 - acc: 0.8944\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 657us/step - loss: 0.1831 - acc: 0.8944\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.1752 - acc: 0.8820\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.1808 - acc: 0.8882\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.1675 - acc: 0.8820\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 717us/step - loss: 0.1599 - acc: 0.8820\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1785 - acc: 0.8509\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.1613 - acc: 0.8696\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.1549 - acc: 0.8509\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 655us/step - loss: 0.1506 - acc: 0.8882\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.1555 - acc: 0.8509\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.1386 - acc: 0.8323\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.1426 - acc: 0.8261\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.1392 - acc: 0.7826\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.1296 - acc: 0.8075\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.1274 - acc: 0.8199\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.2608 - acc: 0.7888\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.1477 - acc: 0.8137\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.1328 - acc: 0.8261\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.1272 - acc: 0.8323\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.1158 - acc: 0.8075\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1203 - acc: 0.7888\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.1195 - acc: 0.8261\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.1056 - acc: 0.8261\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.1035 - acc: 0.8199\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.0998 - acc: 0.8075\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.1027 - acc: 0.8075\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.0979 - acc: 0.7578\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.0994 - acc: 0.7764\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.0998 - acc: 0.7764\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 610us/step - loss: 0.1030 - acc: 0.7888\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 795us/step - loss: 0.1141 - acc: 0.7702\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.0935 - acc: 0.7764\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.0893 - acc: 0.8137\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.0838 - acc: 0.7826\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.0919 - acc: 0.7019\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.0834 - acc: 0.8075\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.0726 - acc: 0.7764\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.0796 - acc: 0.7702\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.0760 - acc: 0.7764\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.0729 - acc: 0.7826\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.0702 - acc: 0.7826\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.0738 - acc: 0.7578\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.0667 - acc: 0.7888\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.0723 - acc: 0.7702\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.0664 - acc: 0.7950\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.0622 - acc: 0.7640\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.0864 - acc: 0.7329\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.0636 - acc: 0.7267\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 698us/step - loss: 0.2010 - acc: 0.7578\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 713us/step - loss: 0.0742 - acc: 0.7391\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 605us/step - loss: 0.0867 - acc: 0.7081\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 596us/step - loss: 0.0684 - acc: 0.7764\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.0675 - acc: 0.7640\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 582us/step - loss: 0.0635 - acc: 0.7143\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.0717 - acc: 0.7453\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.0574 - acc: 0.7205\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.0459 - acc: 0.7764\n",
            "81/81 [==============================] - 2s 31ms/step\n",
            "161/161 [==============================] - 0s 478us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 6s 37ms/step - loss: 0.7119 - acc: 0.5590\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.5792 - acc: 0.7888\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.4392 - acc: 0.7329\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 700us/step - loss: 0.4861 - acc: 0.8261\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.3625 - acc: 0.8137\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.3473 - acc: 0.8075\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.3447 - acc: 0.7950\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.3275 - acc: 0.8385\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.3096 - acc: 0.8385\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.3086 - acc: 0.8323\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.3192 - acc: 0.8385\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 0.2944 - acc: 0.8509\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.3384 - acc: 0.8385\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.2708 - acc: 0.8385\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.2614 - acc: 0.8634\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.2537 - acc: 0.8758\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.2423 - acc: 0.8696\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.2398 - acc: 0.8696\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.2456 - acc: 0.8571\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 593us/step - loss: 0.2165 - acc: 0.8882\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.2408 - acc: 0.8571\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.2319 - acc: 0.8323\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.2114 - acc: 0.8820\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.2024 - acc: 0.8634\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 606us/step - loss: 0.1983 - acc: 0.8696\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.1939 - acc: 0.8758\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.1881 - acc: 0.8571\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.1851 - acc: 0.8820\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1758 - acc: 0.8509\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.1802 - acc: 0.8571\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.1763 - acc: 0.8758\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1680 - acc: 0.8634\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.1678 - acc: 0.8571\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 598us/step - loss: 0.1602 - acc: 0.8882\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.1514 - acc: 0.8820\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1522 - acc: 0.8447\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.1515 - acc: 0.8758\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 572us/step - loss: 0.1480 - acc: 0.8634\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.1429 - acc: 0.8261\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.1329 - acc: 0.8447\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.1193 - acc: 0.8820\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.1351 - acc: 0.8447\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 705us/step - loss: 0.1216 - acc: 0.8571\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.1102 - acc: 0.8696\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1108 - acc: 0.8323\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 606us/step - loss: 0.1139 - acc: 0.8385\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.1012 - acc: 0.8447\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.0990 - acc: 0.8447\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.0959 - acc: 0.8385\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.0932 - acc: 0.8447\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.0949 - acc: 0.8447\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.0923 - acc: 0.8385\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.0921 - acc: 0.8571\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 704us/step - loss: 0.1002 - acc: 0.7826\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.0791 - acc: 0.8696\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.0814 - acc: 0.8199\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 584us/step - loss: 0.0764 - acc: 0.8323\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.0728 - acc: 0.8447\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.0695 - acc: 0.8385\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 665us/step - loss: 0.0649 - acc: 0.8261\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 605us/step - loss: 0.0692 - acc: 0.8385\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 688us/step - loss: 0.0622 - acc: 0.8012\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.0591 - acc: 0.8199\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.0613 - acc: 0.8075\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 729us/step - loss: 0.0549 - acc: 0.8012\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.0618 - acc: 0.8261\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.0509 - acc: 0.8323\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.0495 - acc: 0.8323\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.0758 - acc: 0.7826\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.0593 - acc: 0.7888\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.0529 - acc: 0.8012\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.0413 - acc: 0.8012\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 581us/step - loss: 0.0388 - acc: 0.8137\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.0439 - acc: 0.8385\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.0371 - acc: 0.8199\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 624us/step - loss: 0.0374 - acc: 0.7950\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.0375 - acc: 0.7702\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 610us/step - loss: 0.0321 - acc: 0.7950\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.0357 - acc: 0.7453\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.0297 - acc: 0.7516\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.0299 - acc: 0.7888\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 688us/step - loss: 0.0367 - acc: 0.7702\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 0.0449 - acc: 0.7578\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.0277 - acc: 0.7640\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 0.0340 - acc: 0.7888\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.0262 - acc: 0.7205\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.0195 - acc: 0.7391\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.0232 - acc: 0.7950\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 593us/step - loss: 0.0237 - acc: 0.7391\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.0228 - acc: 0.7516\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 0.0214 - acc: 0.7453\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 607us/step - loss: 0.0179 - acc: 0.7267\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.0189 - acc: 0.7453\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.0125 - acc: 0.7640\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.0162 - acc: 0.7391\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.0160 - acc: 0.7516\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.0194 - acc: 0.7267\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.0133 - acc: 0.7391\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.0126 - acc: 0.7453\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.0152 - acc: 0.7267\n",
            "81/81 [==============================] - 3s 31ms/step\n",
            "161/161 [==============================] - 0s 472us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 6s 37ms/step - loss: 0.8447 - acc: 0.5741\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 622us/step - loss: 0.5945 - acc: 0.6790\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 587us/step - loss: 0.5180 - acc: 0.7593\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.4554 - acc: 0.7716\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 591us/step - loss: 0.4167 - acc: 0.8086\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 654us/step - loss: 0.3809 - acc: 0.8395\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.3664 - acc: 0.8272\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 586us/step - loss: 0.3420 - acc: 0.8086\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 637us/step - loss: 0.3328 - acc: 0.8086\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 702us/step - loss: 0.3186 - acc: 0.8210\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 765us/step - loss: 0.3152 - acc: 0.8210\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 592us/step - loss: 0.2952 - acc: 0.8272\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 611us/step - loss: 0.4766 - acc: 0.8025\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 633us/step - loss: 0.2928 - acc: 0.8457\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 580us/step - loss: 0.2880 - acc: 0.8333\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 575us/step - loss: 0.2663 - acc: 0.8210\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 591us/step - loss: 0.2860 - acc: 0.7901\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 597us/step - loss: 0.2804 - acc: 0.8333\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.2566 - acc: 0.8395\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 609us/step - loss: 0.2612 - acc: 0.8148\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 632us/step - loss: 0.2413 - acc: 0.8086\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 634us/step - loss: 0.2337 - acc: 0.8272\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 606us/step - loss: 0.2420 - acc: 0.8210\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 636us/step - loss: 0.2526 - acc: 0.8272\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 577us/step - loss: 0.2455 - acc: 0.7963\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 626us/step - loss: 0.2266 - acc: 0.8025\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 576us/step - loss: 0.2245 - acc: 0.8025\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 595us/step - loss: 0.2176 - acc: 0.8272\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.2235 - acc: 0.7840\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 754us/step - loss: 0.2021 - acc: 0.8025\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 585us/step - loss: 0.2059 - acc: 0.8025\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.2045 - acc: 0.7840\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 627us/step - loss: 0.2144 - acc: 0.7778\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.1895 - acc: 0.7901\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 622us/step - loss: 0.1899 - acc: 0.8148\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 598us/step - loss: 0.1842 - acc: 0.7901\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 622us/step - loss: 0.1765 - acc: 0.8025\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 608us/step - loss: 0.1847 - acc: 0.7840\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 639us/step - loss: 0.1685 - acc: 0.8148\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 623us/step - loss: 0.1592 - acc: 0.8086\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 0.1584 - acc: 0.8025\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 605us/step - loss: 0.1600 - acc: 0.7778\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 578us/step - loss: 0.1548 - acc: 0.7531\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 613us/step - loss: 0.1474 - acc: 0.7901\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 613us/step - loss: 0.1520 - acc: 0.7654\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 611us/step - loss: 0.1420 - acc: 0.7654\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.1468 - acc: 0.7778\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 635us/step - loss: 0.1326 - acc: 0.7531\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 604us/step - loss: 0.1289 - acc: 0.7593\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 711us/step - loss: 0.1295 - acc: 0.7593\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 0.1275 - acc: 0.7284\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 609us/step - loss: 0.1264 - acc: 0.7654\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 598us/step - loss: 0.1182 - acc: 0.7346\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 675us/step - loss: 0.1169 - acc: 0.7531\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 626us/step - loss: 0.1282 - acc: 0.7160\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 598us/step - loss: 0.1237 - acc: 0.7346\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 622us/step - loss: 0.1518 - acc: 0.7346\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 564us/step - loss: 0.1337 - acc: 0.7654\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 605us/step - loss: 0.1193 - acc: 0.7531\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.1045 - acc: 0.7346\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 616us/step - loss: 0.1175 - acc: 0.6975\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 648us/step - loss: 0.0990 - acc: 0.7160\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 603us/step - loss: 0.0968 - acc: 0.7222\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 637us/step - loss: 0.0923 - acc: 0.7160\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 593us/step - loss: 0.0888 - acc: 0.7222\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 606us/step - loss: 0.1042 - acc: 0.7037\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.0897 - acc: 0.6790\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 737us/step - loss: 0.0801 - acc: 0.6914\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 646us/step - loss: 0.0927 - acc: 0.6667\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 609us/step - loss: 0.0817 - acc: 0.6975\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 593us/step - loss: 0.0819 - acc: 0.6914\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 677us/step - loss: 0.0810 - acc: 0.6975\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.0776 - acc: 0.6975\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.0745 - acc: 0.7099\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.0800 - acc: 0.6728\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 633us/step - loss: 0.0753 - acc: 0.6790\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.0695 - acc: 0.6852\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 629us/step - loss: 0.0724 - acc: 0.6667\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 603us/step - loss: 0.0640 - acc: 0.7037\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 638us/step - loss: 0.0781 - acc: 0.6543\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 659us/step - loss: 0.0795 - acc: 0.6975\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 596us/step - loss: 0.0669 - acc: 0.6667\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 594us/step - loss: 0.0640 - acc: 0.6296\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 669us/step - loss: 0.0635 - acc: 0.6543\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 593us/step - loss: 0.0639 - acc: 0.6358\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 645us/step - loss: 0.0664 - acc: 0.6173\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.0560 - acc: 0.6358\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 0.0639 - acc: 0.6481\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 617us/step - loss: 0.0542 - acc: 0.6605\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 599us/step - loss: 0.0599 - acc: 0.6481\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.0553 - acc: 0.6358\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 605us/step - loss: 0.0528 - acc: 0.6543\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 585us/step - loss: 0.0513 - acc: 0.6728\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 592us/step - loss: 0.0505 - acc: 0.6543\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 646us/step - loss: 0.0456 - acc: 0.6420\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.0473 - acc: 0.6296\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.0488 - acc: 0.6049\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 623us/step - loss: 0.0441 - acc: 0.6296\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 586us/step - loss: 0.0605 - acc: 0.6358\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 615us/step - loss: 0.0389 - acc: 0.6358\n",
            "80/80 [==============================] - 3s 32ms/step\n",
            "162/162 [==============================] - 0s 532us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 6s 38ms/step - loss: 0.8455 - acc: 0.5590\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.7123 - acc: 0.5590\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.6113 - acc: 0.6894\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.5775 - acc: 0.7081\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.5488 - acc: 0.7329\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 598us/step - loss: 0.5170 - acc: 0.7578\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 706us/step - loss: 0.4920 - acc: 0.7640\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 655us/step - loss: 0.4772 - acc: 0.7640\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.4329 - acc: 0.7888\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.4067 - acc: 0.8137\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.3862 - acc: 0.8137\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.3716 - acc: 0.8261\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.3469 - acc: 0.8261\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 687us/step - loss: 0.3366 - acc: 0.8509\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.3238 - acc: 0.8447\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.3266 - acc: 0.8509\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 704us/step - loss: 0.3122 - acc: 0.8323\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.3043 - acc: 0.8571\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.2987 - acc: 0.8323\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.2987 - acc: 0.8323\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.3268 - acc: 0.8509\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.4478 - acc: 0.7950\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.3790 - acc: 0.8634\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.3551 - acc: 0.8696\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 738us/step - loss: 0.3554 - acc: 0.8758\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 607us/step - loss: 0.3435 - acc: 0.8696\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.3564 - acc: 0.8447\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.3553 - acc: 0.8509\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.3346 - acc: 0.8571\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.3316 - acc: 0.8696\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 0.3249 - acc: 0.8882\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 624us/step - loss: 0.3193 - acc: 0.8696\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.3363 - acc: 0.8696\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 684us/step - loss: 0.3139 - acc: 0.8758\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.3206 - acc: 0.8696\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 732us/step - loss: 0.3033 - acc: 0.8882\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.2994 - acc: 0.9006\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.2976 - acc: 0.8820\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 598us/step - loss: 0.2934 - acc: 0.8696\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.3087 - acc: 0.8634\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.2903 - acc: 0.8758\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 599us/step - loss: 0.3277 - acc: 0.8447\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.2799 - acc: 0.8758\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.2755 - acc: 0.8882\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.2727 - acc: 0.8634\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.2762 - acc: 0.8447\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.2685 - acc: 0.8758\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.2670 - acc: 0.8509\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.2611 - acc: 0.8385\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.2605 - acc: 0.8323\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 615us/step - loss: 0.2582 - acc: 0.8323\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 690us/step - loss: 0.2619 - acc: 0.8447\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 587us/step - loss: 0.2429 - acc: 0.8509\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.2394 - acc: 0.8385\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.2362 - acc: 0.8509\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 610us/step - loss: 0.2452 - acc: 0.8323\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.2323 - acc: 0.8261\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.2254 - acc: 0.8323\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 599us/step - loss: 0.2274 - acc: 0.8261\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.2286 - acc: 0.8012\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.2312 - acc: 0.8137\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.2245 - acc: 0.8137\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.2147 - acc: 0.8137\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 615us/step - loss: 0.2276 - acc: 0.7764\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.2131 - acc: 0.8012\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.2061 - acc: 0.8137\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 680us/step - loss: 0.2055 - acc: 0.8137\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.2085 - acc: 0.8075\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 615us/step - loss: 0.2011 - acc: 0.8075\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 610us/step - loss: 0.2182 - acc: 0.7764\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 585us/step - loss: 0.2026 - acc: 0.7764\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.1982 - acc: 0.7950\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 737us/step - loss: 0.1959 - acc: 0.7888\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.1953 - acc: 0.8012\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 0.1883 - acc: 0.7950\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.2021 - acc: 0.7702\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.1864 - acc: 0.8012\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 702us/step - loss: 0.1848 - acc: 0.7888\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.1815 - acc: 0.8012\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 0.1866 - acc: 0.7578\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.1874 - acc: 0.7640\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.1741 - acc: 0.7702\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.1735 - acc: 0.7826\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.1759 - acc: 0.7578\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.1669 - acc: 0.7453\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 708us/step - loss: 0.1844 - acc: 0.7267\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.1933 - acc: 0.7329\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.1718 - acc: 0.7267\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.1689 - acc: 0.7453\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.1614 - acc: 0.7516\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.1605 - acc: 0.7329\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.1585 - acc: 0.7391\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1584 - acc: 0.7267\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 665us/step - loss: 0.1610 - acc: 0.7143\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.1577 - acc: 0.7081\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.1511 - acc: 0.7267\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 607us/step - loss: 0.1522 - acc: 0.7143\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 594us/step - loss: 0.1479 - acc: 0.7267\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.1501 - acc: 0.7391\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 576us/step - loss: 0.1510 - acc: 0.7329\n",
            "81/81 [==============================] - 3s 32ms/step\n",
            "161/161 [==============================] - 0s 469us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 6s 38ms/step - loss: 0.6136 - acc: 0.6894\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.5010 - acc: 0.7578\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.4501 - acc: 0.8075\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.4189 - acc: 0.8012\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 649us/step - loss: 0.4752 - acc: 0.8323\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.5115 - acc: 0.8199\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.5601 - acc: 0.8571\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.5418 - acc: 0.8447\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 816us/step - loss: 0.5333 - acc: 0.8447\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.5238 - acc: 0.8571\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.5119 - acc: 0.8758\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.5019 - acc: 0.8509\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.5363 - acc: 0.8634\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.4983 - acc: 0.8758\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.4877 - acc: 0.8447\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.4785 - acc: 0.8509\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 744us/step - loss: 0.4745 - acc: 0.8696\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.4694 - acc: 0.7950\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.4712 - acc: 0.8137\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.4602 - acc: 0.8199\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 693us/step - loss: 0.4839 - acc: 0.8447\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.4599 - acc: 0.8509\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.4463 - acc: 0.7764\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.4348 - acc: 0.8323\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.4394 - acc: 0.7950\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.4375 - acc: 0.8385\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.4267 - acc: 0.8012\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.4225 - acc: 0.8137\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.4254 - acc: 0.8199\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.4406 - acc: 0.7888\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.4168 - acc: 0.8199\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.4059 - acc: 0.7702\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.4037 - acc: 0.8075\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.3984 - acc: 0.7702\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.3916 - acc: 0.8075\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.3987 - acc: 0.7453\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.3878 - acc: 0.7826\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.3828 - acc: 0.7516\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.3859 - acc: 0.7578\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 731us/step - loss: 0.3739 - acc: 0.7391\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.3791 - acc: 0.7640\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.3739 - acc: 0.7453\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.3707 - acc: 0.7391\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.3680 - acc: 0.7391\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.3728 - acc: 0.7453\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 679us/step - loss: 0.3749 - acc: 0.7329\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.3617 - acc: 0.7391\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.3532 - acc: 0.7205\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.3533 - acc: 0.7267\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.3517 - acc: 0.7267\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.3580 - acc: 0.7329\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.3452 - acc: 0.7205\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.3511 - acc: 0.7205\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.3523 - acc: 0.6957\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 665us/step - loss: 0.3487 - acc: 0.7143\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 694us/step - loss: 0.3542 - acc: 0.6770\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.3469 - acc: 0.7205\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.3372 - acc: 0.7019\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 649us/step - loss: 0.3345 - acc: 0.7019\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.3393 - acc: 0.7081\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.3351 - acc: 0.6832\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.3320 - acc: 0.6894\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.3305 - acc: 0.7081\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 686us/step - loss: 0.3224 - acc: 0.7019\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.3217 - acc: 0.7019\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.3191 - acc: 0.7143\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 649us/step - loss: 0.3341 - acc: 0.6460\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.3212 - acc: 0.7019\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.3172 - acc: 0.6832\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 649us/step - loss: 0.3167 - acc: 0.6770\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.3164 - acc: 0.6460\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.3155 - acc: 0.6646\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 0.3130 - acc: 0.6708\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.3108 - acc: 0.6708\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 714us/step - loss: 0.3135 - acc: 0.6460\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 751us/step - loss: 0.3103 - acc: 0.6770\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.3134 - acc: 0.6398\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.3100 - acc: 0.6460\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 684us/step - loss: 0.3131 - acc: 0.6398\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.3087 - acc: 0.6522\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 599us/step - loss: 0.3079 - acc: 0.6149\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 615us/step - loss: 0.3054 - acc: 0.6087\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.3067 - acc: 0.6149\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.3050 - acc: 0.6273\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.3229 - acc: 0.6025\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.3254 - acc: 0.6087\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.3101 - acc: 0.6211\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.3067 - acc: 0.5776\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 615us/step - loss: 0.3036 - acc: 0.6522\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.3032 - acc: 0.5963\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.3017 - acc: 0.5963\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.3027 - acc: 0.6087\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.3016 - acc: 0.5963\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.3023 - acc: 0.5901\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.3093 - acc: 0.6025\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 697us/step - loss: 0.3027 - acc: 0.5963\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 709us/step - loss: 0.3012 - acc: 0.6025\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.3001 - acc: 0.6149\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.2993 - acc: 0.6025\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.3000 - acc: 0.5776\n",
            "81/81 [==============================] - 3s 32ms/step\n",
            "161/161 [==============================] - 0s 485us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 6s 38ms/step - loss: 2.2183 - acc: 0.4444\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 610us/step - loss: 0.6941 - acc: 0.5432\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 605us/step - loss: 0.5998 - acc: 0.7160\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.5143 - acc: 0.7778\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 648us/step - loss: 0.5625 - acc: 0.7840\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 633us/step - loss: 0.4490 - acc: 0.8148\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 618us/step - loss: 0.5764 - acc: 0.7963\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 0.4798 - acc: 0.8148\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.5693 - acc: 0.8148\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 629us/step - loss: 0.4446 - acc: 0.8519\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 634us/step - loss: 0.4369 - acc: 0.8519\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 595us/step - loss: 0.4994 - acc: 0.8519\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 652us/step - loss: 0.5355 - acc: 0.8519\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.4304 - acc: 0.8333\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.4078 - acc: 0.8519\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 613us/step - loss: 0.3875 - acc: 0.8642\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.3785 - acc: 0.8395\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 618us/step - loss: 0.3696 - acc: 0.8519\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 0.3668 - acc: 0.8519\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 585us/step - loss: 0.3541 - acc: 0.8519\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 635us/step - loss: 0.3477 - acc: 0.8210\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 731us/step - loss: 0.3482 - acc: 0.8272\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 617us/step - loss: 0.3538 - acc: 0.8457\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 646us/step - loss: 0.3336 - acc: 0.8148\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 0.3227 - acc: 0.8086\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 606us/step - loss: 0.3284 - acc: 0.7901\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 627us/step - loss: 0.3243 - acc: 0.7963\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 652us/step - loss: 0.3140 - acc: 0.8148\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 651us/step - loss: 0.3063 - acc: 0.8086\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 634us/step - loss: 0.2935 - acc: 0.7901\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 622us/step - loss: 0.2935 - acc: 0.7654\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.2796 - acc: 0.7963\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 645us/step - loss: 0.2780 - acc: 0.8086\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 638us/step - loss: 0.2734 - acc: 0.8025\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 608us/step - loss: 0.2734 - acc: 0.8025\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 591us/step - loss: 0.2723 - acc: 0.7963\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 701us/step - loss: 0.2656 - acc: 0.7901\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 636us/step - loss: 0.2701 - acc: 0.7963\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 716us/step - loss: 0.2545 - acc: 0.8025\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 636us/step - loss: 0.2571 - acc: 0.7716\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 673us/step - loss: 0.2451 - acc: 0.8086\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.2475 - acc: 0.7778\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 659us/step - loss: 0.2436 - acc: 0.7901\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.2361 - acc: 0.7901\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 635us/step - loss: 0.2343 - acc: 0.7963\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 671us/step - loss: 0.2357 - acc: 0.7901\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 629us/step - loss: 0.2366 - acc: 0.7901\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 658us/step - loss: 0.2240 - acc: 0.7840\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.2201 - acc: 0.7654\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.2288 - acc: 0.8086\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.2079 - acc: 0.7840\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 616us/step - loss: 0.2050 - acc: 0.7840\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 651us/step - loss: 0.2049 - acc: 0.7716\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 621us/step - loss: 0.1923 - acc: 0.7654\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.2027 - acc: 0.7778\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 610us/step - loss: 0.1922 - acc: 0.7654\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.1865 - acc: 0.7531\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 691us/step - loss: 0.1873 - acc: 0.7469\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 610us/step - loss: 0.1817 - acc: 0.7531\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 666us/step - loss: 0.1779 - acc: 0.7469\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 626us/step - loss: 0.1728 - acc: 0.7469\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 616us/step - loss: 0.1740 - acc: 0.7284\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 629us/step - loss: 0.1708 - acc: 0.7407\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 605us/step - loss: 0.1661 - acc: 0.7346\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 636us/step - loss: 0.1647 - acc: 0.7469\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.1610 - acc: 0.7593\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 602us/step - loss: 0.1587 - acc: 0.7346\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.1699 - acc: 0.7160\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 670us/step - loss: 0.1662 - acc: 0.7407\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 615us/step - loss: 0.1680 - acc: 0.7160\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 648us/step - loss: 0.1559 - acc: 0.7284\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 703us/step - loss: 0.1553 - acc: 0.7346\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 637us/step - loss: 0.1541 - acc: 0.7407\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 637us/step - loss: 0.1524 - acc: 0.7037\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 622us/step - loss: 0.1680 - acc: 0.7099\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 601us/step - loss: 0.1565 - acc: 0.6852\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 750us/step - loss: 0.1494 - acc: 0.7160\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 639us/step - loss: 0.1451 - acc: 0.7284\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 664us/step - loss: 0.1549 - acc: 0.7222\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.1443 - acc: 0.7037\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 620us/step - loss: 0.1420 - acc: 0.7099\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 0.1426 - acc: 0.6975\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.1398 - acc: 0.6790\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 666us/step - loss: 0.1439 - acc: 0.7160\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 623us/step - loss: 0.1422 - acc: 0.6914\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.1434 - acc: 0.6728\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 621us/step - loss: 0.1420 - acc: 0.7099\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 643us/step - loss: 0.1409 - acc: 0.6852\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 0.1383 - acc: 0.7160\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.1370 - acc: 0.6790\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 610us/step - loss: 0.1407 - acc: 0.7160\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 634us/step - loss: 0.1366 - acc: 0.6852\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 634us/step - loss: 0.1347 - acc: 0.6852\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 654us/step - loss: 0.1361 - acc: 0.7099\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.1329 - acc: 0.6728\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 650us/step - loss: 0.1368 - acc: 0.6543\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 673us/step - loss: 0.1463 - acc: 0.7222\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 771us/step - loss: 0.1370 - acc: 0.6728\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 604us/step - loss: 0.1381 - acc: 0.6481\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 626us/step - loss: 0.1338 - acc: 0.6728\n",
            "80/80 [==============================] - 3s 33ms/step\n",
            "162/162 [==============================] - 0s 509us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 6s 26ms/step - loss: 2.1200 - acc: 0.5702\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 698us/step - loss: 0.5323 - acc: 0.7397\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 610us/step - loss: 0.5091 - acc: 0.7975\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 626us/step - loss: 0.4594 - acc: 0.7975\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 609us/step - loss: 0.4541 - acc: 0.8182\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 652us/step - loss: 0.5004 - acc: 0.8264\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 633us/step - loss: 0.4307 - acc: 0.8182\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 615us/step - loss: 0.4132 - acc: 0.8430\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 636us/step - loss: 0.3953 - acc: 0.8512\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 606us/step - loss: 0.3557 - acc: 0.8264\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 654us/step - loss: 0.3957 - acc: 0.8347\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 662us/step - loss: 0.3750 - acc: 0.8595\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 631us/step - loss: 0.3741 - acc: 0.8512\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 658us/step - loss: 0.4114 - acc: 0.8802\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 681us/step - loss: 0.3459 - acc: 0.8760\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 636us/step - loss: 0.3408 - acc: 0.8512\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 624us/step - loss: 0.3685 - acc: 0.8843\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 637us/step - loss: 0.3841 - acc: 0.8884\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 633us/step - loss: 0.3592 - acc: 0.8388\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 692us/step - loss: 0.2970 - acc: 0.8760\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 633us/step - loss: 0.4581 - acc: 0.8430\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 629us/step - loss: 0.4246 - acc: 0.8223\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 625us/step - loss: 0.3934 - acc: 0.8223\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 644us/step - loss: 0.3280 - acc: 0.8512\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 612us/step - loss: 0.2929 - acc: 0.8554\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 624us/step - loss: 0.2748 - acc: 0.8554\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 732us/step - loss: 0.2669 - acc: 0.8636\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 719us/step - loss: 0.2573 - acc: 0.8554\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 654us/step - loss: 0.2498 - acc: 0.8471\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 621us/step - loss: 0.2433 - acc: 0.8554\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 606us/step - loss: 0.2387 - acc: 0.8636\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 661us/step - loss: 0.2347 - acc: 0.8306\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 640us/step - loss: 0.2306 - acc: 0.8595\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 619us/step - loss: 0.2253 - acc: 0.8347\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 624us/step - loss: 0.2243 - acc: 0.8430\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 641us/step - loss: 0.2153 - acc: 0.8388\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 616us/step - loss: 0.2200 - acc: 0.8554\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 616us/step - loss: 0.2095 - acc: 0.8430\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 629us/step - loss: 0.2031 - acc: 0.8471\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 715us/step - loss: 0.2014 - acc: 0.8512\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 595us/step - loss: 0.1989 - acc: 0.8512\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 615us/step - loss: 0.1965 - acc: 0.8388\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 606us/step - loss: 0.1921 - acc: 0.8554\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 612us/step - loss: 0.1949 - acc: 0.8347\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 658us/step - loss: 0.1834 - acc: 0.8471\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 637us/step - loss: 0.1781 - acc: 0.8512\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 718us/step - loss: 0.1766 - acc: 0.8554\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 651us/step - loss: 0.1729 - acc: 0.8471\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 700us/step - loss: 0.1710 - acc: 0.8512\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 687us/step - loss: 0.1691 - acc: 0.8554\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 644us/step - loss: 0.1642 - acc: 0.8678\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 709us/step - loss: 0.1628 - acc: 0.8678\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 633us/step - loss: 0.1631 - acc: 0.8595\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 644us/step - loss: 0.1577 - acc: 0.8471\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 650us/step - loss: 0.1592 - acc: 0.8554\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 649us/step - loss: 0.1563 - acc: 0.8678\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 609us/step - loss: 0.1633 - acc: 0.8802\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 642us/step - loss: 0.1492 - acc: 0.8636\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 643us/step - loss: 0.1383 - acc: 0.8388\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 600us/step - loss: 0.1389 - acc: 0.8554\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 628us/step - loss: 0.1395 - acc: 0.8554\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 699us/step - loss: 0.1401 - acc: 0.8430\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 626us/step - loss: 0.1387 - acc: 0.8430\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 627us/step - loss: 0.1395 - acc: 0.8471\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 701us/step - loss: 0.1299 - acc: 0.8719\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 640us/step - loss: 0.1404 - acc: 0.8554\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 632us/step - loss: 0.1315 - acc: 0.8306\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 613us/step - loss: 0.1228 - acc: 0.8595\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 654us/step - loss: 0.1183 - acc: 0.8430\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 616us/step - loss: 0.1189 - acc: 0.8347\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 652us/step - loss: 0.1096 - acc: 0.8471\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 630us/step - loss: 0.1155 - acc: 0.8430\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 631us/step - loss: 0.1177 - acc: 0.8430\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 650us/step - loss: 0.1127 - acc: 0.8058\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 642us/step - loss: 0.1076 - acc: 0.8595\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 659us/step - loss: 0.1062 - acc: 0.8182\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 741us/step - loss: 0.1043 - acc: 0.8430\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 687us/step - loss: 0.1103 - acc: 0.8058\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 627us/step - loss: 0.0995 - acc: 0.8306\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 652us/step - loss: 0.1007 - acc: 0.8388\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 610us/step - loss: 0.0963 - acc: 0.8140\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 649us/step - loss: 0.0895 - acc: 0.8347\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 635us/step - loss: 0.1012 - acc: 0.8182\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 672us/step - loss: 0.0982 - acc: 0.8099\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 663us/step - loss: 0.0933 - acc: 0.8140\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 655us/step - loss: 0.0950 - acc: 0.7851\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 625us/step - loss: 0.0887 - acc: 0.7851\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 708us/step - loss: 0.0878 - acc: 0.7851\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 637us/step - loss: 0.0902 - acc: 0.8182\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 646us/step - loss: 0.0886 - acc: 0.7686\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 717us/step - loss: 0.0923 - acc: 0.8099\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 607us/step - loss: 0.0851 - acc: 0.7686\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 618us/step - loss: 0.0759 - acc: 0.7686\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 637us/step - loss: 0.0856 - acc: 0.7479\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 606us/step - loss: 0.0801 - acc: 0.7851\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 638us/step - loss: 0.0776 - acc: 0.7397\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 648us/step - loss: 0.0715 - acc: 0.7645\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 609us/step - loss: 0.0734 - acc: 0.7645\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 616us/step - loss: 0.0820 - acc: 0.7686\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 611us/step - loss: 0.0741 - acc: 0.7686\n",
            "Best: 0.549587 using {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3CV2tsJxgLnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 24143
        },
        "outputId": "ca6f9d16-999f-433c-9f9b-89b2ddfd8a5f"
      },
      "cell_type": "code",
      "source": [
        "# This one will tune my optimizers. \n",
        "inits = ['normal']\n",
        "optimizers = ['rmsprop', 'adam']\n",
        "activations = [\"relu\"]\n",
        "epochs = [100]\n",
        "batches = [5]\n",
        "\n",
        "def baseline(optimizer = \"adam\", init = \"uniform\", activation='relu'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(39, input_dim=X.shape[1], activation=activation))\n",
        "  model.add(Dense(39, activation=activation))\n",
        "  model.add(Dense(1, activation=activation))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=baseline, verbose = 1)\n",
        "\n",
        "param_grid = dict(optimizer=optimizers, activation=activations, epochs=epochs, batch_size=batches, init=inits)\n",
        "print(param_grid)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, )\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'optimizer': ['rmsprop', 'adam'], 'activation': ['relu'], 'epochs': [100], 'batch_size': [5], 'init': ['normal']}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "161/161 [==============================] - 8s 49ms/step - loss: 1.5479 - acc: 0.5776\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.5085 - acc: 0.7826\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 591us/step - loss: 0.5102 - acc: 0.7764\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.4815 - acc: 0.7950\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.3863 - acc: 0.8012\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.6103 - acc: 0.8137\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 707us/step - loss: 0.5400 - acc: 0.8261\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 695us/step - loss: 0.4591 - acc: 0.8075\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.4194 - acc: 0.8137\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.4415 - acc: 0.8261\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.4139 - acc: 0.8571\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.4974 - acc: 0.8323\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.4930 - acc: 0.8075\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.3930 - acc: 0.8137\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.3800 - acc: 0.8634\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.4470 - acc: 0.8199\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 730us/step - loss: 0.3932 - acc: 0.8634\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.3537 - acc: 0.8385\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 596us/step - loss: 0.4419 - acc: 0.8323\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 680us/step - loss: 0.4533 - acc: 0.8385\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.3692 - acc: 0.8509\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.3351 - acc: 0.8323\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 0.4233 - acc: 0.8696\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.4093 - acc: 0.8261\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.3398 - acc: 0.8696\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.3333 - acc: 0.8696\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 0.3229 - acc: 0.8882\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.3166 - acc: 0.8758\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.3120 - acc: 0.8634\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.2920 - acc: 0.9068\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.3778 - acc: 0.8696\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.3128 - acc: 0.8447\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.2869 - acc: 0.9006\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.2770 - acc: 0.8758\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.2768 - acc: 0.8634\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.2756 - acc: 0.8509\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.2729 - acc: 0.8261\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.3552 - acc: 0.8075\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.3415 - acc: 0.7702\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.3527 - acc: 0.7640\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.3362 - acc: 0.7578\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.2451 - acc: 0.7888\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 659us/step - loss: 0.3333 - acc: 0.7267\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 602us/step - loss: 0.3565 - acc: 0.7826\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.2523 - acc: 0.7888\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.2299 - acc: 0.8012\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 594us/step - loss: 0.2339 - acc: 0.7950\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.2392 - acc: 0.7764\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.2202 - acc: 0.7702\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.3145 - acc: 0.7764\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 737us/step - loss: 0.3222 - acc: 0.6957\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.3058 - acc: 0.7143\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 698us/step - loss: 0.2224 - acc: 0.7081\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.2269 - acc: 0.7578\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.2119 - acc: 0.7516\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.2145 - acc: 0.7578\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.1992 - acc: 0.7764\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.2094 - acc: 0.7391\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.1941 - acc: 0.7329\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1996 - acc: 0.7267\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.2071 - acc: 0.7081\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.1929 - acc: 0.7081\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 610us/step - loss: 0.1893 - acc: 0.6770\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.1935 - acc: 0.6957\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.1845 - acc: 0.6770\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.2003 - acc: 0.6646\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.1794 - acc: 0.6957\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.1798 - acc: 0.7143\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 653us/step - loss: 0.1782 - acc: 0.6894\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.1620 - acc: 0.6894\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.1765 - acc: 0.6832\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 653us/step - loss: 0.1703 - acc: 0.6708\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.1683 - acc: 0.6894\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.1748 - acc: 0.6832\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 606us/step - loss: 0.1664 - acc: 0.6522\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.1633 - acc: 0.6770\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.1535 - acc: 0.6770\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.1697 - acc: 0.6646\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 621us/step - loss: 0.1604 - acc: 0.6708\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.1596 - acc: 0.6335\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1639 - acc: 0.6894\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.1549 - acc: 0.6522\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 657us/step - loss: 0.1470 - acc: 0.6708\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.1511 - acc: 0.6273\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1563 - acc: 0.6708\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.1446 - acc: 0.6460\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.1439 - acc: 0.6770\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 607us/step - loss: 0.1436 - acc: 0.6460\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.1413 - acc: 0.6522\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.1499 - acc: 0.6335\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.1305 - acc: 0.6335\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 714us/step - loss: 0.1436 - acc: 0.6398\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.1395 - acc: 0.6522\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.1327 - acc: 0.6398\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.1334 - acc: 0.6522\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 737us/step - loss: 0.1333 - acc: 0.6522\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.1401 - acc: 0.6335\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.1501 - acc: 0.6087\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.1273 - acc: 0.6522\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.1358 - acc: 0.6398\n",
            "81/81 [==============================] - 3s 34ms/step\n",
            "161/161 [==============================] - 0s 476us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 6s 40ms/step - loss: 1.0456 - acc: 0.4534\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 597us/step - loss: 0.6215 - acc: 0.6273\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.5663 - acc: 0.7453\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.5055 - acc: 0.7764\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 615us/step - loss: 0.4883 - acc: 0.7950\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.4653 - acc: 0.8261\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.3540 - acc: 0.8634\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.3752 - acc: 0.8261\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.4077 - acc: 0.8385\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.4169 - acc: 0.8509\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.3928 - acc: 0.8199\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.3140 - acc: 0.8634\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.2993 - acc: 0.8571\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 692us/step - loss: 0.4794 - acc: 0.8571\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.3079 - acc: 0.8758\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 609us/step - loss: 0.2940 - acc: 0.8882\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.3200 - acc: 0.8758\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.2740 - acc: 0.8882\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.2892 - acc: 0.8820\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.2877 - acc: 0.8882\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.2792 - acc: 0.8820\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.2670 - acc: 0.8944\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.3360 - acc: 0.8509\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.3210 - acc: 0.8634\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 692us/step - loss: 0.3333 - acc: 0.8696\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 616us/step - loss: 0.2503 - acc: 0.8634\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 610us/step - loss: 0.2393 - acc: 0.8820\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.2589 - acc: 0.8758\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.2214 - acc: 0.8882\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 0.3119 - acc: 0.8820\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 597us/step - loss: 0.2255 - acc: 0.9068\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 603us/step - loss: 0.2177 - acc: 0.8944\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.2188 - acc: 0.8882\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.2195 - acc: 0.8820\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 594us/step - loss: 0.2076 - acc: 0.8882\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.1919 - acc: 0.8820\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.1972 - acc: 0.8634\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.2777 - acc: 0.8634\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1761 - acc: 0.8758\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 604us/step - loss: 0.1734 - acc: 0.8634\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.2136 - acc: 0.8137\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.1752 - acc: 0.9068\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 599us/step - loss: 0.1608 - acc: 0.9317\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.1594 - acc: 0.9068\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.1730 - acc: 0.9006\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 590us/step - loss: 0.1604 - acc: 0.8634\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1612 - acc: 0.8820\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 589us/step - loss: 0.1700 - acc: 0.8696\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.1471 - acc: 0.8571\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.2370 - acc: 0.8323\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.1608 - acc: 0.8447\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 741us/step - loss: 0.1443 - acc: 0.8571\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.1465 - acc: 0.8075\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1273 - acc: 0.8323\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.1407 - acc: 0.8323\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.1281 - acc: 0.8571\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.2276 - acc: 0.8261\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 619us/step - loss: 0.1316 - acc: 0.8261\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.1371 - acc: 0.8385\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.1103 - acc: 0.8509\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.1114 - acc: 0.8261\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.1222 - acc: 0.8137\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.1198 - acc: 0.8323\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.1110 - acc: 0.8199\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.1126 - acc: 0.8075\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.1104 - acc: 0.8075\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.1031 - acc: 0.8199\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 688us/step - loss: 0.1067 - acc: 0.7888\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.0930 - acc: 0.8261\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 687us/step - loss: 0.0966 - acc: 0.8012\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 620us/step - loss: 0.0908 - acc: 0.8012\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 718us/step - loss: 0.0905 - acc: 0.8385\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 685us/step - loss: 0.0896 - acc: 0.8137\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 614us/step - loss: 0.0886 - acc: 0.8509\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 608us/step - loss: 0.0845 - acc: 0.8323\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.0894 - acc: 0.7826\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.0847 - acc: 0.7826\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.0788 - acc: 0.7950\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 600us/step - loss: 0.0766 - acc: 0.8012\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 733us/step - loss: 0.0657 - acc: 0.7950\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.0796 - acc: 0.7826\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.0687 - acc: 0.7826\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.0749 - acc: 0.8012\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 632us/step - loss: 0.0686 - acc: 0.8012\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 606us/step - loss: 0.0696 - acc: 0.7578\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 655us/step - loss: 0.0675 - acc: 0.7640\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.0688 - acc: 0.8012\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 622us/step - loss: 0.0751 - acc: 0.7702\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.0624 - acc: 0.7826\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 731us/step - loss: 0.0645 - acc: 0.7888\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.0572 - acc: 0.7453\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.0571 - acc: 0.7888\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.0595 - acc: 0.7578\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 657us/step - loss: 0.0531 - acc: 0.7702\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.0598 - acc: 0.7764\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.0479 - acc: 0.7329\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.0446 - acc: 0.7453\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.0634 - acc: 0.7640\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 657us/step - loss: 0.0566 - acc: 0.7019\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.0422 - acc: 0.7578\n",
            "81/81 [==============================] - 3s 34ms/step\n",
            "161/161 [==============================] - 0s 486us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 6s 40ms/step - loss: 2.9364 - acc: 0.4383\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 633us/step - loss: 0.7051 - acc: 0.5494\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 618us/step - loss: 0.5893 - acc: 0.7469\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.5662 - acc: 0.7716\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 610us/step - loss: 0.4312 - acc: 0.8086\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.3984 - acc: 0.8148\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 0.4022 - acc: 0.8580\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 621us/step - loss: 0.3873 - acc: 0.8148\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 647us/step - loss: 0.3616 - acc: 0.8333\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 643us/step - loss: 0.3566 - acc: 0.8580\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.5232 - acc: 0.8395\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 586us/step - loss: 0.5037 - acc: 0.8272\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 694us/step - loss: 0.3507 - acc: 0.8272\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 682us/step - loss: 0.4838 - acc: 0.8457\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 649us/step - loss: 0.3754 - acc: 0.8457\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 611us/step - loss: 0.3893 - acc: 0.8025\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 0.3930 - acc: 0.8148\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 627us/step - loss: 0.3808 - acc: 0.8148\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 608us/step - loss: 0.3936 - acc: 0.8025\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 643us/step - loss: 0.3746 - acc: 0.8395\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 674us/step - loss: 0.3848 - acc: 0.8272\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.3448 - acc: 0.8333\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 602us/step - loss: 0.3523 - acc: 0.7778\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 665us/step - loss: 0.3526 - acc: 0.7901\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 662us/step - loss: 0.3287 - acc: 0.7716\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 647us/step - loss: 0.3569 - acc: 0.7840\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 642us/step - loss: 0.3245 - acc: 0.7654\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 592us/step - loss: 0.4124 - acc: 0.7840\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 625us/step - loss: 0.3253 - acc: 0.7654\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 595us/step - loss: 0.3205 - acc: 0.7407\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 673us/step - loss: 0.3958 - acc: 0.7407\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 616us/step - loss: 0.3057 - acc: 0.7654\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.3052 - acc: 0.7160\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 668us/step - loss: 0.2889 - acc: 0.7654\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 602us/step - loss: 0.2908 - acc: 0.7284\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 629us/step - loss: 0.2910 - acc: 0.7531\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 613us/step - loss: 0.3673 - acc: 0.7222\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 617us/step - loss: 0.2802 - acc: 0.7407\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 646us/step - loss: 0.3639 - acc: 0.7284\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 617us/step - loss: 0.2491 - acc: 0.7531\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 633us/step - loss: 0.2725 - acc: 0.7593\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.2567 - acc: 0.7407\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 597us/step - loss: 0.2547 - acc: 0.7346\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 595us/step - loss: 0.2515 - acc: 0.7469\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 634us/step - loss: 0.2437 - acc: 0.7407\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 603us/step - loss: 0.2272 - acc: 0.7222\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 639us/step - loss: 0.2480 - acc: 0.7346\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 651us/step - loss: 0.2314 - acc: 0.7407\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 609us/step - loss: 0.2388 - acc: 0.7346\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 619us/step - loss: 0.2317 - acc: 0.7469\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 680us/step - loss: 0.2151 - acc: 0.7531\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 626us/step - loss: 0.2278 - acc: 0.7284\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 615us/step - loss: 0.2286 - acc: 0.7469\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 0.2136 - acc: 0.7284\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 645us/step - loss: 0.2166 - acc: 0.7407\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 612us/step - loss: 0.2028 - acc: 0.7346\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 581us/step - loss: 0.2062 - acc: 0.7407\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 601us/step - loss: 0.2023 - acc: 0.7469\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 602us/step - loss: 0.2102 - acc: 0.7284\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 626us/step - loss: 0.2012 - acc: 0.7346\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 602us/step - loss: 0.2037 - acc: 0.7160\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 660us/step - loss: 0.1981 - acc: 0.7222\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 603us/step - loss: 0.1974 - acc: 0.7284\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 603us/step - loss: 0.1913 - acc: 0.7407\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 618us/step - loss: 0.1889 - acc: 0.7346\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 598us/step - loss: 0.1897 - acc: 0.7469\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 615us/step - loss: 0.1760 - acc: 0.7284\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 632us/step - loss: 0.2820 - acc: 0.6852\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 583us/step - loss: 0.1804 - acc: 0.7284\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 675us/step - loss: 0.1809 - acc: 0.7160\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 662us/step - loss: 0.1864 - acc: 0.7222\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 681us/step - loss: 0.1789 - acc: 0.7160\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 596us/step - loss: 0.1703 - acc: 0.7037\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 597us/step - loss: 0.1821 - acc: 0.7099\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 670us/step - loss: 0.1605 - acc: 0.6852\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 607us/step - loss: 0.1828 - acc: 0.7284\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 639us/step - loss: 0.1574 - acc: 0.7222\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 643us/step - loss: 0.1614 - acc: 0.6975\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 669us/step - loss: 0.1708 - acc: 0.6975\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 757us/step - loss: 0.1668 - acc: 0.6975\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 608us/step - loss: 0.1641 - acc: 0.6975\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 655us/step - loss: 0.1750 - acc: 0.6852\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 684us/step - loss: 0.1520 - acc: 0.7099\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 639us/step - loss: 0.1584 - acc: 0.6790\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 657us/step - loss: 0.1594 - acc: 0.6914\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 0.1600 - acc: 0.6914\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 621us/step - loss: 0.1579 - acc: 0.6914\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 642us/step - loss: 0.1509 - acc: 0.7037\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 709us/step - loss: 0.1598 - acc: 0.6975\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 581us/step - loss: 0.1586 - acc: 0.6728\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 659us/step - loss: 0.1486 - acc: 0.7099\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 604us/step - loss: 0.1603 - acc: 0.6975\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 614us/step - loss: 0.1447 - acc: 0.6790\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 579us/step - loss: 0.2347 - acc: 0.6790\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 647us/step - loss: 0.1579 - acc: 0.6173\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 593us/step - loss: 0.2298 - acc: 0.6667\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 606us/step - loss: 0.1701 - acc: 0.6975\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 593us/step - loss: 0.1415 - acc: 0.6728\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 617us/step - loss: 0.1476 - acc: 0.6543\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 641us/step - loss: 0.3164 - acc: 0.6358\n",
            "80/80 [==============================] - 3s 35ms/step\n",
            "162/162 [==============================] - 0s 524us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 7s 41ms/step - loss: 2.0332 - acc: 0.4596\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.7494 - acc: 0.6025\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.7093 - acc: 0.6398\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.6474 - acc: 0.7019\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.5971 - acc: 0.7267\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.5485 - acc: 0.7329\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.5014 - acc: 0.7888\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.4745 - acc: 0.8137\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.4954 - acc: 0.7950\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.4377 - acc: 0.8447\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 751us/step - loss: 0.4148 - acc: 0.8696\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 689us/step - loss: 0.3976 - acc: 0.8696\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.3804 - acc: 0.8820\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.3717 - acc: 0.8820\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.3662 - acc: 0.8696\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.4160 - acc: 0.8075\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.5645 - acc: 0.8261\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.4071 - acc: 0.8634\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.3823 - acc: 0.8571\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.3919 - acc: 0.8571\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 627us/step - loss: 0.3942 - acc: 0.8634\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.3585 - acc: 0.8634\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.3444 - acc: 0.8634\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.3305 - acc: 0.8758\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.3243 - acc: 0.8696\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.3159 - acc: 0.8758\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.3141 - acc: 0.8696\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.3099 - acc: 0.8634\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.3024 - acc: 0.8758\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.2996 - acc: 0.8882\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.2980 - acc: 0.8820\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.2950 - acc: 0.8696\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.2881 - acc: 0.8820\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.2868 - acc: 0.8820\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.2848 - acc: 0.8820\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.2825 - acc: 0.8820\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 803us/step - loss: 0.2891 - acc: 0.8758\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.2814 - acc: 0.8882\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 659us/step - loss: 0.2738 - acc: 0.8820\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.2714 - acc: 0.8882\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.2710 - acc: 0.8820\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.2703 - acc: 0.8758\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.2667 - acc: 0.8758\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.2653 - acc: 0.8882\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.2606 - acc: 0.8696\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 690us/step - loss: 0.2613 - acc: 0.8634\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.2534 - acc: 0.8758\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 766us/step - loss: 0.2508 - acc: 0.8571\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.2494 - acc: 0.8820\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.2511 - acc: 0.8509\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.2437 - acc: 0.8509\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 655us/step - loss: 0.2438 - acc: 0.8758\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.2434 - acc: 0.8261\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 646us/step - loss: 0.2367 - acc: 0.8696\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 655us/step - loss: 0.2363 - acc: 0.8696\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 693us/step - loss: 0.2288 - acc: 0.8758\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.2270 - acc: 0.8509\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.2263 - acc: 0.8447\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.2225 - acc: 0.8509\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.2192 - acc: 0.8571\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.2211 - acc: 0.8323\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.2215 - acc: 0.8447\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.2207 - acc: 0.8199\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.2148 - acc: 0.8758\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 750us/step - loss: 0.2125 - acc: 0.8323\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.2115 - acc: 0.8137\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.2002 - acc: 0.8012\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.2092 - acc: 0.7826\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.1994 - acc: 0.7888\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.2015 - acc: 0.8199\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 655us/step - loss: 0.1976 - acc: 0.7702\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.2000 - acc: 0.8075\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.1882 - acc: 0.7826\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.1922 - acc: 0.7826\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 637us/step - loss: 0.1944 - acc: 0.7578\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.1885 - acc: 0.7702\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 653us/step - loss: 0.1843 - acc: 0.7764\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 648us/step - loss: 0.1841 - acc: 0.7702\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.1806 - acc: 0.7516\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.1979 - acc: 0.7764\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 659us/step - loss: 0.1835 - acc: 0.7329\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.1711 - acc: 0.7640\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.1736 - acc: 0.7329\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 721us/step - loss: 0.1701 - acc: 0.7578\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 750us/step - loss: 0.1746 - acc: 0.7329\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 692us/step - loss: 0.1659 - acc: 0.7329\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 709us/step - loss: 0.1705 - acc: 0.7578\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1651 - acc: 0.7205\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.1644 - acc: 0.7391\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 743us/step - loss: 0.1601 - acc: 0.7391\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.1626 - acc: 0.7081\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.1623 - acc: 0.7391\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 681us/step - loss: 0.1563 - acc: 0.7205\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.1571 - acc: 0.7143\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.1515 - acc: 0.7143\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.1547 - acc: 0.7143\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.1542 - acc: 0.7267\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.1524 - acc: 0.7143\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.1598 - acc: 0.7143\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 718us/step - loss: 0.1476 - acc: 0.7019\n",
            "81/81 [==============================] - 3s 35ms/step\n",
            "161/161 [==============================] - 0s 472us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 7s 42ms/step - loss: 0.6797 - acc: 0.5652\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.5510 - acc: 0.7267\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.4701 - acc: 0.7888\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.4998 - acc: 0.8137\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.5023 - acc: 0.8199\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.8162 - acc: 0.6522\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 639us/step - loss: 0.3853 - acc: 0.8323\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.3504 - acc: 0.8634\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.3293 - acc: 0.8696\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.3141 - acc: 0.8696\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.3084 - acc: 0.8820\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.2968 - acc: 0.8882\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.2850 - acc: 0.8882\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 665us/step - loss: 0.2736 - acc: 0.8820\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.2667 - acc: 0.8820\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 635us/step - loss: 0.2620 - acc: 0.8882\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.2570 - acc: 0.8820\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.2459 - acc: 0.8634\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.2384 - acc: 0.8758\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.2336 - acc: 0.8758\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.2263 - acc: 0.8571\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.2194 - acc: 0.8509\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.2219 - acc: 0.8571\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.2130 - acc: 0.8820\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.2137 - acc: 0.8509\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.2048 - acc: 0.8509\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 611us/step - loss: 0.2012 - acc: 0.8571\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 628us/step - loss: 0.1977 - acc: 0.8571\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.2047 - acc: 0.8758\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.2018 - acc: 0.8447\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 665us/step - loss: 0.1916 - acc: 0.8571\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.1888 - acc: 0.8509\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 678us/step - loss: 0.1951 - acc: 0.8571\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 618us/step - loss: 0.1770 - acc: 0.8571\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 624us/step - loss: 0.1800 - acc: 0.8571\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 623us/step - loss: 0.1678 - acc: 0.8447\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.1643 - acc: 0.8509\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.1607 - acc: 0.8447\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.1581 - acc: 0.8509\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 695us/step - loss: 0.1862 - acc: 0.8385\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 612us/step - loss: 0.1749 - acc: 0.8634\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 732us/step - loss: 0.1537 - acc: 0.8447\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.1478 - acc: 0.8509\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.1414 - acc: 0.8447\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 633us/step - loss: 0.1393 - acc: 0.8385\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 613us/step - loss: 0.1390 - acc: 0.8385\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.1333 - acc: 0.8634\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.1298 - acc: 0.8509\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 0.1322 - acc: 0.8634\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1271 - acc: 0.8571\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.1225 - acc: 0.8447\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.1218 - acc: 0.8509\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.1199 - acc: 0.8634\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 629us/step - loss: 0.1158 - acc: 0.8509\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 615us/step - loss: 0.1135 - acc: 0.8385\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 757us/step - loss: 0.1112 - acc: 0.8447\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 657us/step - loss: 0.1139 - acc: 0.8261\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 745us/step - loss: 0.1054 - acc: 0.8323\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 630us/step - loss: 0.1055 - acc: 0.8323\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 653us/step - loss: 0.1035 - acc: 0.8323\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 649us/step - loss: 0.1013 - acc: 0.8323\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.1050 - acc: 0.8385\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1021 - acc: 0.8323\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.0955 - acc: 0.8261\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.0934 - acc: 0.8261\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 625us/step - loss: 0.1033 - acc: 0.8261\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 679us/step - loss: 0.0953 - acc: 0.8323\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 688us/step - loss: 0.0923 - acc: 0.8199\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.0854 - acc: 0.8323\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 690us/step - loss: 0.0837 - acc: 0.8261\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 617us/step - loss: 0.0834 - acc: 0.8199\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.0826 - acc: 0.8199\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.0797 - acc: 0.8385\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 678us/step - loss: 0.0861 - acc: 0.8199\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 756us/step - loss: 0.0815 - acc: 0.8199\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.0825 - acc: 0.8137\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.0758 - acc: 0.8323\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 657us/step - loss: 0.0744 - acc: 0.8199\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 649us/step - loss: 0.0758 - acc: 0.8137\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.0743 - acc: 0.8323\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 666us/step - loss: 0.0829 - acc: 0.8199\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.0670 - acc: 0.8261\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.0631 - acc: 0.8261\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.0678 - acc: 0.8199\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.0635 - acc: 0.8323\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.0596 - acc: 0.8199\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.0611 - acc: 0.8261\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 671us/step - loss: 0.0562 - acc: 0.8261\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 741us/step - loss: 0.0647 - acc: 0.8261\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.0585 - acc: 0.8323\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.0565 - acc: 0.8323\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.0611 - acc: 0.8447\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 699us/step - loss: 0.0594 - acc: 0.8385\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 792us/step - loss: 0.0578 - acc: 0.8323\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.0551 - acc: 0.8261\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 655us/step - loss: 0.0503 - acc: 0.8199\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 724us/step - loss: 0.0493 - acc: 0.8447\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 692us/step - loss: 0.0478 - acc: 0.8012\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.0591 - acc: 0.8323\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.0529 - acc: 0.8075\n",
            "81/81 [==============================] - 3s 35ms/step\n",
            "161/161 [==============================] - 0s 496us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 7s 42ms/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 652us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 655us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 644us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 633us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 632us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 622us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 706us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 634us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 693us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 627us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 636us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 654us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 675us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 657us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 621us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 629us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 676us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 617us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 644us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 660us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 626us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 610us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 707us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 729us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 787us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 623us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 628us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 655us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 662us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 648us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 660us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 670us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 629us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 656us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 640us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 661us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 651us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 616us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 613us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 592us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 757us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 642us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 730us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 764us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 721us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 658us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 683us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 635us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 677us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 656us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 655us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 728us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 649us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 739us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 709us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 742us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 680us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 739us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 778us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 818us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 702us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 793us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 631us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 636us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 691us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 660us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 664us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 625us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 630us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 638us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 618us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 641us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 652us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 627us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 661us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 650us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 728us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 662us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 702us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 644us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 641us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 626us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 622us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 616us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 621us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 660us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 648us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 721us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 644us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 642us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 716us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 635us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 624us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 621us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 692us/step - loss: 9.0540 - acc: 0.4383\n",
            "80/80 [==============================] - 3s 37ms/step\n",
            "162/162 [==============================] - 0s 520us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 7s 29ms/step - loss: 0.7688 - acc: 0.5289\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 655us/step - loss: 0.5410 - acc: 0.7190\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 731us/step - loss: 0.5029 - acc: 0.7769\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 700us/step - loss: 0.4481 - acc: 0.8099\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 708us/step - loss: 0.3735 - acc: 0.8140\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 720us/step - loss: 0.4627 - acc: 0.8347\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 735us/step - loss: 0.5028 - acc: 0.8017\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 722us/step - loss: 0.4843 - acc: 0.8058\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 624us/step - loss: 0.4742 - acc: 0.7810\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 702us/step - loss: 0.4652 - acc: 0.7562\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 728us/step - loss: 0.4618 - acc: 0.7893\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 615us/step - loss: 0.4401 - acc: 0.7810\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 659us/step - loss: 0.4381 - acc: 0.7603\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 634us/step - loss: 0.4281 - acc: 0.7769\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 627us/step - loss: 0.4072 - acc: 0.7727\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 717us/step - loss: 0.4083 - acc: 0.7603\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 629us/step - loss: 0.3944 - acc: 0.7603\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 639us/step - loss: 0.3892 - acc: 0.7645\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 657us/step - loss: 0.3716 - acc: 0.8017\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 638us/step - loss: 0.4038 - acc: 0.7727\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 616us/step - loss: 0.3825 - acc: 0.7893\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 681us/step - loss: 0.3762 - acc: 0.7810\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 660us/step - loss: 0.3615 - acc: 0.7851\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 684us/step - loss: 0.3579 - acc: 0.7603\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 619us/step - loss: 0.3535 - acc: 0.7810\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 646us/step - loss: 0.3478 - acc: 0.7851\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 640us/step - loss: 0.3472 - acc: 0.7521\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 703us/step - loss: 0.3487 - acc: 0.7438\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 659us/step - loss: 0.3492 - acc: 0.7397\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 647us/step - loss: 0.3335 - acc: 0.7645\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 664us/step - loss: 0.3310 - acc: 0.7438\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 635us/step - loss: 0.3262 - acc: 0.7521\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 630us/step - loss: 0.3231 - acc: 0.7355\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 716us/step - loss: 0.3359 - acc: 0.7397\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 716us/step - loss: 0.3177 - acc: 0.7190\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 674us/step - loss: 0.3205 - acc: 0.7521\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 671us/step - loss: 0.3168 - acc: 0.7355\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 640us/step - loss: 0.3144 - acc: 0.7479\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 708us/step - loss: 0.3126 - acc: 0.7521\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 749us/step - loss: 0.3059 - acc: 0.7231\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 719us/step - loss: 0.3525 - acc: 0.7397\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 708us/step - loss: 0.3219 - acc: 0.7355\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 713us/step - loss: 0.3040 - acc: 0.6942\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 705us/step - loss: 0.2950 - acc: 0.7314\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 667us/step - loss: 0.3025 - acc: 0.7149\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 656us/step - loss: 0.2884 - acc: 0.7149\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 729us/step - loss: 0.2890 - acc: 0.7025\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 633us/step - loss: 0.2867 - acc: 0.7107\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 646us/step - loss: 0.2908 - acc: 0.6570\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 615us/step - loss: 0.2774 - acc: 0.6818\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 624us/step - loss: 0.2924 - acc: 0.6653\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 650us/step - loss: 0.2822 - acc: 0.6983\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 650us/step - loss: 0.2770 - acc: 0.6612\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 663us/step - loss: 0.2842 - acc: 0.6777\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 686us/step - loss: 0.2826 - acc: 0.6364\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 707us/step - loss: 0.2791 - acc: 0.6653\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 688us/step - loss: 0.2730 - acc: 0.6818\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 639us/step - loss: 0.2668 - acc: 0.6570\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 684us/step - loss: 0.2760 - acc: 0.6612\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 731us/step - loss: 0.2650 - acc: 0.6570\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 649us/step - loss: 0.2745 - acc: 0.6488\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 643us/step - loss: 0.2655 - acc: 0.6446\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 631us/step - loss: 0.2590 - acc: 0.6570\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 630us/step - loss: 0.2571 - acc: 0.6405\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 673us/step - loss: 0.2553 - acc: 0.6446\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 648us/step - loss: 0.2517 - acc: 0.6488\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 643us/step - loss: 0.2584 - acc: 0.6157\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 646us/step - loss: 0.2796 - acc: 0.6322\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 619us/step - loss: 0.2494 - acc: 0.6405\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 659us/step - loss: 0.2537 - acc: 0.6157\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 684us/step - loss: 0.2461 - acc: 0.6446\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 649us/step - loss: 0.2478 - acc: 0.6488\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 645us/step - loss: 0.2476 - acc: 0.6033\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 617us/step - loss: 0.2531 - acc: 0.6281\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 632us/step - loss: 0.2508 - acc: 0.6240\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 646us/step - loss: 0.2445 - acc: 0.6322\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 658us/step - loss: 0.2475 - acc: 0.6240\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 665us/step - loss: 0.2397 - acc: 0.6116\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 651us/step - loss: 0.2391 - acc: 0.6074\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 660us/step - loss: 0.2380 - acc: 0.6240\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 695us/step - loss: 0.2373 - acc: 0.5950\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 669us/step - loss: 0.2329 - acc: 0.5992\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 624us/step - loss: 0.2256 - acc: 0.6157\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 706us/step - loss: 0.2257 - acc: 0.6074\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 683us/step - loss: 0.2398 - acc: 0.5992\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 644us/step - loss: 0.2288 - acc: 0.6157\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 632us/step - loss: 0.2219 - acc: 0.6157\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 637us/step - loss: 0.2266 - acc: 0.6074\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 641us/step - loss: 0.2253 - acc: 0.6116\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 643us/step - loss: 0.2219 - acc: 0.6116\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 627us/step - loss: 0.2200 - acc: 0.6116\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 661us/step - loss: 0.2200 - acc: 0.6157\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 642us/step - loss: 0.2271 - acc: 0.5826\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 628us/step - loss: 0.2217 - acc: 0.5909\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 692us/step - loss: 0.2266 - acc: 0.6074\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 662us/step - loss: 0.2192 - acc: 0.6116\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 650us/step - loss: 0.2211 - acc: 0.6198\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 699us/step - loss: 0.2168 - acc: 0.6074\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 635us/step - loss: 0.2184 - acc: 0.6033\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 608us/step - loss: 0.2193 - acc: 0.6033\n",
            "Best: 0.541322 using {'activation': 'relu', 'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2L5jBv4shoUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 24143
        },
        "outputId": "d602ea46-3664-4a82-d549-30c0ad99457c"
      },
      "cell_type": "code",
      "source": [
        "# This one will tune my activations. \n",
        "activations = [\"relu\", \"sigmoid\"]\n",
        "\n",
        "def baseline(optimizer = \"adam\", init = \"uniform\", activation='relu'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(39, input_dim=X.shape[1], activation=activation))\n",
        "  model.add(Dense(39, activation=activation))\n",
        "  model.add(Dense(1, activation=activation))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=baseline, epochs=100, batch_size=5, verbose=1)\n",
        "\n",
        "param_grid = dict(activation=activations)\n",
        "print(param_grid)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, )\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': ['relu', 'sigmoid']}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "161/161 [==============================] - 8s 49ms/step - loss: 8.9101 - acc: 0.4472\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 750us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 693us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 707us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 666us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 721us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 697us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 829us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 686us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 626us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 636us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 760us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 744us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 764us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 836us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 792us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 774us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 810us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 734us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 741us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 718us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 705us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 770us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 732us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 744us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 756us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 841us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 779us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 705us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 762us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 826us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 777us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 742us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 781us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 767us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 678us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 767us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 845us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 848us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 781us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 804us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 864us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 794us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 761us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 799us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 794us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 748us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 805us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 865us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 798us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 789us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 790us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 771us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 698us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 751us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 730us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 745us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 757us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 663us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 684us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 760us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 670us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 751us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 732us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 656us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 670us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 715us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 716us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 698us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 769us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 755us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 709us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 773us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 724us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 702us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 823us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 741us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 662us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 717us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 8.9100 - acc: 0.4472\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 822us/step - loss: 8.9100 - acc: 0.4472\n",
            "81/81 [==============================] - 3s 38ms/step\n",
            "161/161 [==============================] - 0s 522us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 7s 45ms/step - loss: 2.0184 - acc: 0.6398\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 694us/step - loss: 0.6224 - acc: 0.7764\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.7116 - acc: 0.7267\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 699us/step - loss: 0.4469 - acc: 0.7888\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 764us/step - loss: 0.3950 - acc: 0.8385\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.3757 - acc: 0.8385\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 733us/step - loss: 0.3637 - acc: 0.8385\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.3544 - acc: 0.8323\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.3404 - acc: 0.8323\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.3319 - acc: 0.8509\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3255 - acc: 0.8323\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.3207 - acc: 0.8571\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 722us/step - loss: 0.3089 - acc: 0.8447\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.3053 - acc: 0.8820\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 698us/step - loss: 0.2940 - acc: 0.8820\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 666us/step - loss: 0.2936 - acc: 0.8882\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 631us/step - loss: 0.2875 - acc: 0.8820\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 694us/step - loss: 0.2735 - acc: 0.8882\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.2687 - acc: 0.9006\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 694us/step - loss: 0.2583 - acc: 0.8944\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 709us/step - loss: 0.2582 - acc: 0.9006\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.2590 - acc: 0.9006\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.2474 - acc: 0.9068\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.2346 - acc: 0.9130\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.2260 - acc: 0.9006\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 780us/step - loss: 0.2224 - acc: 0.8944\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 800us/step - loss: 0.2158 - acc: 0.8944\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 852us/step - loss: 0.2132 - acc: 0.8944\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 665us/step - loss: 0.2056 - acc: 0.9068\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 777us/step - loss: 0.2222 - acc: 0.9006\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 655us/step - loss: 0.2087 - acc: 0.8820\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.2032 - acc: 0.8882\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 679us/step - loss: 0.1906 - acc: 0.9130\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.1851 - acc: 0.8696\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.1795 - acc: 0.8944\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 638us/step - loss: 0.1767 - acc: 0.8820\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.1779 - acc: 0.8820\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.1692 - acc: 0.9006\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 694us/step - loss: 0.1604 - acc: 0.8509\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.1609 - acc: 0.8820\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 671us/step - loss: 0.1566 - acc: 0.8571\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.1505 - acc: 0.8696\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 707us/step - loss: 0.1537 - acc: 0.8696\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 768us/step - loss: 0.1493 - acc: 0.8571\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 671us/step - loss: 0.1462 - acc: 0.8634\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.1439 - acc: 0.8634\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 754us/step - loss: 0.1352 - acc: 0.8571\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 780us/step - loss: 0.1347 - acc: 0.8509\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 732us/step - loss: 0.1348 - acc: 0.8571\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 778us/step - loss: 0.1263 - acc: 0.8820\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 793us/step - loss: 0.1231 - acc: 0.8634\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 714us/step - loss: 0.1181 - acc: 0.8696\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 790us/step - loss: 0.1268 - acc: 0.8571\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.1159 - acc: 0.8696\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.1194 - acc: 0.8696\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.1226 - acc: 0.8571\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.1128 - acc: 0.8509\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 681us/step - loss: 0.1193 - acc: 0.8758\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.1138 - acc: 0.8696\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 686us/step - loss: 0.1043 - acc: 0.8509\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.1063 - acc: 0.8571\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 685us/step - loss: 0.0995 - acc: 0.8634\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 788us/step - loss: 0.0994 - acc: 0.8571\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 710us/step - loss: 0.0940 - acc: 0.8509\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 691us/step - loss: 0.0938 - acc: 0.8571\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 754us/step - loss: 0.0952 - acc: 0.8447\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 721us/step - loss: 0.0904 - acc: 0.8509\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.0880 - acc: 0.8634\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 710us/step - loss: 0.0857 - acc: 0.8447\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 705us/step - loss: 0.0861 - acc: 0.8634\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.0863 - acc: 0.8385\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 654us/step - loss: 0.0775 - acc: 0.8385\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 804us/step - loss: 0.0780 - acc: 0.8447\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 696us/step - loss: 0.0724 - acc: 0.8385\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 764us/step - loss: 0.0716 - acc: 0.8571\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 704us/step - loss: 0.0721 - acc: 0.8385\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 721us/step - loss: 0.0691 - acc: 0.8199\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 681us/step - loss: 0.0674 - acc: 0.8385\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 681us/step - loss: 0.0669 - acc: 0.8261\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 800us/step - loss: 0.0647 - acc: 0.8075\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 717us/step - loss: 0.0610 - acc: 0.8075\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.0625 - acc: 0.7888\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 666us/step - loss: 0.0612 - acc: 0.7888\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.0613 - acc: 0.8509\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 721us/step - loss: 0.0554 - acc: 0.8075\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.0568 - acc: 0.7888\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 641us/step - loss: 0.0563 - acc: 0.8385\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.0507 - acc: 0.8323\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 665us/step - loss: 0.0487 - acc: 0.8012\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 768us/step - loss: 0.0541 - acc: 0.8137\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 721us/step - loss: 0.0508 - acc: 0.7764\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.0515 - acc: 0.8012\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 730us/step - loss: 0.0449 - acc: 0.7888\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 690us/step - loss: 0.0457 - acc: 0.7950\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 697us/step - loss: 0.0438 - acc: 0.7888\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.0477 - acc: 0.7702\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 659us/step - loss: 0.0427 - acc: 0.8012\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 671us/step - loss: 0.0513 - acc: 0.8012\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 757us/step - loss: 0.0472 - acc: 0.7391\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.0381 - acc: 0.7640\n",
            "81/81 [==============================] - 3s 38ms/step\n",
            "161/161 [==============================] - 0s 545us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 8s 48ms/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 794us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 721us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 716us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 759us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 667us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 712us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 753us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 747us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 676us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 804us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 702us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 819us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 773us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 791us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 722us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 779us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 743us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 663us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 820us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 798us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 710us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 740us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 673us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 730us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 718us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 750us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 651us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 680us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 747us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 656us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 660us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 673us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 638us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 648us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 668us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 781us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 719us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 747us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 673us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 715us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 723us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 703us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 669us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 692us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 718us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 720us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 671us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 671us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 667us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 651us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 712us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 656us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 656us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 692us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 688us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 737us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 731us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 736us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 647us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 660us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 685us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 721us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 810us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 784us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 795us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 788us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 696us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 739us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 706us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 749us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 788us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 793us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 792us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 767us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 748us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 778us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 751us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 692us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 716us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 682us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 677us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 676us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 646us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 651us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 728us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 770us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 841us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 744us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 744us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 794us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 770us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 715us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 709us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 764us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 679us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 784us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 777us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 769us/step - loss: 9.0540 - acc: 0.4383\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 793us/step - loss: 9.0540 - acc: 0.4383\n",
            "80/80 [==============================] - 3s 39ms/step\n",
            "162/162 [==============================] - 0s 569us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 7s 46ms/step - loss: 0.7130 - acc: 0.4907\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 780us/step - loss: 0.6863 - acc: 0.5528\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 807us/step - loss: 0.6848 - acc: 0.6025\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 744us/step - loss: 0.6768 - acc: 0.5528\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 822us/step - loss: 0.6730 - acc: 0.5528\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 810us/step - loss: 0.6672 - acc: 0.5528\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 819us/step - loss: 0.6642 - acc: 0.6335\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 796us/step - loss: 0.6626 - acc: 0.5652\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.6433 - acc: 0.7081\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.6331 - acc: 0.6584\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.6212 - acc: 0.6708\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.6113 - acc: 0.7267\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.5916 - acc: 0.7950\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 716us/step - loss: 0.5755 - acc: 0.7950\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 689us/step - loss: 0.5565 - acc: 0.8137\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.5397 - acc: 0.8012\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.5215 - acc: 0.8199\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 839us/step - loss: 0.5059 - acc: 0.8012\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.4881 - acc: 0.7950\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.4697 - acc: 0.8137\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.4592 - acc: 0.8075\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 760us/step - loss: 0.4445 - acc: 0.8199\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.4337 - acc: 0.8012\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 729us/step - loss: 0.4248 - acc: 0.8199\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.4155 - acc: 0.8137\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.4095 - acc: 0.8075\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 692us/step - loss: 0.4009 - acc: 0.8323\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 786us/step - loss: 0.3939 - acc: 0.8199\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.3921 - acc: 0.8199\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.3847 - acc: 0.8199\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.3800 - acc: 0.8261\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 731us/step - loss: 0.3773 - acc: 0.8199\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.3726 - acc: 0.8323\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.3774 - acc: 0.8075\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.3668 - acc: 0.8323\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.3697 - acc: 0.8323\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 722us/step - loss: 0.3729 - acc: 0.8323\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 708us/step - loss: 0.3622 - acc: 0.8199\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 779us/step - loss: 0.3586 - acc: 0.8137\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 706us/step - loss: 0.3568 - acc: 0.8447\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3540 - acc: 0.8385\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 731us/step - loss: 0.3591 - acc: 0.8323\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3560 - acc: 0.8447\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 822us/step - loss: 0.3514 - acc: 0.8323\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.3595 - acc: 0.8199\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.3520 - acc: 0.8509\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.3466 - acc: 0.8323\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.3493 - acc: 0.8323\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.3504 - acc: 0.8323\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3420 - acc: 0.8323\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 730us/step - loss: 0.3425 - acc: 0.8323\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.3415 - acc: 0.8261\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.3395 - acc: 0.8509\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 799us/step - loss: 0.3385 - acc: 0.8509\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.3493 - acc: 0.8199\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.3445 - acc: 0.8385\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.3371 - acc: 0.8509\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 689us/step - loss: 0.3413 - acc: 0.8385\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 805us/step - loss: 0.3364 - acc: 0.8447\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 803us/step - loss: 0.3335 - acc: 0.8385\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 775us/step - loss: 0.3338 - acc: 0.8509\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 799us/step - loss: 0.3385 - acc: 0.8261\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 807us/step - loss: 0.3327 - acc: 0.8571\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.3312 - acc: 0.8447\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.3329 - acc: 0.8385\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 790us/step - loss: 0.3322 - acc: 0.8509\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.3296 - acc: 0.8385\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 801us/step - loss: 0.3335 - acc: 0.8509\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 807us/step - loss: 0.3307 - acc: 0.8447\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.3272 - acc: 0.8571\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 833us/step - loss: 0.3344 - acc: 0.8509\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.3361 - acc: 0.8447\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 748us/step - loss: 0.3275 - acc: 0.8758\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 791us/step - loss: 0.3305 - acc: 0.8509\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 788us/step - loss: 0.3254 - acc: 0.8571\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 910us/step - loss: 0.3276 - acc: 0.8385\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 787us/step - loss: 0.3244 - acc: 0.8385\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.3271 - acc: 0.8509\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 790us/step - loss: 0.3248 - acc: 0.8385\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 777us/step - loss: 0.3233 - acc: 0.8634\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 771us/step - loss: 0.3215 - acc: 0.8571\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 764us/step - loss: 0.3275 - acc: 0.8509\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.3225 - acc: 0.8447\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.3237 - acc: 0.8634\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 865us/step - loss: 0.3201 - acc: 0.8509\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 814us/step - loss: 0.3209 - acc: 0.8571\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 792us/step - loss: 0.3201 - acc: 0.8447\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.3215 - acc: 0.8571\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.3252 - acc: 0.8447\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.3221 - acc: 0.8758\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.3275 - acc: 0.8261\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 845us/step - loss: 0.3182 - acc: 0.8696\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 790us/step - loss: 0.3179 - acc: 0.8634\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 754us/step - loss: 0.3208 - acc: 0.8509\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 748us/step - loss: 0.3211 - acc: 0.8509\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.3152 - acc: 0.8509\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.3176 - acc: 0.8571\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 764us/step - loss: 0.3177 - acc: 0.8758\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 715us/step - loss: 0.3185 - acc: 0.8571\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 703us/step - loss: 0.3172 - acc: 0.8634\n",
            "81/81 [==============================] - 3s 39ms/step\n",
            "161/161 [==============================] - 0s 533us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 7s 47ms/step - loss: 0.6961 - acc: 0.5280\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 717us/step - loss: 0.6868 - acc: 0.5342\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 743us/step - loss: 0.6806 - acc: 0.5342\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.6763 - acc: 0.5839\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 716us/step - loss: 0.6744 - acc: 0.7205\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 718us/step - loss: 0.6662 - acc: 0.7516\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 764us/step - loss: 0.6561 - acc: 0.6211\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 766us/step - loss: 0.6492 - acc: 0.6832\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 805us/step - loss: 0.6419 - acc: 0.7826\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.6286 - acc: 0.7950\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.6195 - acc: 0.7391\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 787us/step - loss: 0.6038 - acc: 0.8012\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.5848 - acc: 0.8075\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.5717 - acc: 0.7764\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.5549 - acc: 0.7950\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.5321 - acc: 0.8137\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 785us/step - loss: 0.5149 - acc: 0.8137\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 757us/step - loss: 0.4970 - acc: 0.7888\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.4843 - acc: 0.8199\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.4689 - acc: 0.8137\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 765us/step - loss: 0.4511 - acc: 0.8075\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 701us/step - loss: 0.4389 - acc: 0.8012\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.4315 - acc: 0.8075\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 751us/step - loss: 0.4205 - acc: 0.8012\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 817us/step - loss: 0.4127 - acc: 0.8075\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 786us/step - loss: 0.4046 - acc: 0.8075\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.4037 - acc: 0.8075\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.4002 - acc: 0.8012\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 723us/step - loss: 0.3987 - acc: 0.8075\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 827us/step - loss: 0.3849 - acc: 0.8137\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 806us/step - loss: 0.3816 - acc: 0.8199\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 826us/step - loss: 0.3798 - acc: 0.8199\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 817us/step - loss: 0.3746 - acc: 0.8199\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 796us/step - loss: 0.3728 - acc: 0.8199\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 811us/step - loss: 0.3734 - acc: 0.8199\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 827us/step - loss: 0.3674 - acc: 0.8385\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 790us/step - loss: 0.3775 - acc: 0.8261\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.3675 - acc: 0.8261\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 822us/step - loss: 0.3649 - acc: 0.8385\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 854us/step - loss: 0.3640 - acc: 0.8323\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 789us/step - loss: 0.3616 - acc: 0.8447\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 754us/step - loss: 0.3578 - acc: 0.8447\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 900us/step - loss: 0.3575 - acc: 0.8447\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 757us/step - loss: 0.3585 - acc: 0.8447\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 822us/step - loss: 0.3536 - acc: 0.8571\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 848us/step - loss: 0.3526 - acc: 0.8571\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 893us/step - loss: 0.3523 - acc: 0.8509\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 810us/step - loss: 0.3510 - acc: 0.8571\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 787us/step - loss: 0.3504 - acc: 0.8634\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 819us/step - loss: 0.3481 - acc: 0.8634\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 786us/step - loss: 0.3477 - acc: 0.8634\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 781us/step - loss: 0.3456 - acc: 0.8509\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 783us/step - loss: 0.3456 - acc: 0.8447\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 866us/step - loss: 0.3471 - acc: 0.8509\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 794us/step - loss: 0.3447 - acc: 0.8571\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 845us/step - loss: 0.3475 - acc: 0.8696\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 837us/step - loss: 0.3517 - acc: 0.8509\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 779us/step - loss: 0.3455 - acc: 0.8571\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 811us/step - loss: 0.3439 - acc: 0.8634\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 792us/step - loss: 0.3421 - acc: 0.8571\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.3419 - acc: 0.8571\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 806us/step - loss: 0.3412 - acc: 0.8571\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 793us/step - loss: 0.3425 - acc: 0.8634\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 777us/step - loss: 0.3395 - acc: 0.8634\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.3408 - acc: 0.8571\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 798us/step - loss: 0.3473 - acc: 0.8634\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 819us/step - loss: 0.3478 - acc: 0.8634\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 752us/step - loss: 0.3431 - acc: 0.8634\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 795us/step - loss: 0.3400 - acc: 0.8634\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3405 - acc: 0.8509\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 804us/step - loss: 0.3385 - acc: 0.8634\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.3429 - acc: 0.8571\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.3405 - acc: 0.8509\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 786us/step - loss: 0.3417 - acc: 0.8696\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 825us/step - loss: 0.3429 - acc: 0.8509\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 699us/step - loss: 0.3352 - acc: 0.8509\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.3405 - acc: 0.8509\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 811us/step - loss: 0.3410 - acc: 0.8571\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 806us/step - loss: 0.3400 - acc: 0.8634\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 681us/step - loss: 0.3342 - acc: 0.8447\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 729us/step - loss: 0.3359 - acc: 0.8509\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 677us/step - loss: 0.3390 - acc: 0.8634\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.3486 - acc: 0.8571\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 741us/step - loss: 0.3359 - acc: 0.8571\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 715us/step - loss: 0.3344 - acc: 0.8634\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.3420 - acc: 0.8634\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 737us/step - loss: 0.3354 - acc: 0.8571\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 770us/step - loss: 0.3380 - acc: 0.8696\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.3348 - acc: 0.8634\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.3355 - acc: 0.8696\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 768us/step - loss: 0.3372 - acc: 0.8758\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.3344 - acc: 0.8696\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 724us/step - loss: 0.3315 - acc: 0.8634\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 810us/step - loss: 0.3322 - acc: 0.8634\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 812us/step - loss: 0.3352 - acc: 0.8571\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.3360 - acc: 0.8571\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3320 - acc: 0.8634\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.3324 - acc: 0.8634\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 781us/step - loss: 0.3328 - acc: 0.8634\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3326 - acc: 0.8571\n",
            "81/81 [==============================] - 3s 40ms/step\n",
            "161/161 [==============================] - 0s 654us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 8s 47ms/step - loss: 0.7679 - acc: 0.4444\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 829us/step - loss: 0.6767 - acc: 0.5679\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 844us/step - loss: 0.6747 - acc: 0.5617\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 847us/step - loss: 0.6680 - acc: 0.5617\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 821us/step - loss: 0.6644 - acc: 0.5741\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 817us/step - loss: 0.6591 - acc: 0.6173\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 803us/step - loss: 0.6519 - acc: 0.6111\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 793us/step - loss: 0.6443 - acc: 0.6420\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 850us/step - loss: 0.6345 - acc: 0.6358\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 841us/step - loss: 0.6239 - acc: 0.6790\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 915us/step - loss: 0.6152 - acc: 0.7593\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 927us/step - loss: 0.5995 - acc: 0.7531\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 865us/step - loss: 0.5877 - acc: 0.7284\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 861us/step - loss: 0.5735 - acc: 0.7654\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 866us/step - loss: 0.5567 - acc: 0.7778\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 877us/step - loss: 0.5435 - acc: 0.7840\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 923us/step - loss: 0.5250 - acc: 0.8025\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 840us/step - loss: 0.5120 - acc: 0.7963\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 808us/step - loss: 0.4946 - acc: 0.7963\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 837us/step - loss: 0.4846 - acc: 0.7778\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 739us/step - loss: 0.4686 - acc: 0.7963\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 781us/step - loss: 0.4608 - acc: 0.8148\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 794us/step - loss: 0.4467 - acc: 0.8148\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 824us/step - loss: 0.4423 - acc: 0.8272\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 823us/step - loss: 0.4330 - acc: 0.8025\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 865us/step - loss: 0.4234 - acc: 0.8086\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 844us/step - loss: 0.4203 - acc: 0.8086\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 834us/step - loss: 0.4155 - acc: 0.8210\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 841us/step - loss: 0.4062 - acc: 0.8148\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 759us/step - loss: 0.4038 - acc: 0.8210\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 791us/step - loss: 0.4000 - acc: 0.8210\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 897us/step - loss: 0.3945 - acc: 0.8148\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 728us/step - loss: 0.3949 - acc: 0.8086\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 816us/step - loss: 0.3936 - acc: 0.8148\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 847us/step - loss: 0.3961 - acc: 0.8148\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 869us/step - loss: 0.3880 - acc: 0.8148\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 797us/step - loss: 0.3868 - acc: 0.8272\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 819us/step - loss: 0.3853 - acc: 0.8333\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 827us/step - loss: 0.3813 - acc: 0.8333\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 815us/step - loss: 0.3811 - acc: 0.8333\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 806us/step - loss: 0.3773 - acc: 0.8210\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 816us/step - loss: 0.3775 - acc: 0.8333\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 820us/step - loss: 0.3760 - acc: 0.8395\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 793us/step - loss: 0.3734 - acc: 0.8457\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 811us/step - loss: 0.3740 - acc: 0.8395\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 796us/step - loss: 0.3745 - acc: 0.8333\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 812us/step - loss: 0.3733 - acc: 0.8457\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 850us/step - loss: 0.3777 - acc: 0.8333\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 767us/step - loss: 0.3691 - acc: 0.8210\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 780us/step - loss: 0.3717 - acc: 0.8333\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 774us/step - loss: 0.3689 - acc: 0.8457\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 736us/step - loss: 0.3670 - acc: 0.8519\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 780us/step - loss: 0.3677 - acc: 0.8395\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 820us/step - loss: 0.3671 - acc: 0.8457\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 791us/step - loss: 0.3658 - acc: 0.8519\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 776us/step - loss: 0.3689 - acc: 0.8457\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 738us/step - loss: 0.3697 - acc: 0.8272\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 790us/step - loss: 0.3661 - acc: 0.8519\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 831us/step - loss: 0.3655 - acc: 0.8580\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 834us/step - loss: 0.3637 - acc: 0.8519\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 834us/step - loss: 0.3648 - acc: 0.8580\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 813us/step - loss: 0.3644 - acc: 0.8395\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 811us/step - loss: 0.3669 - acc: 0.8519\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 807us/step - loss: 0.3622 - acc: 0.8580\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 797us/step - loss: 0.3644 - acc: 0.8519\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 816us/step - loss: 0.3623 - acc: 0.8580\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 720us/step - loss: 0.3657 - acc: 0.8457\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 831us/step - loss: 0.3636 - acc: 0.8519\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 796us/step - loss: 0.3614 - acc: 0.8580\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 739us/step - loss: 0.3618 - acc: 0.8519\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 914us/step - loss: 0.3609 - acc: 0.8519\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 862us/step - loss: 0.3609 - acc: 0.8519\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 800us/step - loss: 0.3614 - acc: 0.8519\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 818us/step - loss: 0.3602 - acc: 0.8519\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 802us/step - loss: 0.3606 - acc: 0.8519\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 791us/step - loss: 0.3606 - acc: 0.8580\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 780us/step - loss: 0.3589 - acc: 0.8519\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 837us/step - loss: 0.3640 - acc: 0.8395\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 727us/step - loss: 0.3637 - acc: 0.8580\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 805us/step - loss: 0.3587 - acc: 0.8519\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 865us/step - loss: 0.3632 - acc: 0.8580\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 772us/step - loss: 0.3596 - acc: 0.8457\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 812us/step - loss: 0.3643 - acc: 0.8519\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 828us/step - loss: 0.3579 - acc: 0.8519\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 806us/step - loss: 0.3605 - acc: 0.8395\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 888us/step - loss: 0.3597 - acc: 0.8642\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 870us/step - loss: 0.3645 - acc: 0.8333\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 801us/step - loss: 0.3587 - acc: 0.8519\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 863us/step - loss: 0.3586 - acc: 0.8580\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 879us/step - loss: 0.3587 - acc: 0.8519\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 859us/step - loss: 0.3560 - acc: 0.8519\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 907us/step - loss: 0.3572 - acc: 0.8642\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 934us/step - loss: 0.3609 - acc: 0.8519\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 828us/step - loss: 0.3574 - acc: 0.8519\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 862us/step - loss: 0.3577 - acc: 0.8519\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 790us/step - loss: 0.3667 - acc: 0.8457\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 806us/step - loss: 0.3655 - acc: 0.8272\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 795us/step - loss: 0.3577 - acc: 0.8519\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 860us/step - loss: 0.3591 - acc: 0.8519\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 882us/step - loss: 0.3577 - acc: 0.8519\n",
            "80/80 [==============================] - 3s 40ms/step\n",
            "162/162 [==============================] - 0s 554us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 8s 32ms/step - loss: 0.6912 - acc: 0.5331\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 662us/step - loss: 0.6786 - acc: 0.6240\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 733us/step - loss: 0.6625 - acc: 0.5992\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 726us/step - loss: 0.6485 - acc: 0.6033\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 714us/step - loss: 0.6336 - acc: 0.7107\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 708us/step - loss: 0.6119 - acc: 0.7603\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 740us/step - loss: 0.5859 - acc: 0.7686\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 733us/step - loss: 0.5595 - acc: 0.7727\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 745us/step - loss: 0.5339 - acc: 0.7727\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 743us/step - loss: 0.5109 - acc: 0.7893\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 687us/step - loss: 0.4879 - acc: 0.7851\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 670us/step - loss: 0.4699 - acc: 0.7851\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 733us/step - loss: 0.4528 - acc: 0.7975\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 706us/step - loss: 0.4416 - acc: 0.7810\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 723us/step - loss: 0.4270 - acc: 0.8017\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 753us/step - loss: 0.4228 - acc: 0.8058\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 744us/step - loss: 0.4173 - acc: 0.7893\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 698us/step - loss: 0.4082 - acc: 0.8017\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 727us/step - loss: 0.4042 - acc: 0.7934\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 785us/step - loss: 0.3994 - acc: 0.7934\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 764us/step - loss: 0.3937 - acc: 0.8140\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 768us/step - loss: 0.3931 - acc: 0.8140\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 714us/step - loss: 0.3861 - acc: 0.8182\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 747us/step - loss: 0.3852 - acc: 0.8099\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 760us/step - loss: 0.3868 - acc: 0.8099\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 777us/step - loss: 0.3819 - acc: 0.8140\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 744us/step - loss: 0.3806 - acc: 0.8099\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 763us/step - loss: 0.3778 - acc: 0.8223\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 702us/step - loss: 0.3762 - acc: 0.8306\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 660us/step - loss: 0.3743 - acc: 0.8140\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 777us/step - loss: 0.3739 - acc: 0.8264\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 747us/step - loss: 0.3737 - acc: 0.8140\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 692us/step - loss: 0.3716 - acc: 0.8388\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 729us/step - loss: 0.3751 - acc: 0.8182\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 719us/step - loss: 0.3698 - acc: 0.8306\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 657us/step - loss: 0.3713 - acc: 0.8347\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 775us/step - loss: 0.3726 - acc: 0.8347\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 729us/step - loss: 0.3675 - acc: 0.8347\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 709us/step - loss: 0.3699 - acc: 0.8347\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 737us/step - loss: 0.3699 - acc: 0.8388\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 699us/step - loss: 0.3649 - acc: 0.8306\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 721us/step - loss: 0.3663 - acc: 0.8388\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 724us/step - loss: 0.3667 - acc: 0.8471\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 690us/step - loss: 0.3704 - acc: 0.8306\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 717us/step - loss: 0.3696 - acc: 0.8388\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 701us/step - loss: 0.3638 - acc: 0.8388\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 680us/step - loss: 0.3615 - acc: 0.8471\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 732us/step - loss: 0.3598 - acc: 0.8430\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 746us/step - loss: 0.3639 - acc: 0.8512\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 716us/step - loss: 0.3652 - acc: 0.8554\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 735us/step - loss: 0.3622 - acc: 0.8471\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 734us/step - loss: 0.3611 - acc: 0.8595\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 719us/step - loss: 0.3681 - acc: 0.8471\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 849us/step - loss: 0.3603 - acc: 0.8512\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 820us/step - loss: 0.3654 - acc: 0.8388\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 763us/step - loss: 0.3577 - acc: 0.8595\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 748us/step - loss: 0.3599 - acc: 0.8430\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 697us/step - loss: 0.3605 - acc: 0.8554\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 811us/step - loss: 0.3608 - acc: 0.8554\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 805us/step - loss: 0.3583 - acc: 0.8430\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 750us/step - loss: 0.3654 - acc: 0.8347\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 733us/step - loss: 0.3620 - acc: 0.8554\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 776us/step - loss: 0.3600 - acc: 0.8595\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 813us/step - loss: 0.3610 - acc: 0.8512\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 807us/step - loss: 0.3597 - acc: 0.8595\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 771us/step - loss: 0.3567 - acc: 0.8554\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 756us/step - loss: 0.3577 - acc: 0.8636\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 726us/step - loss: 0.3586 - acc: 0.8719\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 736us/step - loss: 0.3580 - acc: 0.8595\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 728us/step - loss: 0.3565 - acc: 0.8595\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 761us/step - loss: 0.3570 - acc: 0.8554\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 751us/step - loss: 0.3611 - acc: 0.8595\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 739us/step - loss: 0.3612 - acc: 0.8636\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 737us/step - loss: 0.3591 - acc: 0.8471\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 808us/step - loss: 0.3574 - acc: 0.8595\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 775us/step - loss: 0.3560 - acc: 0.8678\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 744us/step - loss: 0.3596 - acc: 0.8512\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 762us/step - loss: 0.3585 - acc: 0.8595\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 759us/step - loss: 0.3589 - acc: 0.8471\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 802us/step - loss: 0.3603 - acc: 0.8471\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 860us/step - loss: 0.3593 - acc: 0.8430\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 813us/step - loss: 0.3587 - acc: 0.8554\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 784us/step - loss: 0.3561 - acc: 0.8388\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 868us/step - loss: 0.3585 - acc: 0.8554\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 799us/step - loss: 0.3537 - acc: 0.8595\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 800us/step - loss: 0.3535 - acc: 0.8595\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 783us/step - loss: 0.3562 - acc: 0.8595\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 795us/step - loss: 0.3545 - acc: 0.8512\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 786us/step - loss: 0.3568 - acc: 0.8595\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 807us/step - loss: 0.3622 - acc: 0.8595\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 840us/step - loss: 0.3577 - acc: 0.8554\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 760us/step - loss: 0.3523 - acc: 0.8636\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 775us/step - loss: 0.3602 - acc: 0.8719\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 678us/step - loss: 0.3536 - acc: 0.8554\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 770us/step - loss: 0.3549 - acc: 0.8595\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 770us/step - loss: 0.3561 - acc: 0.8512\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 781us/step - loss: 0.3573 - acc: 0.8595\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 815us/step - loss: 0.3578 - acc: 0.8512\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 791us/step - loss: 0.3546 - acc: 0.8595\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 739us/step - loss: 0.3553 - acc: 0.8595\n",
            "Best: 0.797521 using {'activation': 'sigmoid'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SUH1_54lho5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34411
        },
        "outputId": "d378ebd6-ec50-484d-b08b-67e10735a397"
      },
      "cell_type": "code",
      "source": [
        "# This one will tune # of epochs. \n",
        "epochs = np.array([50, 100, 150])\n",
        "\n",
        "def baseline(optimizer = \"adam\", init = \"uniform\", activation='sigmoid'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(39, input_dim=X.shape[1], activation=activation))\n",
        "  model.add(Dense(39, activation=activation))\n",
        "  model.add(Dense(1, activation=activation))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=baseline, batch_size=5, verbose=1)\n",
        "\n",
        "param_grid = dict(epochs=epochs)\n",
        "print(param_grid)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, )\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'epochs': array([ 50, 100, 150])}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "161/161 [==============================] - 8s 47ms/step - loss: 0.7228 - acc: 0.5528\n",
            "Epoch 2/50\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.6887 - acc: 0.5528\n",
            "Epoch 3/50\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.6845 - acc: 0.5528\n",
            "Epoch 4/50\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.6833 - acc: 0.5528\n",
            "Epoch 5/50\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.6767 - acc: 0.5528\n",
            "Epoch 6/50\n",
            "161/161 [==============================] - 0s 677us/step - loss: 0.6717 - acc: 0.5528\n",
            "Epoch 7/50\n",
            "161/161 [==============================] - 0s 754us/step - loss: 0.6673 - acc: 0.5528\n",
            "Epoch 8/50\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.6628 - acc: 0.6025\n",
            "Epoch 9/50\n",
            "161/161 [==============================] - 0s 656us/step - loss: 0.6554 - acc: 0.5776\n",
            "Epoch 10/50\n",
            "161/161 [==============================] - 0s 733us/step - loss: 0.6456 - acc: 0.7143\n",
            "Epoch 11/50\n",
            "161/161 [==============================] - 0s 677us/step - loss: 0.6342 - acc: 0.7329\n",
            "Epoch 12/50\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.6267 - acc: 0.6646\n",
            "Epoch 13/50\n",
            "161/161 [==============================] - 0s 716us/step - loss: 0.6165 - acc: 0.7702\n",
            "Epoch 14/50\n",
            "161/161 [==============================] - 0s 736us/step - loss: 0.6057 - acc: 0.7019\n",
            "Epoch 15/50\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.5883 - acc: 0.7950\n",
            "Epoch 16/50\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.5707 - acc: 0.8199\n",
            "Epoch 17/50\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.5580 - acc: 0.7702\n",
            "Epoch 18/50\n",
            "161/161 [==============================] - 0s 699us/step - loss: 0.5391 - acc: 0.7826\n",
            "Epoch 19/50\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.5227 - acc: 0.8012\n",
            "Epoch 20/50\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.5077 - acc: 0.7888\n",
            "Epoch 21/50\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.4911 - acc: 0.8012\n",
            "Epoch 22/50\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.4780 - acc: 0.7888\n",
            "Epoch 23/50\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.4689 - acc: 0.7950\n",
            "Epoch 24/50\n",
            "161/161 [==============================] - 0s 733us/step - loss: 0.4532 - acc: 0.7950\n",
            "Epoch 25/50\n",
            "161/161 [==============================] - 0s 687us/step - loss: 0.4428 - acc: 0.7950\n",
            "Epoch 26/50\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.4325 - acc: 0.7950\n",
            "Epoch 27/50\n",
            "161/161 [==============================] - 0s 663us/step - loss: 0.4247 - acc: 0.7950\n",
            "Epoch 28/50\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.4246 - acc: 0.7888\n",
            "Epoch 29/50\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.4127 - acc: 0.8012\n",
            "Epoch 30/50\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.4054 - acc: 0.7950\n",
            "Epoch 31/50\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.4018 - acc: 0.8137\n",
            "Epoch 32/50\n",
            "161/161 [==============================] - 0s 636us/step - loss: 0.4016 - acc: 0.7950\n",
            "Epoch 33/50\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.3922 - acc: 0.8012\n",
            "Epoch 34/50\n",
            "161/161 [==============================] - 0s 719us/step - loss: 0.3933 - acc: 0.8199\n",
            "Epoch 35/50\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.3908 - acc: 0.8137\n",
            "Epoch 36/50\n",
            "161/161 [==============================] - 0s 732us/step - loss: 0.3845 - acc: 0.8137\n",
            "Epoch 37/50\n",
            "161/161 [==============================] - 0s 736us/step - loss: 0.3784 - acc: 0.8137\n",
            "Epoch 38/50\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.3830 - acc: 0.8261\n",
            "Epoch 39/50\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.3773 - acc: 0.8261\n",
            "Epoch 40/50\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.3751 - acc: 0.8137\n",
            "Epoch 41/50\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.3747 - acc: 0.8323\n",
            "Epoch 42/50\n",
            "161/161 [==============================] - 0s 643us/step - loss: 0.3665 - acc: 0.8385\n",
            "Epoch 43/50\n",
            "161/161 [==============================] - 0s 793us/step - loss: 0.3654 - acc: 0.8323\n",
            "Epoch 44/50\n",
            "161/161 [==============================] - 0s 709us/step - loss: 0.3650 - acc: 0.8199\n",
            "Epoch 45/50\n",
            "161/161 [==============================] - 0s 775us/step - loss: 0.3600 - acc: 0.8385\n",
            "Epoch 46/50\n",
            "161/161 [==============================] - 0s 754us/step - loss: 0.3615 - acc: 0.8261\n",
            "Epoch 47/50\n",
            "161/161 [==============================] - 0s 817us/step - loss: 0.3616 - acc: 0.8385\n",
            "Epoch 48/50\n",
            "161/161 [==============================] - 0s 700us/step - loss: 0.3557 - acc: 0.8323\n",
            "Epoch 49/50\n",
            "161/161 [==============================] - 0s 684us/step - loss: 0.3550 - acc: 0.8385\n",
            "Epoch 50/50\n",
            "161/161 [==============================] - 0s 678us/step - loss: 0.3612 - acc: 0.8261\n",
            "81/81 [==============================] - 3s 40ms/step\n",
            "161/161 [==============================] - 0s 515us/step\n",
            "Epoch 1/50\n",
            "161/161 [==============================] - 8s 47ms/step - loss: 0.6971 - acc: 0.5342\n",
            "Epoch 2/50\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.6847 - acc: 0.6957\n",
            "Epoch 3/50\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.6752 - acc: 0.5652\n",
            "Epoch 4/50\n",
            "161/161 [==============================] - 0s 811us/step - loss: 0.6712 - acc: 0.5342\n",
            "Epoch 5/50\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.6645 - acc: 0.5839\n",
            "Epoch 6/50\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.6520 - acc: 0.6708\n",
            "Epoch 7/50\n",
            "161/161 [==============================] - 0s 789us/step - loss: 0.6423 - acc: 0.6894\n",
            "Epoch 8/50\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.6304 - acc: 0.7391\n",
            "Epoch 9/50\n",
            "161/161 [==============================] - 0s 738us/step - loss: 0.6216 - acc: 0.7888\n",
            "Epoch 10/50\n",
            "161/161 [==============================] - 0s 680us/step - loss: 0.6035 - acc: 0.8075\n",
            "Epoch 11/50\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.5841 - acc: 0.8075\n",
            "Epoch 12/50\n",
            "161/161 [==============================] - 0s 814us/step - loss: 0.5681 - acc: 0.7950\n",
            "Epoch 13/50\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.5463 - acc: 0.8199\n",
            "Epoch 14/50\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.5313 - acc: 0.8075\n",
            "Epoch 15/50\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.5106 - acc: 0.8012\n",
            "Epoch 16/50\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.4951 - acc: 0.7950\n",
            "Epoch 17/50\n",
            "161/161 [==============================] - 0s 752us/step - loss: 0.4791 - acc: 0.8137\n",
            "Epoch 18/50\n",
            "161/161 [==============================] - 0s 789us/step - loss: 0.4608 - acc: 0.8075\n",
            "Epoch 19/50\n",
            "161/161 [==============================] - 0s 816us/step - loss: 0.4475 - acc: 0.7888\n",
            "Epoch 20/50\n",
            "161/161 [==============================] - 0s 729us/step - loss: 0.4441 - acc: 0.7888\n",
            "Epoch 21/50\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.4357 - acc: 0.7950\n",
            "Epoch 22/50\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.4231 - acc: 0.8261\n",
            "Epoch 23/50\n",
            "161/161 [==============================] - 0s 729us/step - loss: 0.4120 - acc: 0.8012\n",
            "Epoch 24/50\n",
            "161/161 [==============================] - 0s 722us/step - loss: 0.4066 - acc: 0.8012\n",
            "Epoch 25/50\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.4059 - acc: 0.8137\n",
            "Epoch 26/50\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.3958 - acc: 0.8075\n",
            "Epoch 27/50\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.3917 - acc: 0.8012\n",
            "Epoch 28/50\n",
            "161/161 [==============================] - 0s 764us/step - loss: 0.3974 - acc: 0.8012\n",
            "Epoch 29/50\n",
            "161/161 [==============================] - 0s 687us/step - loss: 0.3834 - acc: 0.8199\n",
            "Epoch 30/50\n",
            "161/161 [==============================] - 0s 729us/step - loss: 0.3795 - acc: 0.8075\n",
            "Epoch 31/50\n",
            "161/161 [==============================] - 0s 797us/step - loss: 0.3824 - acc: 0.8199\n",
            "Epoch 32/50\n",
            "161/161 [==============================] - 0s 854us/step - loss: 0.3778 - acc: 0.8199\n",
            "Epoch 33/50\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.3733 - acc: 0.8323\n",
            "Epoch 34/50\n",
            "161/161 [==============================] - 0s 748us/step - loss: 0.3722 - acc: 0.8199\n",
            "Epoch 35/50\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.3715 - acc: 0.8075\n",
            "Epoch 36/50\n",
            "161/161 [==============================] - 0s 704us/step - loss: 0.3686 - acc: 0.8385\n",
            "Epoch 37/50\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.3635 - acc: 0.8385\n",
            "Epoch 38/50\n",
            "161/161 [==============================] - 0s 718us/step - loss: 0.3710 - acc: 0.8199\n",
            "Epoch 39/50\n",
            "161/161 [==============================] - 0s 653us/step - loss: 0.3649 - acc: 0.8447\n",
            "Epoch 40/50\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3614 - acc: 0.8323\n",
            "Epoch 41/50\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.3700 - acc: 0.8385\n",
            "Epoch 42/50\n",
            "161/161 [==============================] - 0s 705us/step - loss: 0.3562 - acc: 0.8509\n",
            "Epoch 43/50\n",
            "161/161 [==============================] - 0s 678us/step - loss: 0.3574 - acc: 0.8571\n",
            "Epoch 44/50\n",
            "161/161 [==============================] - 0s 676us/step - loss: 0.3647 - acc: 0.8261\n",
            "Epoch 45/50\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.3542 - acc: 0.8447\n",
            "Epoch 46/50\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.3575 - acc: 0.8447\n",
            "Epoch 47/50\n",
            "161/161 [==============================] - 0s 736us/step - loss: 0.3527 - acc: 0.8571\n",
            "Epoch 48/50\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.3630 - acc: 0.8447\n",
            "Epoch 49/50\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.3552 - acc: 0.8447\n",
            "Epoch 50/50\n",
            "161/161 [==============================] - 0s 713us/step - loss: 0.3558 - acc: 0.8447\n",
            "81/81 [==============================] - 3s 40ms/step\n",
            "161/161 [==============================] - 0s 543us/step\n",
            "Epoch 1/50\n",
            "162/162 [==============================] - 8s 48ms/step - loss: 0.7298 - acc: 0.5617\n",
            "Epoch 2/50\n",
            "162/162 [==============================] - 0s 652us/step - loss: 0.6809 - acc: 0.5617\n",
            "Epoch 3/50\n",
            "162/162 [==============================] - 0s 760us/step - loss: 0.6784 - acc: 0.5617\n",
            "Epoch 4/50\n",
            "162/162 [==============================] - 0s 700us/step - loss: 0.6774 - acc: 0.5617\n",
            "Epoch 5/50\n",
            "162/162 [==============================] - 0s 728us/step - loss: 0.6715 - acc: 0.6296\n",
            "Epoch 6/50\n",
            "162/162 [==============================] - 0s 826us/step - loss: 0.6629 - acc: 0.5617\n",
            "Epoch 7/50\n",
            "162/162 [==============================] - 0s 963us/step - loss: 0.6578 - acc: 0.5926\n",
            "Epoch 8/50\n",
            "162/162 [==============================] - 0s 912us/step - loss: 0.6509 - acc: 0.5679\n",
            "Epoch 9/50\n",
            "162/162 [==============================] - 0s 881us/step - loss: 0.6416 - acc: 0.6296\n",
            "Epoch 10/50\n",
            "162/162 [==============================] - 0s 883us/step - loss: 0.6396 - acc: 0.6852\n",
            "Epoch 11/50\n",
            "162/162 [==============================] - 0s 917us/step - loss: 0.6271 - acc: 0.6358\n",
            "Epoch 12/50\n",
            "162/162 [==============================] - 0s 927us/step - loss: 0.6116 - acc: 0.7407\n",
            "Epoch 13/50\n",
            "162/162 [==============================] - 0s 949us/step - loss: 0.6024 - acc: 0.7716\n",
            "Epoch 14/50\n",
            "162/162 [==============================] - 0s 939us/step - loss: 0.5849 - acc: 0.7469\n",
            "Epoch 15/50\n",
            "162/162 [==============================] - 0s 958us/step - loss: 0.5719 - acc: 0.7778\n",
            "Epoch 16/50\n",
            "162/162 [==============================] - 0s 936us/step - loss: 0.5564 - acc: 0.7901\n",
            "Epoch 17/50\n",
            "162/162 [==============================] - 0s 906us/step - loss: 0.5413 - acc: 0.7654\n",
            "Epoch 18/50\n",
            "162/162 [==============================] - 0s 866us/step - loss: 0.5283 - acc: 0.7778\n",
            "Epoch 19/50\n",
            "162/162 [==============================] - 0s 882us/step - loss: 0.5096 - acc: 0.8025\n",
            "Epoch 20/50\n",
            "162/162 [==============================] - 0s 985us/step - loss: 0.4949 - acc: 0.7963\n",
            "Epoch 21/50\n",
            "162/162 [==============================] - 0s 917us/step - loss: 0.4812 - acc: 0.8025\n",
            "Epoch 22/50\n",
            "162/162 [==============================] - 0s 856us/step - loss: 0.4704 - acc: 0.7963\n",
            "Epoch 23/50\n",
            "162/162 [==============================] - 0s 872us/step - loss: 0.4578 - acc: 0.8148\n",
            "Epoch 24/50\n",
            "162/162 [==============================] - 0s 870us/step - loss: 0.4490 - acc: 0.8148\n",
            "Epoch 25/50\n",
            "162/162 [==============================] - 0s 856us/step - loss: 0.4425 - acc: 0.7963\n",
            "Epoch 26/50\n",
            "162/162 [==============================] - 0s 833us/step - loss: 0.4336 - acc: 0.8210\n",
            "Epoch 27/50\n",
            "162/162 [==============================] - 0s 876us/step - loss: 0.4264 - acc: 0.8333\n",
            "Epoch 28/50\n",
            "162/162 [==============================] - 0s 901us/step - loss: 0.4184 - acc: 0.8272\n",
            "Epoch 29/50\n",
            "162/162 [==============================] - 0s 888us/step - loss: 0.4158 - acc: 0.8148\n",
            "Epoch 30/50\n",
            "162/162 [==============================] - 0s 896us/step - loss: 0.4097 - acc: 0.8210\n",
            "Epoch 31/50\n",
            "162/162 [==============================] - 0s 900us/step - loss: 0.4069 - acc: 0.8272\n",
            "Epoch 32/50\n",
            "162/162 [==============================] - 0s 882us/step - loss: 0.4048 - acc: 0.8333\n",
            "Epoch 33/50\n",
            "162/162 [==============================] - 0s 858us/step - loss: 0.4000 - acc: 0.8148\n",
            "Epoch 34/50\n",
            "162/162 [==============================] - 0s 851us/step - loss: 0.4053 - acc: 0.8148\n",
            "Epoch 35/50\n",
            "162/162 [==============================] - 0s 829us/step - loss: 0.3949 - acc: 0.8272\n",
            "Epoch 36/50\n",
            "162/162 [==============================] - 0s 912us/step - loss: 0.3920 - acc: 0.8395\n",
            "Epoch 37/50\n",
            "162/162 [==============================] - 0s 848us/step - loss: 0.3941 - acc: 0.8272\n",
            "Epoch 38/50\n",
            "162/162 [==============================] - 0s 903us/step - loss: 0.3942 - acc: 0.8272\n",
            "Epoch 39/50\n",
            "162/162 [==============================] - 0s 879us/step - loss: 0.3932 - acc: 0.8333\n",
            "Epoch 40/50\n",
            "162/162 [==============================] - 0s 882us/step - loss: 0.3862 - acc: 0.8148\n",
            "Epoch 41/50\n",
            "162/162 [==============================] - 0s 905us/step - loss: 0.3829 - acc: 0.8395\n",
            "Epoch 42/50\n",
            "162/162 [==============================] - 0s 918us/step - loss: 0.3872 - acc: 0.8210\n",
            "Epoch 43/50\n",
            "162/162 [==============================] - 0s 919us/step - loss: 0.3830 - acc: 0.8457\n",
            "Epoch 44/50\n",
            "162/162 [==============================] - 0s 878us/step - loss: 0.3815 - acc: 0.8272\n",
            "Epoch 45/50\n",
            "162/162 [==============================] - 0s 873us/step - loss: 0.3810 - acc: 0.8333\n",
            "Epoch 46/50\n",
            "162/162 [==============================] - 0s 863us/step - loss: 0.3790 - acc: 0.8333\n",
            "Epoch 47/50\n",
            "162/162 [==============================] - 0s 887us/step - loss: 0.3799 - acc: 0.8333\n",
            "Epoch 48/50\n",
            "162/162 [==============================] - 0s 948us/step - loss: 0.3777 - acc: 0.8457\n",
            "Epoch 49/50\n",
            "162/162 [==============================] - 0s 743us/step - loss: 0.3754 - acc: 0.8395\n",
            "Epoch 50/50\n",
            "162/162 [==============================] - 0s 665us/step - loss: 0.3753 - acc: 0.8333\n",
            "80/80 [==============================] - 3s 41ms/step\n",
            "162/162 [==============================] - 0s 568us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 8s 48ms/step - loss: 0.6972 - acc: 0.5031\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 841us/step - loss: 0.6845 - acc: 0.5528\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.6809 - acc: 0.5528\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 756us/step - loss: 0.6802 - acc: 0.5528\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 686us/step - loss: 0.6700 - acc: 0.6584\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 706us/step - loss: 0.6629 - acc: 0.5901\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.6546 - acc: 0.6398\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 724us/step - loss: 0.6457 - acc: 0.6957\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 794us/step - loss: 0.6360 - acc: 0.6273\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 771us/step - loss: 0.6209 - acc: 0.6398\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.6174 - acc: 0.7453\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 736us/step - loss: 0.5860 - acc: 0.7516\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.5704 - acc: 0.7764\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 741us/step - loss: 0.5534 - acc: 0.7888\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 724us/step - loss: 0.5366 - acc: 0.8012\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.5186 - acc: 0.7826\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.5032 - acc: 0.7950\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 692us/step - loss: 0.4850 - acc: 0.7826\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.4681 - acc: 0.7888\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.4597 - acc: 0.7950\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.4523 - acc: 0.8075\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.4385 - acc: 0.8075\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 644us/step - loss: 0.4302 - acc: 0.8012\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.4195 - acc: 0.8075\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 642us/step - loss: 0.4135 - acc: 0.8075\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 707us/step - loss: 0.4068 - acc: 0.7950\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.4015 - acc: 0.7950\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 697us/step - loss: 0.4028 - acc: 0.8075\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.3911 - acc: 0.8199\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.3921 - acc: 0.8199\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 645us/step - loss: 0.3888 - acc: 0.8385\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 718us/step - loss: 0.3826 - acc: 0.8199\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.3784 - acc: 0.8261\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.3784 - acc: 0.8261\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.3840 - acc: 0.8261\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.3695 - acc: 0.8323\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 733us/step - loss: 0.3734 - acc: 0.8261\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 640us/step - loss: 0.3635 - acc: 0.8447\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.3685 - acc: 0.8261\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.3669 - acc: 0.8509\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 745us/step - loss: 0.3600 - acc: 0.8447\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 810us/step - loss: 0.3597 - acc: 0.8385\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 718us/step - loss: 0.3626 - acc: 0.8323\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.3533 - acc: 0.8571\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 686us/step - loss: 0.3554 - acc: 0.8385\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 699us/step - loss: 0.3514 - acc: 0.8447\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.3517 - acc: 0.8323\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 703us/step - loss: 0.3496 - acc: 0.8447\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.3486 - acc: 0.8447\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.3534 - acc: 0.8323\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 724us/step - loss: 0.3460 - acc: 0.8447\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.3440 - acc: 0.8571\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 783us/step - loss: 0.3540 - acc: 0.8261\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 771us/step - loss: 0.3433 - acc: 0.8385\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 713us/step - loss: 0.3442 - acc: 0.8447\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.3447 - acc: 0.8323\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 719us/step - loss: 0.3407 - acc: 0.8571\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.3423 - acc: 0.8634\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.3552 - acc: 0.8447\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 671us/step - loss: 0.3403 - acc: 0.8261\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.3437 - acc: 0.8385\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 699us/step - loss: 0.3395 - acc: 0.8447\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 700us/step - loss: 0.3363 - acc: 0.8509\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 701us/step - loss: 0.3364 - acc: 0.8323\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 683us/step - loss: 0.3337 - acc: 0.8447\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 650us/step - loss: 0.3351 - acc: 0.8758\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 686us/step - loss: 0.3316 - acc: 0.8385\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 647us/step - loss: 0.3349 - acc: 0.8634\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 795us/step - loss: 0.3305 - acc: 0.8571\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.3314 - acc: 0.8571\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.3312 - acc: 0.8385\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.3302 - acc: 0.8634\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3308 - acc: 0.8385\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 677us/step - loss: 0.3335 - acc: 0.8571\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 689us/step - loss: 0.3319 - acc: 0.8385\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.3278 - acc: 0.8571\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 680us/step - loss: 0.3311 - acc: 0.8509\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 701us/step - loss: 0.3322 - acc: 0.8571\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 666us/step - loss: 0.3309 - acc: 0.8634\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.3279 - acc: 0.8385\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.3291 - acc: 0.8634\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 710us/step - loss: 0.3224 - acc: 0.8571\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 745us/step - loss: 0.3272 - acc: 0.8571\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.3230 - acc: 0.8509\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 770us/step - loss: 0.3297 - acc: 0.8447\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 802us/step - loss: 0.3210 - acc: 0.8696\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 794us/step - loss: 0.3301 - acc: 0.8696\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 790us/step - loss: 0.3223 - acc: 0.8447\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.3327 - acc: 0.8447\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 709us/step - loss: 0.3207 - acc: 0.8634\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 705us/step - loss: 0.3224 - acc: 0.8509\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.3210 - acc: 0.8634\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 714us/step - loss: 0.3206 - acc: 0.8571\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 666us/step - loss: 0.3231 - acc: 0.8696\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.3219 - acc: 0.8696\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 691us/step - loss: 0.3194 - acc: 0.8571\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 765us/step - loss: 0.3181 - acc: 0.8447\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3174 - acc: 0.8571\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.3295 - acc: 0.8509\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.3210 - acc: 0.8509\n",
            "81/81 [==============================] - 3s 41ms/step\n",
            "161/161 [==============================] - 0s 533us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 8s 48ms/step - loss: 0.7019 - acc: 0.4969\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.6980 - acc: 0.5342\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 706us/step - loss: 0.6905 - acc: 0.5404\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.6846 - acc: 0.5590\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 669us/step - loss: 0.6761 - acc: 0.7019\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 719us/step - loss: 0.6698 - acc: 0.7516\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 659us/step - loss: 0.6576 - acc: 0.7391\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 778us/step - loss: 0.6494 - acc: 0.7578\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 686us/step - loss: 0.6377 - acc: 0.7950\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.6215 - acc: 0.7702\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.6139 - acc: 0.7516\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 745us/step - loss: 0.5889 - acc: 0.7950\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.5740 - acc: 0.7950\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 731us/step - loss: 0.5532 - acc: 0.8199\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 777us/step - loss: 0.5392 - acc: 0.8012\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.5191 - acc: 0.8199\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.5040 - acc: 0.7950\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 737us/step - loss: 0.4896 - acc: 0.8261\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.4715 - acc: 0.8012\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 707us/step - loss: 0.4584 - acc: 0.8012\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 744us/step - loss: 0.4471 - acc: 0.8137\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.4429 - acc: 0.8199\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.4310 - acc: 0.8012\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 634us/step - loss: 0.4185 - acc: 0.8075\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 733us/step - loss: 0.4156 - acc: 0.8075\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 796us/step - loss: 0.4066 - acc: 0.8075\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 700us/step - loss: 0.3980 - acc: 0.8199\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 756us/step - loss: 0.3943 - acc: 0.8137\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3934 - acc: 0.8199\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 687us/step - loss: 0.3914 - acc: 0.8199\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.3847 - acc: 0.8075\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 756us/step - loss: 0.3797 - acc: 0.8261\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 764us/step - loss: 0.3827 - acc: 0.8385\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 777us/step - loss: 0.3771 - acc: 0.8137\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 760us/step - loss: 0.3743 - acc: 0.8137\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.3683 - acc: 0.8261\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 737us/step - loss: 0.3720 - acc: 0.8447\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 745us/step - loss: 0.3673 - acc: 0.8385\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 788us/step - loss: 0.3636 - acc: 0.8323\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 807us/step - loss: 0.3625 - acc: 0.8447\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 785us/step - loss: 0.3598 - acc: 0.8447\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 775us/step - loss: 0.3601 - acc: 0.8447\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.3563 - acc: 0.8571\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 658us/step - loss: 0.3591 - acc: 0.8447\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 732us/step - loss: 0.3553 - acc: 0.8571\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.3552 - acc: 0.8509\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 715us/step - loss: 0.3524 - acc: 0.8571\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 732us/step - loss: 0.3546 - acc: 0.8571\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 766us/step - loss: 0.3533 - acc: 0.8447\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 764us/step - loss: 0.3507 - acc: 0.8571\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 651us/step - loss: 0.3489 - acc: 0.8571\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.3509 - acc: 0.8509\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 717us/step - loss: 0.3500 - acc: 0.8509\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 767us/step - loss: 0.3478 - acc: 0.8634\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.3485 - acc: 0.8447\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 800us/step - loss: 0.3528 - acc: 0.8634\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 875us/step - loss: 0.3512 - acc: 0.8634\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 779us/step - loss: 0.3496 - acc: 0.8571\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 837us/step - loss: 0.3554 - acc: 0.8509\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 751us/step - loss: 0.3512 - acc: 0.8447\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 801us/step - loss: 0.3429 - acc: 0.8634\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.3472 - acc: 0.8634\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 760us/step - loss: 0.3431 - acc: 0.8634\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.3407 - acc: 0.8634\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 837us/step - loss: 0.3432 - acc: 0.8634\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 793us/step - loss: 0.3439 - acc: 0.8634\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 812us/step - loss: 0.3404 - acc: 0.8571\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 828us/step - loss: 0.3428 - acc: 0.8634\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 825us/step - loss: 0.3417 - acc: 0.8634\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 832us/step - loss: 0.3411 - acc: 0.8696\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 832us/step - loss: 0.3391 - acc: 0.8634\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 795us/step - loss: 0.3409 - acc: 0.8571\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 787us/step - loss: 0.3392 - acc: 0.8634\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 870us/step - loss: 0.3447 - acc: 0.8696\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 799us/step - loss: 0.3395 - acc: 0.8634\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.3412 - acc: 0.8571\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 803us/step - loss: 0.3425 - acc: 0.8509\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 798us/step - loss: 0.3393 - acc: 0.8571\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.3367 - acc: 0.8634\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 802us/step - loss: 0.3349 - acc: 0.8571\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 799us/step - loss: 0.3349 - acc: 0.8696\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3395 - acc: 0.8634\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 791us/step - loss: 0.3364 - acc: 0.8634\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.3377 - acc: 0.8696\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 709us/step - loss: 0.3356 - acc: 0.8634\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.3362 - acc: 0.8696\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 754us/step - loss: 0.3429 - acc: 0.8571\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.3383 - acc: 0.8634\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.3350 - acc: 0.8634\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.3353 - acc: 0.8634\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 710us/step - loss: 0.3367 - acc: 0.8634\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.3369 - acc: 0.8696\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 679us/step - loss: 0.3367 - acc: 0.8571\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.3367 - acc: 0.8696\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 722us/step - loss: 0.3427 - acc: 0.8696\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 700us/step - loss: 0.3393 - acc: 0.8758\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.3344 - acc: 0.8634\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 756us/step - loss: 0.3350 - acc: 0.8696\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.3350 - acc: 0.8634\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 667us/step - loss: 0.3351 - acc: 0.8758\n",
            "81/81 [==============================] - 3s 42ms/step\n",
            "161/161 [==============================] - 0s 543us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 8s 49ms/step - loss: 0.6910 - acc: 0.5617\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 765us/step - loss: 0.6859 - acc: 0.5556\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 715us/step - loss: 0.6794 - acc: 0.5617\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 727us/step - loss: 0.6756 - acc: 0.5617\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 653us/step - loss: 0.6691 - acc: 0.5617\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 756us/step - loss: 0.6625 - acc: 0.5741\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 754us/step - loss: 0.6564 - acc: 0.6111\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 705us/step - loss: 0.6475 - acc: 0.5988\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 800us/step - loss: 0.6352 - acc: 0.5864\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 760us/step - loss: 0.6250 - acc: 0.6790\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 801us/step - loss: 0.6166 - acc: 0.7222\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 740us/step - loss: 0.5979 - acc: 0.7160\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 676us/step - loss: 0.5856 - acc: 0.7284\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 733us/step - loss: 0.5654 - acc: 0.7901\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 741us/step - loss: 0.5528 - acc: 0.7469\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 807us/step - loss: 0.5368 - acc: 0.7840\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 787us/step - loss: 0.5199 - acc: 0.7716\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 778us/step - loss: 0.5039 - acc: 0.8025\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 749us/step - loss: 0.4885 - acc: 0.7901\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 809us/step - loss: 0.4736 - acc: 0.8086\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 760us/step - loss: 0.4757 - acc: 0.8086\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 834us/step - loss: 0.4563 - acc: 0.8086\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 802us/step - loss: 0.4493 - acc: 0.8025\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 828us/step - loss: 0.4364 - acc: 0.8333\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 801us/step - loss: 0.4317 - acc: 0.8148\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 787us/step - loss: 0.4218 - acc: 0.8210\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 801us/step - loss: 0.4186 - acc: 0.8210\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 795us/step - loss: 0.4110 - acc: 0.8457\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 821us/step - loss: 0.4070 - acc: 0.8148\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 829us/step - loss: 0.4139 - acc: 0.8086\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 870us/step - loss: 0.4011 - acc: 0.8272\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 803us/step - loss: 0.3953 - acc: 0.8148\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 806us/step - loss: 0.3955 - acc: 0.8210\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 788us/step - loss: 0.3927 - acc: 0.8210\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 769us/step - loss: 0.3890 - acc: 0.8333\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 808us/step - loss: 0.3887 - acc: 0.8272\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 790us/step - loss: 0.3838 - acc: 0.8272\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 838us/step - loss: 0.3818 - acc: 0.8395\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 772us/step - loss: 0.3790 - acc: 0.8272\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 780us/step - loss: 0.3790 - acc: 0.8333\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 769us/step - loss: 0.3767 - acc: 0.8395\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 738us/step - loss: 0.3798 - acc: 0.8457\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 688us/step - loss: 0.3786 - acc: 0.8519\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 732us/step - loss: 0.3751 - acc: 0.8395\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 707us/step - loss: 0.3726 - acc: 0.8395\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 665us/step - loss: 0.3729 - acc: 0.8395\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 755us/step - loss: 0.3709 - acc: 0.8519\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 755us/step - loss: 0.3726 - acc: 0.8395\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 723us/step - loss: 0.3761 - acc: 0.8457\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 726us/step - loss: 0.3704 - acc: 0.8333\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 723us/step - loss: 0.3697 - acc: 0.8457\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 784us/step - loss: 0.3706 - acc: 0.8395\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 774us/step - loss: 0.3681 - acc: 0.8519\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 761us/step - loss: 0.3680 - acc: 0.8457\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 756us/step - loss: 0.3674 - acc: 0.8519\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 834us/step - loss: 0.3655 - acc: 0.8457\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 734us/step - loss: 0.3667 - acc: 0.8519\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 728us/step - loss: 0.3664 - acc: 0.8580\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 671us/step - loss: 0.3681 - acc: 0.8333\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 747us/step - loss: 0.3704 - acc: 0.8333\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 693us/step - loss: 0.3706 - acc: 0.8457\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 758us/step - loss: 0.3697 - acc: 0.8395\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 728us/step - loss: 0.3756 - acc: 0.8580\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 712us/step - loss: 0.3713 - acc: 0.8457\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 721us/step - loss: 0.3657 - acc: 0.8519\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 736us/step - loss: 0.3664 - acc: 0.8580\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 702us/step - loss: 0.3646 - acc: 0.8519\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 748us/step - loss: 0.3653 - acc: 0.8580\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 668us/step - loss: 0.3635 - acc: 0.8580\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 704us/step - loss: 0.3629 - acc: 0.8519\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 722us/step - loss: 0.3640 - acc: 0.8580\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 661us/step - loss: 0.3659 - acc: 0.8519\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 849us/step - loss: 0.3633 - acc: 0.8580\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 730us/step - loss: 0.3656 - acc: 0.8519\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 742us/step - loss: 0.3611 - acc: 0.8519\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 738us/step - loss: 0.3619 - acc: 0.8519\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 789us/step - loss: 0.3625 - acc: 0.8519\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 728us/step - loss: 0.3612 - acc: 0.8519\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 811us/step - loss: 0.3616 - acc: 0.8580\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 803us/step - loss: 0.3652 - acc: 0.8457\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 757us/step - loss: 0.3624 - acc: 0.8457\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 768us/step - loss: 0.3592 - acc: 0.8580\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 784us/step - loss: 0.3613 - acc: 0.8580\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 797us/step - loss: 0.3616 - acc: 0.8580\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 752us/step - loss: 0.3597 - acc: 0.8519\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 776us/step - loss: 0.3603 - acc: 0.8519\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 748us/step - loss: 0.3628 - acc: 0.8457\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 756us/step - loss: 0.3678 - acc: 0.8580\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 702us/step - loss: 0.3590 - acc: 0.8642\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 763us/step - loss: 0.3635 - acc: 0.8519\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 726us/step - loss: 0.3606 - acc: 0.8580\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 717us/step - loss: 0.3632 - acc: 0.8519\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 726us/step - loss: 0.3612 - acc: 0.8580\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 754us/step - loss: 0.3667 - acc: 0.8333\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 796us/step - loss: 0.3643 - acc: 0.8395\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 784us/step - loss: 0.3622 - acc: 0.8519\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 744us/step - loss: 0.3617 - acc: 0.8580\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 671us/step - loss: 0.3602 - acc: 0.8580\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 732us/step - loss: 0.3601 - acc: 0.8457\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 784us/step - loss: 0.3607 - acc: 0.8519\n",
            "80/80 [==============================] - 3s 43ms/step\n",
            "162/162 [==============================] - 0s 557us/step\n",
            "Epoch 1/150\n",
            "161/161 [==============================] - 8s 50ms/step - loss: 0.6937 - acc: 0.5528\n",
            "Epoch 2/150\n",
            "161/161 [==============================] - 0s 776us/step - loss: 0.6813 - acc: 0.5528\n",
            "Epoch 3/150\n",
            "161/161 [==============================] - 0s 816us/step - loss: 0.6774 - acc: 0.5528\n",
            "Epoch 4/150\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.6707 - acc: 0.5528\n",
            "Epoch 5/150\n",
            "161/161 [==============================] - 0s 794us/step - loss: 0.6701 - acc: 0.6584\n",
            "Epoch 6/150\n",
            "161/161 [==============================] - 0s 772us/step - loss: 0.6609 - acc: 0.6770\n",
            "Epoch 7/150\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.6544 - acc: 0.5839\n",
            "Epoch 8/150\n",
            "161/161 [==============================] - 0s 698us/step - loss: 0.6456 - acc: 0.7329\n",
            "Epoch 9/150\n",
            "161/161 [==============================] - 0s 704us/step - loss: 0.6383 - acc: 0.6149\n",
            "Epoch 10/150\n",
            "161/161 [==============================] - 0s 677us/step - loss: 0.6198 - acc: 0.7453\n",
            "Epoch 11/150\n",
            "161/161 [==============================] - 0s 737us/step - loss: 0.6074 - acc: 0.7578\n",
            "Epoch 12/150\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.5877 - acc: 0.7702\n",
            "Epoch 13/150\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.5714 - acc: 0.7888\n",
            "Epoch 14/150\n",
            "161/161 [==============================] - 0s 866us/step - loss: 0.5548 - acc: 0.7826\n",
            "Epoch 15/150\n",
            "161/161 [==============================] - 0s 679us/step - loss: 0.5397 - acc: 0.7764\n",
            "Epoch 16/150\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.5185 - acc: 0.7888\n",
            "Epoch 17/150\n",
            "161/161 [==============================] - 0s 732us/step - loss: 0.4994 - acc: 0.7888\n",
            "Epoch 18/150\n",
            "161/161 [==============================] - 0s 745us/step - loss: 0.4897 - acc: 0.8075\n",
            "Epoch 19/150\n",
            "161/161 [==============================] - 0s 723us/step - loss: 0.4762 - acc: 0.7950\n",
            "Epoch 20/150\n",
            "161/161 [==============================] - 0s 705us/step - loss: 0.4563 - acc: 0.8137\n",
            "Epoch 21/150\n",
            "161/161 [==============================] - 0s 757us/step - loss: 0.4444 - acc: 0.7950\n",
            "Epoch 22/150\n",
            "161/161 [==============================] - 0s 715us/step - loss: 0.4389 - acc: 0.7888\n",
            "Epoch 23/150\n",
            "161/161 [==============================] - 0s 767us/step - loss: 0.4302 - acc: 0.8075\n",
            "Epoch 24/150\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.4227 - acc: 0.8075\n",
            "Epoch 25/150\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.4163 - acc: 0.8012\n",
            "Epoch 26/150\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.4054 - acc: 0.8075\n",
            "Epoch 27/150\n",
            "161/161 [==============================] - 0s 718us/step - loss: 0.4023 - acc: 0.8075\n",
            "Epoch 28/150\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.3954 - acc: 0.8012\n",
            "Epoch 29/150\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.3930 - acc: 0.8075\n",
            "Epoch 30/150\n",
            "161/161 [==============================] - 0s 741us/step - loss: 0.3869 - acc: 0.8137\n",
            "Epoch 31/150\n",
            "161/161 [==============================] - 0s 744us/step - loss: 0.3817 - acc: 0.8075\n",
            "Epoch 32/150\n",
            "161/161 [==============================] - 0s 733us/step - loss: 0.3786 - acc: 0.8137\n",
            "Epoch 33/150\n",
            "161/161 [==============================] - 0s 702us/step - loss: 0.3800 - acc: 0.8261\n",
            "Epoch 34/150\n",
            "161/161 [==============================] - 0s 752us/step - loss: 0.3750 - acc: 0.8199\n",
            "Epoch 35/150\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.3755 - acc: 0.8261\n",
            "Epoch 36/150\n",
            "161/161 [==============================] - 0s 673us/step - loss: 0.3672 - acc: 0.8199\n",
            "Epoch 37/150\n",
            "161/161 [==============================] - 0s 664us/step - loss: 0.3673 - acc: 0.8261\n",
            "Epoch 38/150\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3662 - acc: 0.8323\n",
            "Epoch 39/150\n",
            "161/161 [==============================] - 0s 767us/step - loss: 0.3616 - acc: 0.8385\n",
            "Epoch 40/150\n",
            "161/161 [==============================] - 0s 702us/step - loss: 0.3594 - acc: 0.8447\n",
            "Epoch 41/150\n",
            "161/161 [==============================] - 0s 741us/step - loss: 0.3673 - acc: 0.8137\n",
            "Epoch 42/150\n",
            "161/161 [==============================] - 0s 680us/step - loss: 0.3560 - acc: 0.8509\n",
            "Epoch 43/150\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.3545 - acc: 0.8385\n",
            "Epoch 44/150\n",
            "161/161 [==============================] - 0s 703us/step - loss: 0.3633 - acc: 0.8385\n",
            "Epoch 45/150\n",
            "161/161 [==============================] - 0s 779us/step - loss: 0.3580 - acc: 0.8323\n",
            "Epoch 46/150\n",
            "161/161 [==============================] - 0s 760us/step - loss: 0.3508 - acc: 0.8509\n",
            "Epoch 47/150\n",
            "161/161 [==============================] - 0s 770us/step - loss: 0.3484 - acc: 0.8571\n",
            "Epoch 48/150\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.3527 - acc: 0.8261\n",
            "Epoch 49/150\n",
            "161/161 [==============================] - 0s 700us/step - loss: 0.3462 - acc: 0.8323\n",
            "Epoch 50/150\n",
            "161/161 [==============================] - 0s 752us/step - loss: 0.3535 - acc: 0.8571\n",
            "Epoch 51/150\n",
            "161/161 [==============================] - 0s 709us/step - loss: 0.3468 - acc: 0.8323\n",
            "Epoch 52/150\n",
            "161/161 [==============================] - 0s 719us/step - loss: 0.3445 - acc: 0.8509\n",
            "Epoch 53/150\n",
            "161/161 [==============================] - 0s 707us/step - loss: 0.3413 - acc: 0.8571\n",
            "Epoch 54/150\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.3416 - acc: 0.8634\n",
            "Epoch 55/150\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.3418 - acc: 0.8385\n",
            "Epoch 56/150\n",
            "161/161 [==============================] - 0s 741us/step - loss: 0.3383 - acc: 0.8447\n",
            "Epoch 57/150\n",
            "161/161 [==============================] - 0s 703us/step - loss: 0.3396 - acc: 0.8447\n",
            "Epoch 58/150\n",
            "161/161 [==============================] - 0s 693us/step - loss: 0.3375 - acc: 0.8385\n",
            "Epoch 59/150\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.3383 - acc: 0.8634\n",
            "Epoch 60/150\n",
            "161/161 [==============================] - 0s 733us/step - loss: 0.3392 - acc: 0.8323\n",
            "Epoch 61/150\n",
            "161/161 [==============================] - 0s 731us/step - loss: 0.3394 - acc: 0.8634\n",
            "Epoch 62/150\n",
            "161/161 [==============================] - 0s 652us/step - loss: 0.3317 - acc: 0.8509\n",
            "Epoch 63/150\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.3354 - acc: 0.8385\n",
            "Epoch 64/150\n",
            "161/161 [==============================] - 0s 670us/step - loss: 0.3316 - acc: 0.8509\n",
            "Epoch 65/150\n",
            "161/161 [==============================] - 0s 713us/step - loss: 0.3333 - acc: 0.8447\n",
            "Epoch 66/150\n",
            "161/161 [==============================] - 0s 730us/step - loss: 0.3294 - acc: 0.8447\n",
            "Epoch 67/150\n",
            "161/161 [==============================] - 0s 714us/step - loss: 0.3392 - acc: 0.8634\n",
            "Epoch 68/150\n",
            "161/161 [==============================] - 0s 675us/step - loss: 0.3305 - acc: 0.8447\n",
            "Epoch 69/150\n",
            "161/161 [==============================] - 0s 682us/step - loss: 0.3261 - acc: 0.8571\n",
            "Epoch 70/150\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.3261 - acc: 0.8571\n",
            "Epoch 71/150\n",
            "161/161 [==============================] - 0s 678us/step - loss: 0.3279 - acc: 0.8571\n",
            "Epoch 72/150\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3283 - acc: 0.8447\n",
            "Epoch 73/150\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.3253 - acc: 0.8571\n",
            "Epoch 74/150\n",
            "161/161 [==============================] - 0s 736us/step - loss: 0.3273 - acc: 0.8571\n",
            "Epoch 75/150\n",
            "161/161 [==============================] - 0s 760us/step - loss: 0.3253 - acc: 0.8509\n",
            "Epoch 76/150\n",
            "161/161 [==============================] - 0s 694us/step - loss: 0.3329 - acc: 0.8323\n",
            "Epoch 77/150\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.3224 - acc: 0.8385\n",
            "Epoch 78/150\n",
            "161/161 [==============================] - 0s 715us/step - loss: 0.3198 - acc: 0.8571\n",
            "Epoch 79/150\n",
            "161/161 [==============================] - 0s 770us/step - loss: 0.3268 - acc: 0.8696\n",
            "Epoch 80/150\n",
            "161/161 [==============================] - 0s 802us/step - loss: 0.3206 - acc: 0.8571\n",
            "Epoch 81/150\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.3220 - acc: 0.8634\n",
            "Epoch 82/150\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.3214 - acc: 0.8571\n",
            "Epoch 83/150\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.3223 - acc: 0.8571\n",
            "Epoch 84/150\n",
            "161/161 [==============================] - 0s 781us/step - loss: 0.3205 - acc: 0.8509\n",
            "Epoch 85/150\n",
            "161/161 [==============================] - 0s 713us/step - loss: 0.3213 - acc: 0.8571\n",
            "Epoch 86/150\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.3237 - acc: 0.8571\n",
            "Epoch 87/150\n",
            "161/161 [==============================] - 0s 775us/step - loss: 0.3237 - acc: 0.8447\n",
            "Epoch 88/150\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.3208 - acc: 0.8447\n",
            "Epoch 89/150\n",
            "161/161 [==============================] - 0s 768us/step - loss: 0.3174 - acc: 0.8634\n",
            "Epoch 90/150\n",
            "161/161 [==============================] - 0s 834us/step - loss: 0.3160 - acc: 0.8634\n",
            "Epoch 91/150\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.3175 - acc: 0.8509\n",
            "Epoch 92/150\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.3152 - acc: 0.8634\n",
            "Epoch 93/150\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.3159 - acc: 0.8634\n",
            "Epoch 94/150\n",
            "161/161 [==============================] - 0s 741us/step - loss: 0.3167 - acc: 0.8820\n",
            "Epoch 95/150\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.3160 - acc: 0.8634\n",
            "Epoch 96/150\n",
            "161/161 [==============================] - 0s 714us/step - loss: 0.3159 - acc: 0.8696\n",
            "Epoch 97/150\n",
            "161/161 [==============================] - 0s 743us/step - loss: 0.3182 - acc: 0.8696\n",
            "Epoch 98/150\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.3183 - acc: 0.8634\n",
            "Epoch 99/150\n",
            "161/161 [==============================] - 0s 657us/step - loss: 0.3143 - acc: 0.8634\n",
            "Epoch 100/150\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3159 - acc: 0.8758\n",
            "Epoch 101/150\n",
            "161/161 [==============================] - 0s 757us/step - loss: 0.3149 - acc: 0.8634\n",
            "Epoch 102/150\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.3131 - acc: 0.8571\n",
            "Epoch 103/150\n",
            "161/161 [==============================] - 0s 743us/step - loss: 0.3183 - acc: 0.8820\n",
            "Epoch 104/150\n",
            "161/161 [==============================] - 0s 718us/step - loss: 0.3158 - acc: 0.8571\n",
            "Epoch 105/150\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.3180 - acc: 0.8696\n",
            "Epoch 106/150\n",
            "161/161 [==============================] - 0s 787us/step - loss: 0.3166 - acc: 0.8634\n",
            "Epoch 107/150\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.3122 - acc: 0.8696\n",
            "Epoch 108/150\n",
            "161/161 [==============================] - 0s 757us/step - loss: 0.3203 - acc: 0.8571\n",
            "Epoch 109/150\n",
            "161/161 [==============================] - 0s 771us/step - loss: 0.3108 - acc: 0.8820\n",
            "Epoch 110/150\n",
            "161/161 [==============================] - 0s 743us/step - loss: 0.3181 - acc: 0.8634\n",
            "Epoch 111/150\n",
            "161/161 [==============================] - 0s 716us/step - loss: 0.3109 - acc: 0.8634\n",
            "Epoch 112/150\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3106 - acc: 0.8571\n",
            "Epoch 113/150\n",
            "161/161 [==============================] - 0s 777us/step - loss: 0.3101 - acc: 0.8634\n",
            "Epoch 114/150\n",
            "161/161 [==============================] - 0s 794us/step - loss: 0.3100 - acc: 0.8634\n",
            "Epoch 115/150\n",
            "161/161 [==============================] - 0s 808us/step - loss: 0.3101 - acc: 0.8696\n",
            "Epoch 116/150\n",
            "161/161 [==============================] - 0s 800us/step - loss: 0.3123 - acc: 0.8571\n",
            "Epoch 117/150\n",
            "161/161 [==============================] - 0s 775us/step - loss: 0.3090 - acc: 0.8571\n",
            "Epoch 118/150\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.3090 - acc: 0.8696\n",
            "Epoch 119/150\n",
            "161/161 [==============================] - 0s 771us/step - loss: 0.3074 - acc: 0.8634\n",
            "Epoch 120/150\n",
            "161/161 [==============================] - 0s 804us/step - loss: 0.3088 - acc: 0.8696\n",
            "Epoch 121/150\n",
            "161/161 [==============================] - 0s 821us/step - loss: 0.3128 - acc: 0.8882\n",
            "Epoch 122/150\n",
            "161/161 [==============================] - 0s 788us/step - loss: 0.3097 - acc: 0.8696\n",
            "Epoch 123/150\n",
            "161/161 [==============================] - 0s 795us/step - loss: 0.3120 - acc: 0.8634\n",
            "Epoch 124/150\n",
            "161/161 [==============================] - 0s 820us/step - loss: 0.3069 - acc: 0.8882\n",
            "Epoch 125/150\n",
            "161/161 [==============================] - 0s 798us/step - loss: 0.3061 - acc: 0.8758\n",
            "Epoch 126/150\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3068 - acc: 0.8820\n",
            "Epoch 127/150\n",
            "161/161 [==============================] - 0s 791us/step - loss: 0.3068 - acc: 0.8634\n",
            "Epoch 128/150\n",
            "161/161 [==============================] - 0s 757us/step - loss: 0.3115 - acc: 0.8882\n",
            "Epoch 129/150\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.3051 - acc: 0.8696\n",
            "Epoch 130/150\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.3099 - acc: 0.8634\n",
            "Epoch 131/150\n",
            "161/161 [==============================] - 0s 719us/step - loss: 0.3056 - acc: 0.8696\n",
            "Epoch 132/150\n",
            "161/161 [==============================] - 0s 719us/step - loss: 0.3053 - acc: 0.8634\n",
            "Epoch 133/150\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.3040 - acc: 0.8820\n",
            "Epoch 134/150\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.3059 - acc: 0.8820\n",
            "Epoch 135/150\n",
            "161/161 [==============================] - 0s 770us/step - loss: 0.3053 - acc: 0.8634\n",
            "Epoch 136/150\n",
            "161/161 [==============================] - 0s 723us/step - loss: 0.3078 - acc: 0.8634\n",
            "Epoch 137/150\n",
            "161/161 [==============================] - 0s 729us/step - loss: 0.3065 - acc: 0.8820\n",
            "Epoch 138/150\n",
            "161/161 [==============================] - 0s 837us/step - loss: 0.3062 - acc: 0.8634\n",
            "Epoch 139/150\n",
            "161/161 [==============================] - 0s 730us/step - loss: 0.3130 - acc: 0.8634\n",
            "Epoch 140/150\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.3121 - acc: 0.8696\n",
            "Epoch 141/150\n",
            "161/161 [==============================] - 0s 771us/step - loss: 0.3068 - acc: 0.8882\n",
            "Epoch 142/150\n",
            "161/161 [==============================] - 0s 762us/step - loss: 0.3055 - acc: 0.8758\n",
            "Epoch 143/150\n",
            "161/161 [==============================] - 0s 719us/step - loss: 0.3030 - acc: 0.8696\n",
            "Epoch 144/150\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.3089 - acc: 0.8758\n",
            "Epoch 145/150\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.3066 - acc: 0.8696\n",
            "Epoch 146/150\n",
            "161/161 [==============================] - 0s 722us/step - loss: 0.3028 - acc: 0.8758\n",
            "Epoch 147/150\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.3022 - acc: 0.8882\n",
            "Epoch 148/150\n",
            "161/161 [==============================] - 0s 729us/step - loss: 0.3049 - acc: 0.8758\n",
            "Epoch 149/150\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.3027 - acc: 0.8696\n",
            "Epoch 150/150\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.3031 - acc: 0.8696\n",
            "81/81 [==============================] - 3s 43ms/step\n",
            "161/161 [==============================] - 0s 588us/step\n",
            "Epoch 1/150\n",
            "161/161 [==============================] - 8s 51ms/step - loss: 0.7249 - acc: 0.4596\n",
            "Epoch 2/150\n",
            "161/161 [==============================] - 0s 789us/step - loss: 0.6905 - acc: 0.5342\n",
            "Epoch 3/150\n",
            "161/161 [==============================] - 0s 851us/step - loss: 0.6845 - acc: 0.5404\n",
            "Epoch 4/150\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.6788 - acc: 0.5342\n",
            "Epoch 5/150\n",
            "161/161 [==============================] - 0s 807us/step - loss: 0.6716 - acc: 0.5901\n",
            "Epoch 6/150\n",
            "161/161 [==============================] - 0s 785us/step - loss: 0.6663 - acc: 0.5342\n",
            "Epoch 7/150\n",
            "161/161 [==============================] - 0s 765us/step - loss: 0.6564 - acc: 0.7578\n",
            "Epoch 8/150\n",
            "161/161 [==============================] - 0s 751us/step - loss: 0.6517 - acc: 0.5963\n",
            "Epoch 9/150\n",
            "161/161 [==============================] - 0s 745us/step - loss: 0.6422 - acc: 0.7329\n",
            "Epoch 10/150\n",
            "161/161 [==============================] - 0s 661us/step - loss: 0.6202 - acc: 0.7640\n",
            "Epoch 11/150\n",
            "161/161 [==============================] - 0s 672us/step - loss: 0.6063 - acc: 0.7640\n",
            "Epoch 12/150\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.5881 - acc: 0.7950\n",
            "Epoch 13/150\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.5742 - acc: 0.7826\n",
            "Epoch 14/150\n",
            "161/161 [==============================] - 0s 760us/step - loss: 0.5516 - acc: 0.8012\n",
            "Epoch 15/150\n",
            "161/161 [==============================] - 0s 723us/step - loss: 0.5336 - acc: 0.8075\n",
            "Epoch 16/150\n",
            "161/161 [==============================] - 0s 740us/step - loss: 0.5189 - acc: 0.7950\n",
            "Epoch 17/150\n",
            "161/161 [==============================] - 0s 728us/step - loss: 0.4985 - acc: 0.8199\n",
            "Epoch 18/150\n",
            "161/161 [==============================] - 0s 726us/step - loss: 0.4863 - acc: 0.7888\n",
            "Epoch 19/150\n",
            "161/161 [==============================] - 0s 698us/step - loss: 0.4690 - acc: 0.8199\n",
            "Epoch 20/150\n",
            "161/161 [==============================] - 0s 751us/step - loss: 0.4631 - acc: 0.7888\n",
            "Epoch 21/150\n",
            "161/161 [==============================] - 0s 723us/step - loss: 0.4411 - acc: 0.8137\n",
            "Epoch 22/150\n",
            "161/161 [==============================] - 0s 722us/step - loss: 0.4335 - acc: 0.7950\n",
            "Epoch 23/150\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.4222 - acc: 0.7950\n",
            "Epoch 24/150\n",
            "161/161 [==============================] - 0s 674us/step - loss: 0.4178 - acc: 0.8199\n",
            "Epoch 25/150\n",
            "161/161 [==============================] - 0s 714us/step - loss: 0.4084 - acc: 0.8012\n",
            "Epoch 26/150\n",
            "161/161 [==============================] - 0s 687us/step - loss: 0.4030 - acc: 0.8012\n",
            "Epoch 27/150\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.3971 - acc: 0.7950\n",
            "Epoch 28/150\n",
            "161/161 [==============================] - 0s 760us/step - loss: 0.3939 - acc: 0.8012\n",
            "Epoch 29/150\n",
            "161/161 [==============================] - 0s 731us/step - loss: 0.3917 - acc: 0.7950\n",
            "Epoch 30/150\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.3864 - acc: 0.8075\n",
            "Epoch 31/150\n",
            "161/161 [==============================] - 0s 744us/step - loss: 0.3835 - acc: 0.8075\n",
            "Epoch 32/150\n",
            "161/161 [==============================] - 0s 721us/step - loss: 0.3797 - acc: 0.8075\n",
            "Epoch 33/150\n",
            "161/161 [==============================] - 0s 730us/step - loss: 0.3755 - acc: 0.8199\n",
            "Epoch 34/150\n",
            "161/161 [==============================] - 0s 763us/step - loss: 0.3791 - acc: 0.8261\n",
            "Epoch 35/150\n",
            "161/161 [==============================] - 0s 768us/step - loss: 0.3725 - acc: 0.8199\n",
            "Epoch 36/150\n",
            "161/161 [==============================] - 0s 806us/step - loss: 0.3721 - acc: 0.8323\n",
            "Epoch 37/150\n",
            "161/161 [==============================] - 0s 755us/step - loss: 0.3677 - acc: 0.8261\n",
            "Epoch 38/150\n",
            "161/161 [==============================] - 0s 668us/step - loss: 0.3679 - acc: 0.8385\n",
            "Epoch 39/150\n",
            "161/161 [==============================] - 0s 662us/step - loss: 0.3759 - acc: 0.8199\n",
            "Epoch 40/150\n",
            "161/161 [==============================] - 0s 737us/step - loss: 0.3737 - acc: 0.8323\n",
            "Epoch 41/150\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.3631 - acc: 0.8385\n",
            "Epoch 42/150\n",
            "161/161 [==============================] - 0s 679us/step - loss: 0.3588 - acc: 0.8385\n",
            "Epoch 43/150\n",
            "161/161 [==============================] - 0s 814us/step - loss: 0.3583 - acc: 0.8385\n",
            "Epoch 44/150\n",
            "161/161 [==============================] - 0s 690us/step - loss: 0.3560 - acc: 0.8447\n",
            "Epoch 45/150\n",
            "161/161 [==============================] - 0s 767us/step - loss: 0.3566 - acc: 0.8509\n",
            "Epoch 46/150\n",
            "161/161 [==============================] - 0s 660us/step - loss: 0.3558 - acc: 0.8509\n",
            "Epoch 47/150\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.3540 - acc: 0.8634\n",
            "Epoch 48/150\n",
            "161/161 [==============================] - 0s 786us/step - loss: 0.3533 - acc: 0.8509\n",
            "Epoch 49/150\n",
            "161/161 [==============================] - 0s 780us/step - loss: 0.3520 - acc: 0.8509\n",
            "Epoch 50/150\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.3524 - acc: 0.8571\n",
            "Epoch 51/150\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.3494 - acc: 0.8634\n",
            "Epoch 52/150\n",
            "161/161 [==============================] - 0s 773us/step - loss: 0.3561 - acc: 0.8509\n",
            "Epoch 53/150\n",
            "161/161 [==============================] - 0s 753us/step - loss: 0.3556 - acc: 0.8447\n",
            "Epoch 54/150\n",
            "161/161 [==============================] - 0s 751us/step - loss: 0.3467 - acc: 0.8634\n",
            "Epoch 55/150\n",
            "161/161 [==============================] - 0s 712us/step - loss: 0.3473 - acc: 0.8634\n",
            "Epoch 56/150\n",
            "161/161 [==============================] - 0s 739us/step - loss: 0.3480 - acc: 0.8509\n",
            "Epoch 57/150\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.3454 - acc: 0.8634\n",
            "Epoch 58/150\n",
            "161/161 [==============================] - 0s 778us/step - loss: 0.3491 - acc: 0.8571\n",
            "Epoch 59/150\n",
            "161/161 [==============================] - 0s 811us/step - loss: 0.3481 - acc: 0.8634\n",
            "Epoch 60/150\n",
            "161/161 [==============================] - 0s 839us/step - loss: 0.3470 - acc: 0.8571\n",
            "Epoch 61/150\n",
            "161/161 [==============================] - 0s 822us/step - loss: 0.3494 - acc: 0.8634\n",
            "Epoch 62/150\n",
            "161/161 [==============================] - 0s 767us/step - loss: 0.3415 - acc: 0.8696\n",
            "Epoch 63/150\n",
            "161/161 [==============================] - 0s 829us/step - loss: 0.3420 - acc: 0.8634\n",
            "Epoch 64/150\n",
            "161/161 [==============================] - 0s 722us/step - loss: 0.3417 - acc: 0.8696\n",
            "Epoch 65/150\n",
            "161/161 [==============================] - 0s 778us/step - loss: 0.3409 - acc: 0.8571\n",
            "Epoch 66/150\n",
            "161/161 [==============================] - 0s 778us/step - loss: 0.3450 - acc: 0.8634\n",
            "Epoch 67/150\n",
            "161/161 [==============================] - 0s 849us/step - loss: 0.3416 - acc: 0.8571\n",
            "Epoch 68/150\n",
            "161/161 [==============================] - 0s 704us/step - loss: 0.3394 - acc: 0.8571\n",
            "Epoch 69/150\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.3390 - acc: 0.8571\n",
            "Epoch 70/150\n",
            "161/161 [==============================] - 0s 770us/step - loss: 0.3442 - acc: 0.8509\n",
            "Epoch 71/150\n",
            "161/161 [==============================] - 0s 789us/step - loss: 0.3419 - acc: 0.8571\n",
            "Epoch 72/150\n",
            "161/161 [==============================] - 0s 752us/step - loss: 0.3421 - acc: 0.8509\n",
            "Epoch 73/150\n",
            "161/161 [==============================] - 0s 781us/step - loss: 0.3402 - acc: 0.8447\n",
            "Epoch 74/150\n",
            "161/161 [==============================] - 0s 745us/step - loss: 0.3450 - acc: 0.8696\n",
            "Epoch 75/150\n",
            "161/161 [==============================] - 0s 707us/step - loss: 0.3371 - acc: 0.8509\n",
            "Epoch 76/150\n",
            "161/161 [==============================] - 0s 705us/step - loss: 0.3390 - acc: 0.8634\n",
            "Epoch 77/150\n",
            "161/161 [==============================] - 0s 713us/step - loss: 0.3411 - acc: 0.8758\n",
            "Epoch 78/150\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.3373 - acc: 0.8634\n",
            "Epoch 79/150\n",
            "161/161 [==============================] - 0s 771us/step - loss: 0.3390 - acc: 0.8571\n",
            "Epoch 80/150\n",
            "161/161 [==============================] - 0s 776us/step - loss: 0.3368 - acc: 0.8571\n",
            "Epoch 81/150\n",
            "161/161 [==============================] - 0s 795us/step - loss: 0.3366 - acc: 0.8634\n",
            "Epoch 82/150\n",
            "161/161 [==============================] - 0s 779us/step - loss: 0.3380 - acc: 0.8509\n",
            "Epoch 83/150\n",
            "161/161 [==============================] - 0s 801us/step - loss: 0.3373 - acc: 0.8509\n",
            "Epoch 84/150\n",
            "161/161 [==============================] - 0s 751us/step - loss: 0.3347 - acc: 0.8634\n",
            "Epoch 85/150\n",
            "161/161 [==============================] - 0s 801us/step - loss: 0.3368 - acc: 0.8509\n",
            "Epoch 86/150\n",
            "161/161 [==============================] - 0s 799us/step - loss: 0.3370 - acc: 0.8634\n",
            "Epoch 87/150\n",
            "161/161 [==============================] - 0s 781us/step - loss: 0.3477 - acc: 0.8447\n",
            "Epoch 88/150\n",
            "161/161 [==============================] - 0s 713us/step - loss: 0.3399 - acc: 0.8634\n",
            "Epoch 89/150\n",
            "161/161 [==============================] - 0s 736us/step - loss: 0.3322 - acc: 0.8634\n",
            "Epoch 90/150\n",
            "161/161 [==============================] - 0s 709us/step - loss: 0.3365 - acc: 0.8634\n",
            "Epoch 91/150\n",
            "161/161 [==============================] - 0s 765us/step - loss: 0.3339 - acc: 0.8634\n",
            "Epoch 92/150\n",
            "161/161 [==============================] - 0s 720us/step - loss: 0.3392 - acc: 0.8696\n",
            "Epoch 93/150\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.3335 - acc: 0.8634\n",
            "Epoch 94/150\n",
            "161/161 [==============================] - 0s 677us/step - loss: 0.3382 - acc: 0.8696\n",
            "Epoch 95/150\n",
            "161/161 [==============================] - 0s 783us/step - loss: 0.3344 - acc: 0.8571\n",
            "Epoch 96/150\n",
            "161/161 [==============================] - 0s 778us/step - loss: 0.3371 - acc: 0.8571\n",
            "Epoch 97/150\n",
            "161/161 [==============================] - 0s 774us/step - loss: 0.3335 - acc: 0.8696\n",
            "Epoch 98/150\n",
            "161/161 [==============================] - 0s 760us/step - loss: 0.3358 - acc: 0.8634\n",
            "Epoch 99/150\n",
            "161/161 [==============================] - 0s 771us/step - loss: 0.3371 - acc: 0.8696\n",
            "Epoch 100/150\n",
            "161/161 [==============================] - 0s 766us/step - loss: 0.3321 - acc: 0.8634\n",
            "Epoch 101/150\n",
            "161/161 [==============================] - 0s 778us/step - loss: 0.3358 - acc: 0.8634\n",
            "Epoch 102/150\n",
            "161/161 [==============================] - 0s 749us/step - loss: 0.3341 - acc: 0.8571\n",
            "Epoch 103/150\n",
            "161/161 [==============================] - 0s 756us/step - loss: 0.3362 - acc: 0.8571\n",
            "Epoch 104/150\n",
            "161/161 [==============================] - 0s 756us/step - loss: 0.3326 - acc: 0.8634\n",
            "Epoch 105/150\n",
            "161/161 [==============================] - 0s 731us/step - loss: 0.3316 - acc: 0.8758\n",
            "Epoch 106/150\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.3460 - acc: 0.8509\n",
            "Epoch 107/150\n",
            "161/161 [==============================] - 0s 666us/step - loss: 0.3511 - acc: 0.8571\n",
            "Epoch 108/150\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.3388 - acc: 0.8696\n",
            "Epoch 109/150\n",
            "161/161 [==============================] - 0s 768us/step - loss: 0.3334 - acc: 0.8696\n",
            "Epoch 110/150\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.3333 - acc: 0.8634\n",
            "Epoch 111/150\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.3324 - acc: 0.8696\n",
            "Epoch 112/150\n",
            "161/161 [==============================] - 0s 742us/step - loss: 0.3334 - acc: 0.8634\n",
            "Epoch 113/150\n",
            "161/161 [==============================] - 0s 803us/step - loss: 0.3318 - acc: 0.8634\n",
            "Epoch 114/150\n",
            "161/161 [==============================] - 0s 788us/step - loss: 0.3329 - acc: 0.8696\n",
            "Epoch 115/150\n",
            "161/161 [==============================] - 0s 795us/step - loss: 0.3297 - acc: 0.8696\n",
            "Epoch 116/150\n",
            "161/161 [==============================] - 0s 748us/step - loss: 0.3409 - acc: 0.8571\n",
            "Epoch 117/150\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.3302 - acc: 0.8634\n",
            "Epoch 118/150\n",
            "161/161 [==============================] - 0s 803us/step - loss: 0.3311 - acc: 0.8634\n",
            "Epoch 119/150\n",
            "161/161 [==============================] - 0s 789us/step - loss: 0.3322 - acc: 0.8571\n",
            "Epoch 120/150\n",
            "161/161 [==============================] - 0s 865us/step - loss: 0.3308 - acc: 0.8634\n",
            "Epoch 121/150\n",
            "161/161 [==============================] - 0s 759us/step - loss: 0.3317 - acc: 0.8696\n",
            "Epoch 122/150\n",
            "161/161 [==============================] - 0s 725us/step - loss: 0.3324 - acc: 0.8634\n",
            "Epoch 123/150\n",
            "161/161 [==============================] - 0s 748us/step - loss: 0.3368 - acc: 0.8696\n",
            "Epoch 124/150\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3289 - acc: 0.8696\n",
            "Epoch 125/150\n",
            "161/161 [==============================] - 0s 794us/step - loss: 0.3336 - acc: 0.8571\n",
            "Epoch 126/150\n",
            "161/161 [==============================] - 0s 761us/step - loss: 0.3292 - acc: 0.8634\n",
            "Epoch 127/150\n",
            "161/161 [==============================] - 0s 790us/step - loss: 0.3308 - acc: 0.8634\n",
            "Epoch 128/150\n",
            "161/161 [==============================] - 0s 758us/step - loss: 0.3303 - acc: 0.8571\n",
            "Epoch 129/150\n",
            "161/161 [==============================] - 0s 813us/step - loss: 0.3283 - acc: 0.8820\n",
            "Epoch 130/150\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3322 - acc: 0.8696\n",
            "Epoch 131/150\n",
            "161/161 [==============================] - 0s 727us/step - loss: 0.3367 - acc: 0.8696\n",
            "Epoch 132/150\n",
            "161/161 [==============================] - 0s 752us/step - loss: 0.3284 - acc: 0.8696\n",
            "Epoch 133/150\n",
            "161/161 [==============================] - 0s 780us/step - loss: 0.3341 - acc: 0.8758\n",
            "Epoch 134/150\n",
            "161/161 [==============================] - 0s 746us/step - loss: 0.3327 - acc: 0.8758\n",
            "Epoch 135/150\n",
            "161/161 [==============================] - 0s 678us/step - loss: 0.3286 - acc: 0.8634\n",
            "Epoch 136/150\n",
            "161/161 [==============================] - 0s 770us/step - loss: 0.3294 - acc: 0.8696\n",
            "Epoch 137/150\n",
            "161/161 [==============================] - 0s 724us/step - loss: 0.3297 - acc: 0.8571\n",
            "Epoch 138/150\n",
            "161/161 [==============================] - 0s 711us/step - loss: 0.3292 - acc: 0.8634\n",
            "Epoch 139/150\n",
            "161/161 [==============================] - 0s 705us/step - loss: 0.3270 - acc: 0.8758\n",
            "Epoch 140/150\n",
            "161/161 [==============================] - 0s 734us/step - loss: 0.3297 - acc: 0.8634\n",
            "Epoch 141/150\n",
            "161/161 [==============================] - 0s 766us/step - loss: 0.3314 - acc: 0.8571\n",
            "Epoch 142/150\n",
            "161/161 [==============================] - 0s 735us/step - loss: 0.3322 - acc: 0.8696\n",
            "Epoch 143/150\n",
            "161/161 [==============================] - 0s 702us/step - loss: 0.3322 - acc: 0.8758\n",
            "Epoch 144/150\n",
            "161/161 [==============================] - 0s 756us/step - loss: 0.3292 - acc: 0.8634\n",
            "Epoch 145/150\n",
            "161/161 [==============================] - 0s 747us/step - loss: 0.3305 - acc: 0.8634\n",
            "Epoch 146/150\n",
            "161/161 [==============================] - 0s 706us/step - loss: 0.3279 - acc: 0.8634\n",
            "Epoch 147/150\n",
            "161/161 [==============================] - 0s 793us/step - loss: 0.3302 - acc: 0.8634\n",
            "Epoch 148/150\n",
            "161/161 [==============================] - 0s 769us/step - loss: 0.3282 - acc: 0.8696\n",
            "Epoch 149/150\n",
            "161/161 [==============================] - 0s 843us/step - loss: 0.3266 - acc: 0.8634\n",
            "Epoch 150/150\n",
            "161/161 [==============================] - 0s 773us/step - loss: 0.3283 - acc: 0.8696\n",
            "81/81 [==============================] - 4s 43ms/step\n",
            "161/161 [==============================] - 0s 568us/step\n",
            "Epoch 1/150\n",
            "162/162 [==============================] - 8s 51ms/step - loss: 0.6912 - acc: 0.5617\n",
            "Epoch 2/150\n",
            "162/162 [==============================] - 0s 674us/step - loss: 0.6795 - acc: 0.5617\n",
            "Epoch 3/150\n",
            "162/162 [==============================] - 0s 892us/step - loss: 0.6779 - acc: 0.5617\n",
            "Epoch 4/150\n",
            "162/162 [==============================] - 0s 911us/step - loss: 0.6703 - acc: 0.5617\n",
            "Epoch 5/150\n",
            "162/162 [==============================] - 0s 749us/step - loss: 0.6649 - acc: 0.5617\n",
            "Epoch 6/150\n",
            "162/162 [==============================] - 0s 750us/step - loss: 0.6587 - acc: 0.5679\n",
            "Epoch 7/150\n",
            "162/162 [==============================] - 0s 709us/step - loss: 0.6518 - acc: 0.5741\n",
            "Epoch 8/150\n",
            "162/162 [==============================] - 0s 771us/step - loss: 0.6416 - acc: 0.7346\n",
            "Epoch 9/150\n",
            "162/162 [==============================] - 0s 753us/step - loss: 0.6328 - acc: 0.6296\n",
            "Epoch 10/150\n",
            "162/162 [==============================] - 0s 731us/step - loss: 0.6155 - acc: 0.6358\n",
            "Epoch 11/150\n",
            "162/162 [==============================] - 0s 724us/step - loss: 0.6017 - acc: 0.7469\n",
            "Epoch 12/150\n",
            "162/162 [==============================] - 0s 705us/step - loss: 0.5846 - acc: 0.7407\n",
            "Epoch 13/150\n",
            "162/162 [==============================] - 0s 756us/step - loss: 0.5662 - acc: 0.7840\n",
            "Epoch 14/150\n",
            "162/162 [==============================] - 0s 826us/step - loss: 0.5482 - acc: 0.7778\n",
            "Epoch 15/150\n",
            "162/162 [==============================] - 0s 756us/step - loss: 0.5299 - acc: 0.7901\n",
            "Epoch 16/150\n",
            "162/162 [==============================] - 0s 752us/step - loss: 0.5129 - acc: 0.8148\n",
            "Epoch 17/150\n",
            "162/162 [==============================] - 0s 766us/step - loss: 0.4960 - acc: 0.8148\n",
            "Epoch 18/150\n",
            "162/162 [==============================] - 0s 790us/step - loss: 0.4840 - acc: 0.8025\n",
            "Epoch 19/150\n",
            "162/162 [==============================] - 0s 805us/step - loss: 0.4672 - acc: 0.8086\n",
            "Epoch 20/150\n",
            "162/162 [==============================] - 0s 771us/step - loss: 0.4533 - acc: 0.8333\n",
            "Epoch 21/150\n",
            "162/162 [==============================] - 0s 735us/step - loss: 0.4453 - acc: 0.7963\n",
            "Epoch 22/150\n",
            "162/162 [==============================] - 0s 791us/step - loss: 0.4347 - acc: 0.8210\n",
            "Epoch 23/150\n",
            "162/162 [==============================] - 0s 772us/step - loss: 0.4229 - acc: 0.8272\n",
            "Epoch 24/150\n",
            "162/162 [==============================] - 0s 748us/step - loss: 0.4160 - acc: 0.8272\n",
            "Epoch 25/150\n",
            "162/162 [==============================] - 0s 735us/step - loss: 0.4103 - acc: 0.8272\n",
            "Epoch 26/150\n",
            "162/162 [==============================] - 0s 679us/step - loss: 0.4067 - acc: 0.8272\n",
            "Epoch 27/150\n",
            "162/162 [==============================] - 0s 723us/step - loss: 0.4060 - acc: 0.8148\n",
            "Epoch 28/150\n",
            "162/162 [==============================] - 0s 706us/step - loss: 0.3990 - acc: 0.8395\n",
            "Epoch 29/150\n",
            "162/162 [==============================] - 0s 757us/step - loss: 0.3944 - acc: 0.8210\n",
            "Epoch 30/150\n",
            "162/162 [==============================] - 0s 817us/step - loss: 0.3927 - acc: 0.8272\n",
            "Epoch 31/150\n",
            "162/162 [==============================] - 0s 806us/step - loss: 0.3932 - acc: 0.8457\n",
            "Epoch 32/150\n",
            "162/162 [==============================] - 0s 744us/step - loss: 0.3845 - acc: 0.8272\n",
            "Epoch 33/150\n",
            "162/162 [==============================] - 0s 707us/step - loss: 0.3839 - acc: 0.8333\n",
            "Epoch 34/150\n",
            "162/162 [==============================] - 0s 724us/step - loss: 0.3824 - acc: 0.8457\n",
            "Epoch 35/150\n",
            "162/162 [==============================] - 0s 770us/step - loss: 0.3794 - acc: 0.8333\n",
            "Epoch 36/150\n",
            "162/162 [==============================] - 0s 722us/step - loss: 0.3797 - acc: 0.8333\n",
            "Epoch 37/150\n",
            "162/162 [==============================] - 0s 775us/step - loss: 0.3796 - acc: 0.8395\n",
            "Epoch 38/150\n",
            "162/162 [==============================] - 0s 742us/step - loss: 0.3837 - acc: 0.8333\n",
            "Epoch 39/150\n",
            "162/162 [==============================] - 0s 667us/step - loss: 0.3773 - acc: 0.8457\n",
            "Epoch 40/150\n",
            "162/162 [==============================] - 0s 735us/step - loss: 0.3773 - acc: 0.8333\n",
            "Epoch 41/150\n",
            "162/162 [==============================] - 0s 735us/step - loss: 0.3737 - acc: 0.8395\n",
            "Epoch 42/150\n",
            "162/162 [==============================] - 0s 703us/step - loss: 0.3739 - acc: 0.8457\n",
            "Epoch 43/150\n",
            "162/162 [==============================] - 0s 781us/step - loss: 0.3734 - acc: 0.8395\n",
            "Epoch 44/150\n",
            "162/162 [==============================] - 0s 742us/step - loss: 0.3753 - acc: 0.8395\n",
            "Epoch 45/150\n",
            "162/162 [==============================] - 0s 747us/step - loss: 0.3715 - acc: 0.8457\n",
            "Epoch 46/150\n",
            "162/162 [==============================] - 0s 805us/step - loss: 0.3750 - acc: 0.8395\n",
            "Epoch 47/150\n",
            "162/162 [==============================] - 0s 746us/step - loss: 0.3743 - acc: 0.8395\n",
            "Epoch 48/150\n",
            "162/162 [==============================] - 0s 761us/step - loss: 0.3674 - acc: 0.8519\n",
            "Epoch 49/150\n",
            "162/162 [==============================] - 0s 735us/step - loss: 0.3721 - acc: 0.8395\n",
            "Epoch 50/150\n",
            "162/162 [==============================] - 0s 732us/step - loss: 0.3744 - acc: 0.8395\n",
            "Epoch 51/150\n",
            "162/162 [==============================] - 0s 775us/step - loss: 0.3757 - acc: 0.8272\n",
            "Epoch 52/150\n",
            "162/162 [==============================] - 0s 772us/step - loss: 0.3682 - acc: 0.8457\n",
            "Epoch 53/150\n",
            "162/162 [==============================] - 0s 751us/step - loss: 0.3666 - acc: 0.8580\n",
            "Epoch 54/150\n",
            "162/162 [==============================] - 0s 750us/step - loss: 0.3695 - acc: 0.8395\n",
            "Epoch 55/150\n",
            "162/162 [==============================] - 0s 663us/step - loss: 0.3686 - acc: 0.8519\n",
            "Epoch 56/150\n",
            "162/162 [==============================] - 0s 728us/step - loss: 0.3673 - acc: 0.8519\n",
            "Epoch 57/150\n",
            "162/162 [==============================] - 0s 746us/step - loss: 0.3670 - acc: 0.8519\n",
            "Epoch 58/150\n",
            "162/162 [==============================] - 0s 689us/step - loss: 0.3653 - acc: 0.8580\n",
            "Epoch 59/150\n",
            "162/162 [==============================] - 0s 747us/step - loss: 0.3652 - acc: 0.8580\n",
            "Epoch 60/150\n",
            "162/162 [==============================] - 0s 751us/step - loss: 0.3677 - acc: 0.8580\n",
            "Epoch 61/150\n",
            "162/162 [==============================] - 0s 746us/step - loss: 0.3632 - acc: 0.8519\n",
            "Epoch 62/150\n",
            "162/162 [==============================] - 0s 768us/step - loss: 0.3645 - acc: 0.8580\n",
            "Epoch 63/150\n",
            "162/162 [==============================] - 0s 840us/step - loss: 0.3668 - acc: 0.8580\n",
            "Epoch 64/150\n",
            "162/162 [==============================] - 0s 772us/step - loss: 0.3646 - acc: 0.8580\n",
            "Epoch 65/150\n",
            "162/162 [==============================] - 0s 786us/step - loss: 0.3681 - acc: 0.8395\n",
            "Epoch 66/150\n",
            "162/162 [==============================] - 0s 779us/step - loss: 0.3646 - acc: 0.8580\n",
            "Epoch 67/150\n",
            "162/162 [==============================] - 0s 774us/step - loss: 0.3656 - acc: 0.8395\n",
            "Epoch 68/150\n",
            "162/162 [==============================] - 0s 708us/step - loss: 0.3655 - acc: 0.8457\n",
            "Epoch 69/150\n",
            "162/162 [==============================] - 0s 850us/step - loss: 0.3726 - acc: 0.8457\n",
            "Epoch 70/150\n",
            "162/162 [==============================] - 0s 786us/step - loss: 0.3627 - acc: 0.8580\n",
            "Epoch 71/150\n",
            "162/162 [==============================] - 0s 737us/step - loss: 0.3676 - acc: 0.8519\n",
            "Epoch 72/150\n",
            "162/162 [==============================] - 0s 744us/step - loss: 0.3630 - acc: 0.8580\n",
            "Epoch 73/150\n",
            "162/162 [==============================] - 0s 754us/step - loss: 0.3618 - acc: 0.8580\n",
            "Epoch 74/150\n",
            "162/162 [==============================] - 0s 753us/step - loss: 0.3666 - acc: 0.8580\n",
            "Epoch 75/150\n",
            "162/162 [==============================] - 0s 737us/step - loss: 0.3643 - acc: 0.8519\n",
            "Epoch 76/150\n",
            "162/162 [==============================] - 0s 709us/step - loss: 0.3704 - acc: 0.8519\n",
            "Epoch 77/150\n",
            "162/162 [==============================] - 0s 776us/step - loss: 0.3652 - acc: 0.8333\n",
            "Epoch 78/150\n",
            "162/162 [==============================] - 0s 842us/step - loss: 0.3607 - acc: 0.8580\n",
            "Epoch 79/150\n",
            "162/162 [==============================] - 0s 770us/step - loss: 0.3674 - acc: 0.8580\n",
            "Epoch 80/150\n",
            "162/162 [==============================] - 0s 776us/step - loss: 0.3654 - acc: 0.8457\n",
            "Epoch 81/150\n",
            "162/162 [==============================] - 0s 688us/step - loss: 0.3655 - acc: 0.8519\n",
            "Epoch 82/150\n",
            "162/162 [==============================] - 0s 745us/step - loss: 0.3617 - acc: 0.8580\n",
            "Epoch 83/150\n",
            "162/162 [==============================] - 0s 697us/step - loss: 0.3618 - acc: 0.8457\n",
            "Epoch 84/150\n",
            "162/162 [==============================] - 0s 768us/step - loss: 0.3735 - acc: 0.8457\n",
            "Epoch 85/150\n",
            "162/162 [==============================] - 0s 755us/step - loss: 0.3640 - acc: 0.8519\n",
            "Epoch 86/150\n",
            "162/162 [==============================] - 0s 695us/step - loss: 0.3653 - acc: 0.8333\n",
            "Epoch 87/150\n",
            "162/162 [==============================] - 0s 788us/step - loss: 0.3713 - acc: 0.8395\n",
            "Epoch 88/150\n",
            "162/162 [==============================] - 0s 746us/step - loss: 0.3658 - acc: 0.8580\n",
            "Epoch 89/150\n",
            "162/162 [==============================] - 0s 693us/step - loss: 0.3627 - acc: 0.8519\n",
            "Epoch 90/150\n",
            "162/162 [==============================] - 0s 743us/step - loss: 0.3629 - acc: 0.8519\n",
            "Epoch 91/150\n",
            "162/162 [==============================] - 0s 655us/step - loss: 0.3664 - acc: 0.8519\n",
            "Epoch 92/150\n",
            "162/162 [==============================] - 0s 686us/step - loss: 0.3607 - acc: 0.8519\n",
            "Epoch 93/150\n",
            "162/162 [==============================] - 0s 738us/step - loss: 0.3628 - acc: 0.8457\n",
            "Epoch 94/150\n",
            "162/162 [==============================] - 0s 684us/step - loss: 0.3626 - acc: 0.8580\n",
            "Epoch 95/150\n",
            "162/162 [==============================] - 0s 815us/step - loss: 0.3633 - acc: 0.8519\n",
            "Epoch 96/150\n",
            "162/162 [==============================] - 0s 799us/step - loss: 0.3608 - acc: 0.8580\n",
            "Epoch 97/150\n",
            "162/162 [==============================] - 0s 743us/step - loss: 0.3589 - acc: 0.8580\n",
            "Epoch 98/150\n",
            "162/162 [==============================] - 0s 729us/step - loss: 0.3605 - acc: 0.8580\n",
            "Epoch 99/150\n",
            "162/162 [==============================] - 0s 722us/step - loss: 0.3709 - acc: 0.8333\n",
            "Epoch 100/150\n",
            "162/162 [==============================] - 0s 740us/step - loss: 0.3702 - acc: 0.8272\n",
            "Epoch 101/150\n",
            "162/162 [==============================] - 0s 770us/step - loss: 0.3622 - acc: 0.8580\n",
            "Epoch 102/150\n",
            "162/162 [==============================] - 0s 721us/step - loss: 0.3614 - acc: 0.8457\n",
            "Epoch 103/150\n",
            "162/162 [==============================] - 0s 781us/step - loss: 0.3636 - acc: 0.8580\n",
            "Epoch 104/150\n",
            "162/162 [==============================] - 0s 733us/step - loss: 0.3631 - acc: 0.8519\n",
            "Epoch 105/150\n",
            "162/162 [==============================] - 0s 771us/step - loss: 0.3627 - acc: 0.8519\n",
            "Epoch 106/150\n",
            "162/162 [==============================] - 0s 724us/step - loss: 0.3635 - acc: 0.8580\n",
            "Epoch 107/150\n",
            "162/162 [==============================] - 0s 754us/step - loss: 0.3633 - acc: 0.8457\n",
            "Epoch 108/150\n",
            "162/162 [==============================] - 0s 729us/step - loss: 0.3594 - acc: 0.8580\n",
            "Epoch 109/150\n",
            "162/162 [==============================] - 0s 715us/step - loss: 0.3602 - acc: 0.8580\n",
            "Epoch 110/150\n",
            "162/162 [==============================] - 0s 782us/step - loss: 0.3598 - acc: 0.8580\n",
            "Epoch 111/150\n",
            "162/162 [==============================] - 0s 839us/step - loss: 0.3653 - acc: 0.8580\n",
            "Epoch 112/150\n",
            "162/162 [==============================] - 0s 728us/step - loss: 0.3601 - acc: 0.8519\n",
            "Epoch 113/150\n",
            "162/162 [==============================] - 0s 774us/step - loss: 0.3596 - acc: 0.8457\n",
            "Epoch 114/150\n",
            "162/162 [==============================] - 0s 789us/step - loss: 0.3584 - acc: 0.8580\n",
            "Epoch 115/150\n",
            "162/162 [==============================] - 0s 790us/step - loss: 0.3617 - acc: 0.8457\n",
            "Epoch 116/150\n",
            "162/162 [==============================] - 0s 855us/step - loss: 0.3596 - acc: 0.8642\n",
            "Epoch 117/150\n",
            "162/162 [==============================] - 0s 826us/step - loss: 0.3592 - acc: 0.8519\n",
            "Epoch 118/150\n",
            "162/162 [==============================] - 0s 762us/step - loss: 0.3617 - acc: 0.8642\n",
            "Epoch 119/150\n",
            "162/162 [==============================] - 0s 767us/step - loss: 0.3608 - acc: 0.8519\n",
            "Epoch 120/150\n",
            "162/162 [==============================] - 0s 784us/step - loss: 0.3566 - acc: 0.8580\n",
            "Epoch 121/150\n",
            "162/162 [==============================] - 0s 789us/step - loss: 0.3602 - acc: 0.8580\n",
            "Epoch 122/150\n",
            "162/162 [==============================] - 0s 776us/step - loss: 0.3611 - acc: 0.8580\n",
            "Epoch 123/150\n",
            "162/162 [==============================] - 0s 805us/step - loss: 0.3647 - acc: 0.8580\n",
            "Epoch 124/150\n",
            "162/162 [==============================] - 0s 709us/step - loss: 0.3653 - acc: 0.8395\n",
            "Epoch 125/150\n",
            "162/162 [==============================] - 0s 799us/step - loss: 0.3591 - acc: 0.8519\n",
            "Epoch 126/150\n",
            "162/162 [==============================] - 0s 730us/step - loss: 0.3614 - acc: 0.8519\n",
            "Epoch 127/150\n",
            "162/162 [==============================] - 0s 814us/step - loss: 0.3556 - acc: 0.8580\n",
            "Epoch 128/150\n",
            "162/162 [==============================] - 0s 794us/step - loss: 0.3576 - acc: 0.8519\n",
            "Epoch 129/150\n",
            "162/162 [==============================] - 0s 785us/step - loss: 0.3594 - acc: 0.8580\n",
            "Epoch 130/150\n",
            "162/162 [==============================] - 0s 716us/step - loss: 0.3570 - acc: 0.8580\n",
            "Epoch 131/150\n",
            "162/162 [==============================] - 0s 710us/step - loss: 0.3585 - acc: 0.8580\n",
            "Epoch 132/150\n",
            "162/162 [==============================] - 0s 714us/step - loss: 0.3630 - acc: 0.8457\n",
            "Epoch 133/150\n",
            "162/162 [==============================] - 0s 758us/step - loss: 0.3590 - acc: 0.8519\n",
            "Epoch 134/150\n",
            "162/162 [==============================] - 0s 718us/step - loss: 0.3578 - acc: 0.8580\n",
            "Epoch 135/150\n",
            "162/162 [==============================] - 0s 757us/step - loss: 0.3578 - acc: 0.8580\n",
            "Epoch 136/150\n",
            "162/162 [==============================] - 0s 721us/step - loss: 0.3645 - acc: 0.8519\n",
            "Epoch 137/150\n",
            "162/162 [==============================] - 0s 670us/step - loss: 0.3609 - acc: 0.8333\n",
            "Epoch 138/150\n",
            "162/162 [==============================] - 0s 769us/step - loss: 0.3593 - acc: 0.8519\n",
            "Epoch 139/150\n",
            "162/162 [==============================] - 0s 796us/step - loss: 0.3636 - acc: 0.8580\n",
            "Epoch 140/150\n",
            "162/162 [==============================] - 0s 764us/step - loss: 0.3612 - acc: 0.8642\n",
            "Epoch 141/150\n",
            "162/162 [==============================] - 0s 757us/step - loss: 0.3571 - acc: 0.8642\n",
            "Epoch 142/150\n",
            "162/162 [==============================] - 0s 784us/step - loss: 0.3563 - acc: 0.8642\n",
            "Epoch 143/150\n",
            "162/162 [==============================] - 0s 833us/step - loss: 0.3608 - acc: 0.8580\n",
            "Epoch 144/150\n",
            "162/162 [==============================] - 0s 772us/step - loss: 0.3553 - acc: 0.8580\n",
            "Epoch 145/150\n",
            "162/162 [==============================] - 0s 767us/step - loss: 0.3562 - acc: 0.8580\n",
            "Epoch 146/150\n",
            "162/162 [==============================] - 0s 799us/step - loss: 0.3565 - acc: 0.8580\n",
            "Epoch 147/150\n",
            "162/162 [==============================] - 0s 788us/step - loss: 0.3588 - acc: 0.8580\n",
            "Epoch 148/150\n",
            "162/162 [==============================] - 0s 841us/step - loss: 0.3583 - acc: 0.8580\n",
            "Epoch 149/150\n",
            "162/162 [==============================] - 0s 843us/step - loss: 0.3577 - acc: 0.8457\n",
            "Epoch 150/150\n",
            "162/162 [==============================] - 0s 781us/step - loss: 0.3556 - acc: 0.8642\n",
            "80/80 [==============================] - 4s 45ms/step\n",
            "162/162 [==============================] - 0s 576us/step\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 9s 35ms/step - loss: 0.6953 - acc: 0.5496\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 780us/step - loss: 0.6837 - acc: 0.5496\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 857us/step - loss: 0.6790 - acc: 0.5496\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 822us/step - loss: 0.6670 - acc: 0.6901\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 850us/step - loss: 0.6541 - acc: 0.5620\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 836us/step - loss: 0.6368 - acc: 0.7769\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 843us/step - loss: 0.6158 - acc: 0.7355\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 818us/step - loss: 0.5894 - acc: 0.7686\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 793us/step - loss: 0.5617 - acc: 0.8017\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 816us/step - loss: 0.5348 - acc: 0.7603\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 861us/step - loss: 0.5036 - acc: 0.8058\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 839us/step - loss: 0.4812 - acc: 0.8140\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 869us/step - loss: 0.4609 - acc: 0.7893\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 747us/step - loss: 0.4420 - acc: 0.8099\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 756us/step - loss: 0.4304 - acc: 0.8264\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 783us/step - loss: 0.4221 - acc: 0.8058\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 812us/step - loss: 0.4140 - acc: 0.8017\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 911us/step - loss: 0.4104 - acc: 0.7893\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 926us/step - loss: 0.3974 - acc: 0.8017\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 854us/step - loss: 0.3942 - acc: 0.8099\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 935us/step - loss: 0.3899 - acc: 0.8099\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 832us/step - loss: 0.3882 - acc: 0.8140\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 859us/step - loss: 0.3854 - acc: 0.8223\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 853us/step - loss: 0.3840 - acc: 0.8264\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 838us/step - loss: 0.3880 - acc: 0.8058\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 782us/step - loss: 0.3812 - acc: 0.8264\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 909us/step - loss: 0.3787 - acc: 0.8223\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 876us/step - loss: 0.3772 - acc: 0.8306\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 885us/step - loss: 0.3752 - acc: 0.8306\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 830us/step - loss: 0.3742 - acc: 0.8264\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 840us/step - loss: 0.3712 - acc: 0.8306\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 795us/step - loss: 0.3747 - acc: 0.8347\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 785us/step - loss: 0.3690 - acc: 0.8388\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 755us/step - loss: 0.3704 - acc: 0.8388\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 845us/step - loss: 0.3712 - acc: 0.8264\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 890us/step - loss: 0.3666 - acc: 0.8388\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 830us/step - loss: 0.3660 - acc: 0.8388\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 821us/step - loss: 0.3709 - acc: 0.8306\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 813us/step - loss: 0.3661 - acc: 0.8430\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 853us/step - loss: 0.3661 - acc: 0.8430\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 826us/step - loss: 0.3652 - acc: 0.8471\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 946us/step - loss: 0.3662 - acc: 0.8512\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 827us/step - loss: 0.3688 - acc: 0.8347\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 809us/step - loss: 0.3643 - acc: 0.8471\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 820us/step - loss: 0.3645 - acc: 0.8430\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 797us/step - loss: 0.3641 - acc: 0.8554\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 852us/step - loss: 0.3642 - acc: 0.8471\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 858us/step - loss: 0.3658 - acc: 0.8471\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 829us/step - loss: 0.3616 - acc: 0.8512\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 810us/step - loss: 0.3626 - acc: 0.8471\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 833us/step - loss: 0.3587 - acc: 0.8430\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 939us/step - loss: 0.3678 - acc: 0.8347\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 845us/step - loss: 0.3609 - acc: 0.8471\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 829us/step - loss: 0.3637 - acc: 0.8636\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 813us/step - loss: 0.3623 - acc: 0.8554\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 846us/step - loss: 0.3617 - acc: 0.8595\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 859us/step - loss: 0.3595 - acc: 0.8512\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 886us/step - loss: 0.3611 - acc: 0.8554\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 750us/step - loss: 0.3580 - acc: 0.8471\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 757us/step - loss: 0.3613 - acc: 0.8512\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 791us/step - loss: 0.3627 - acc: 0.8430\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 817us/step - loss: 0.3608 - acc: 0.8430\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 829us/step - loss: 0.3608 - acc: 0.8595\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 870us/step - loss: 0.3627 - acc: 0.8471\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 824us/step - loss: 0.3614 - acc: 0.8554\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 833us/step - loss: 0.3597 - acc: 0.8595\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 863us/step - loss: 0.3564 - acc: 0.8636\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 886us/step - loss: 0.3598 - acc: 0.8595\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 842us/step - loss: 0.3637 - acc: 0.8512\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 824us/step - loss: 0.3598 - acc: 0.8512\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 863us/step - loss: 0.3601 - acc: 0.8554\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 817us/step - loss: 0.3577 - acc: 0.8636\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 834us/step - loss: 0.3573 - acc: 0.8512\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 775us/step - loss: 0.3651 - acc: 0.8595\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 781us/step - loss: 0.3628 - acc: 0.8471\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 842us/step - loss: 0.3596 - acc: 0.8512\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 761us/step - loss: 0.3569 - acc: 0.8636\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 802us/step - loss: 0.3574 - acc: 0.8512\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 813us/step - loss: 0.3733 - acc: 0.8264\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 838us/step - loss: 0.3605 - acc: 0.8554\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 839us/step - loss: 0.3576 - acc: 0.8554\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 837us/step - loss: 0.3564 - acc: 0.8595\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 837us/step - loss: 0.3557 - acc: 0.8595\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 850us/step - loss: 0.3559 - acc: 0.8636\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 805us/step - loss: 0.3587 - acc: 0.8636\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 799us/step - loss: 0.3563 - acc: 0.8636\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 850us/step - loss: 0.3591 - acc: 0.8512\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 807us/step - loss: 0.3560 - acc: 0.8595\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 812us/step - loss: 0.3564 - acc: 0.8554\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 829us/step - loss: 0.3581 - acc: 0.8512\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 877us/step - loss: 0.3577 - acc: 0.8554\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 823us/step - loss: 0.3577 - acc: 0.8512\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 881us/step - loss: 0.3551 - acc: 0.8636\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 801us/step - loss: 0.3544 - acc: 0.8595\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 811us/step - loss: 0.3536 - acc: 0.8636\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 793us/step - loss: 0.3544 - acc: 0.8554\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 781us/step - loss: 0.3589 - acc: 0.8512\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 824us/step - loss: 0.3552 - acc: 0.8678\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 801us/step - loss: 0.3536 - acc: 0.8512\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 828us/step - loss: 0.3548 - acc: 0.8554\n",
            "Best: 0.801653 using {'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YngbQED6hpjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 24109
        },
        "outputId": "cd0b5ff5-69a2-4323-9d38-165f4a2afebb"
      },
      "cell_type": "code",
      "source": [
        "# This one will tune batch size. \n",
        "batches = np.array([5, 20])\n",
        "\n",
        "def baseline(optimizer = \"adam\", init = \"uniform\", activation='sigmoid'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(39, input_dim=X.shape[1], activation=activation))\n",
        "  model.add(Dense(39, activation=activation))\n",
        "  model.add(Dense(1, activation=activation))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=baseline, epochs=100, verbose=1)\n",
        "\n",
        "param_grid = dict(batch_size=batches)\n",
        "print(param_grid)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, )\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': array([ 5, 20])}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "161/161 [==============================] - 9s 56ms/step - loss: 0.6944 - acc: 0.5528\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 831us/step - loss: 0.6870 - acc: 0.5528\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 860us/step - loss: 0.6835 - acc: 0.5528\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 819us/step - loss: 0.6782 - acc: 0.5652\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 783us/step - loss: 0.6769 - acc: 0.6894\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 852us/step - loss: 0.6652 - acc: 0.5590\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 826us/step - loss: 0.6565 - acc: 0.6460\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 815us/step - loss: 0.6471 - acc: 0.6211\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 902us/step - loss: 0.6386 - acc: 0.7640\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 892us/step - loss: 0.6230 - acc: 0.7205\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 830us/step - loss: 0.6112 - acc: 0.7205\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 793us/step - loss: 0.5993 - acc: 0.7702\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 838us/step - loss: 0.5814 - acc: 0.7391\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 849us/step - loss: 0.5658 - acc: 0.7143\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 818us/step - loss: 0.5439 - acc: 0.7950\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 884us/step - loss: 0.5235 - acc: 0.8012\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 842us/step - loss: 0.5084 - acc: 0.8012\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 900us/step - loss: 0.4926 - acc: 0.8012\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 859us/step - loss: 0.4826 - acc: 0.7950\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 869us/step - loss: 0.4628 - acc: 0.8012\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 919us/step - loss: 0.4509 - acc: 0.7826\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 911us/step - loss: 0.4400 - acc: 0.7950\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 910us/step - loss: 0.4309 - acc: 0.8137\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 893us/step - loss: 0.4265 - acc: 0.7888\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 853us/step - loss: 0.4127 - acc: 0.7950\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 858us/step - loss: 0.4097 - acc: 0.7950\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 882us/step - loss: 0.4009 - acc: 0.8012\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 925us/step - loss: 0.4018 - acc: 0.8137\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 923us/step - loss: 0.3958 - acc: 0.8137\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 905us/step - loss: 0.3918 - acc: 0.8075\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 937us/step - loss: 0.3895 - acc: 0.8323\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 819us/step - loss: 0.3812 - acc: 0.8137\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 816us/step - loss: 0.3812 - acc: 0.8137\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 852us/step - loss: 0.3767 - acc: 0.8137\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 858us/step - loss: 0.3733 - acc: 0.8137\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 840us/step - loss: 0.3773 - acc: 0.8199\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 843us/step - loss: 0.3711 - acc: 0.8199\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 849us/step - loss: 0.3642 - acc: 0.8261\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 911us/step - loss: 0.3747 - acc: 0.8199\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 885us/step - loss: 0.3668 - acc: 0.8385\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 863us/step - loss: 0.3671 - acc: 0.8323\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 850us/step - loss: 0.3590 - acc: 0.8199\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 845us/step - loss: 0.3593 - acc: 0.8261\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 868us/step - loss: 0.3545 - acc: 0.8385\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 918us/step - loss: 0.3550 - acc: 0.8261\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 1ms/step - loss: 0.3605 - acc: 0.8447\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 840us/step - loss: 0.3605 - acc: 0.8261\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 859us/step - loss: 0.3540 - acc: 0.8447\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 873us/step - loss: 0.3551 - acc: 0.8509\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 922us/step - loss: 0.3460 - acc: 0.8385\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 829us/step - loss: 0.3463 - acc: 0.8261\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 862us/step - loss: 0.3471 - acc: 0.8261\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 933us/step - loss: 0.3535 - acc: 0.8385\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 870us/step - loss: 0.3449 - acc: 0.8199\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 855us/step - loss: 0.3447 - acc: 0.8323\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 860us/step - loss: 0.3406 - acc: 0.8509\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 817us/step - loss: 0.3404 - acc: 0.8385\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 818us/step - loss: 0.3417 - acc: 0.8509\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 843us/step - loss: 0.3407 - acc: 0.8385\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 841us/step - loss: 0.3407 - acc: 0.8385\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 812us/step - loss: 0.3455 - acc: 0.8323\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3374 - acc: 0.8634\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 860us/step - loss: 0.3367 - acc: 0.8261\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 893us/step - loss: 0.3384 - acc: 0.8323\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 1ms/step - loss: 0.3344 - acc: 0.8571\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 886us/step - loss: 0.3354 - acc: 0.8385\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 918us/step - loss: 0.3357 - acc: 0.8509\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 878us/step - loss: 0.3332 - acc: 0.8509\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 864us/step - loss: 0.3437 - acc: 0.8447\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 848us/step - loss: 0.3319 - acc: 0.8447\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 787us/step - loss: 0.3350 - acc: 0.8447\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 866us/step - loss: 0.3352 - acc: 0.8447\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 829us/step - loss: 0.3304 - acc: 0.8509\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 902us/step - loss: 0.3529 - acc: 0.8385\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 838us/step - loss: 0.3275 - acc: 0.8447\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 889us/step - loss: 0.3288 - acc: 0.8571\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 855us/step - loss: 0.3279 - acc: 0.8509\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 856us/step - loss: 0.3303 - acc: 0.8509\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 877us/step - loss: 0.3278 - acc: 0.8571\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 881us/step - loss: 0.3251 - acc: 0.8509\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 981us/step - loss: 0.3274 - acc: 0.8758\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 909us/step - loss: 0.3297 - acc: 0.8323\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 869us/step - loss: 0.3271 - acc: 0.8634\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 909us/step - loss: 0.3317 - acc: 0.8571\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 895us/step - loss: 0.3247 - acc: 0.8385\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 899us/step - loss: 0.3226 - acc: 0.8447\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 782us/step - loss: 0.3239 - acc: 0.8509\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 905us/step - loss: 0.3248 - acc: 0.8571\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 876us/step - loss: 0.3247 - acc: 0.8634\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 873us/step - loss: 0.3252 - acc: 0.8571\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 867us/step - loss: 0.3314 - acc: 0.8447\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 890us/step - loss: 0.3250 - acc: 0.8509\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 875us/step - loss: 0.3275 - acc: 0.8634\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 875us/step - loss: 0.3268 - acc: 0.8323\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 928us/step - loss: 0.3218 - acc: 0.8758\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 851us/step - loss: 0.3254 - acc: 0.8634\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 913us/step - loss: 0.3225 - acc: 0.8509\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 919us/step - loss: 0.3156 - acc: 0.8571\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 969us/step - loss: 0.3225 - acc: 0.8696\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 1ms/step - loss: 0.3189 - acc: 0.8634\n",
            "81/81 [==============================] - 4s 48ms/step\n",
            "161/161 [==============================] - 0s 825us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 9s 56ms/step - loss: 0.7113 - acc: 0.4534\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 839us/step - loss: 0.6847 - acc: 0.5342\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 886us/step - loss: 0.6780 - acc: 0.5466\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 858us/step - loss: 0.6721 - acc: 0.5342\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 848us/step - loss: 0.6684 - acc: 0.7267\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 849us/step - loss: 0.6605 - acc: 0.5839\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 838us/step - loss: 0.6479 - acc: 0.7640\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 863us/step - loss: 0.6378 - acc: 0.8012\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 840us/step - loss: 0.6247 - acc: 0.7143\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 834us/step - loss: 0.6169 - acc: 0.7640\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 862us/step - loss: 0.5986 - acc: 0.7826\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 798us/step - loss: 0.5782 - acc: 0.8199\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 804us/step - loss: 0.5614 - acc: 0.7888\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 823us/step - loss: 0.5421 - acc: 0.8199\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 867us/step - loss: 0.5234 - acc: 0.7826\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 885us/step - loss: 0.5047 - acc: 0.8075\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 848us/step - loss: 0.4942 - acc: 0.8137\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 866us/step - loss: 0.4778 - acc: 0.8075\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 847us/step - loss: 0.4635 - acc: 0.8075\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 840us/step - loss: 0.4507 - acc: 0.7888\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 778us/step - loss: 0.4354 - acc: 0.8012\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 804us/step - loss: 0.4275 - acc: 0.8137\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 822us/step - loss: 0.4168 - acc: 0.7950\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 843us/step - loss: 0.4162 - acc: 0.8199\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 823us/step - loss: 0.4019 - acc: 0.8012\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 838us/step - loss: 0.4010 - acc: 0.8012\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 851us/step - loss: 0.3976 - acc: 0.8137\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 850us/step - loss: 0.3885 - acc: 0.8012\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 813us/step - loss: 0.3846 - acc: 0.8137\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 829us/step - loss: 0.3814 - acc: 0.8075\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 844us/step - loss: 0.3776 - acc: 0.8137\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 813us/step - loss: 0.3782 - acc: 0.8137\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 862us/step - loss: 0.3741 - acc: 0.8323\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 865us/step - loss: 0.3755 - acc: 0.8012\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 934us/step - loss: 0.3719 - acc: 0.8199\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 927us/step - loss: 0.3686 - acc: 0.8447\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 918us/step - loss: 0.3616 - acc: 0.8385\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 819us/step - loss: 0.3651 - acc: 0.8323\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 820us/step - loss: 0.3592 - acc: 0.8509\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 839us/step - loss: 0.3587 - acc: 0.8385\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 831us/step - loss: 0.3573 - acc: 0.8509\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 832us/step - loss: 0.3569 - acc: 0.8385\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 840us/step - loss: 0.3576 - acc: 0.8447\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 858us/step - loss: 0.3554 - acc: 0.8447\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 880us/step - loss: 0.3542 - acc: 0.8571\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 898us/step - loss: 0.3539 - acc: 0.8509\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 879us/step - loss: 0.3533 - acc: 0.8509\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 842us/step - loss: 0.3499 - acc: 0.8509\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 864us/step - loss: 0.3480 - acc: 0.8634\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 887us/step - loss: 0.3511 - acc: 0.8509\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 895us/step - loss: 0.3540 - acc: 0.8571\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 861us/step - loss: 0.3463 - acc: 0.8509\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 938us/step - loss: 0.3504 - acc: 0.8509\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 865us/step - loss: 0.3504 - acc: 0.8571\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 899us/step - loss: 0.3450 - acc: 0.8571\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 897us/step - loss: 0.3466 - acc: 0.8634\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 895us/step - loss: 0.3432 - acc: 0.8634\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 838us/step - loss: 0.3419 - acc: 0.8634\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 777us/step - loss: 0.3423 - acc: 0.8634\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 797us/step - loss: 0.3421 - acc: 0.8571\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 859us/step - loss: 0.3497 - acc: 0.8696\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 852us/step - loss: 0.3422 - acc: 0.8571\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 832us/step - loss: 0.3443 - acc: 0.8696\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 946us/step - loss: 0.3434 - acc: 0.8634\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 901us/step - loss: 0.3462 - acc: 0.8696\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 880us/step - loss: 0.3426 - acc: 0.8571\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 806us/step - loss: 0.3395 - acc: 0.8571\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 912us/step - loss: 0.3391 - acc: 0.8696\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 869us/step - loss: 0.3372 - acc: 0.8571\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 941us/step - loss: 0.3374 - acc: 0.8571\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 859us/step - loss: 0.3372 - acc: 0.8571\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 871us/step - loss: 0.3391 - acc: 0.8571\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 877us/step - loss: 0.3354 - acc: 0.8634\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 837us/step - loss: 0.3367 - acc: 0.8696\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 856us/step - loss: 0.3430 - acc: 0.8634\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 900us/step - loss: 0.3359 - acc: 0.8634\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 842us/step - loss: 0.3429 - acc: 0.8634\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 723us/step - loss: 0.3392 - acc: 0.8696\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 790us/step - loss: 0.3361 - acc: 0.8696\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 784us/step - loss: 0.3390 - acc: 0.8509\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 825us/step - loss: 0.3341 - acc: 0.8571\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 848us/step - loss: 0.3453 - acc: 0.8509\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 882us/step - loss: 0.3359 - acc: 0.8634\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 867us/step - loss: 0.3342 - acc: 0.8634\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 850us/step - loss: 0.3367 - acc: 0.8571\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 850us/step - loss: 0.3350 - acc: 0.8696\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 872us/step - loss: 0.3322 - acc: 0.8696\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 909us/step - loss: 0.3352 - acc: 0.8634\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 805us/step - loss: 0.3338 - acc: 0.8634\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 824us/step - loss: 0.3326 - acc: 0.8509\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 829us/step - loss: 0.3337 - acc: 0.8634\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 837us/step - loss: 0.3410 - acc: 0.8571\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 889us/step - loss: 0.3332 - acc: 0.8634\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 926us/step - loss: 0.3331 - acc: 0.8634\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 860us/step - loss: 0.3325 - acc: 0.8571\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 894us/step - loss: 0.3334 - acc: 0.8634\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 903us/step - loss: 0.3332 - acc: 0.8696\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 941us/step - loss: 0.3301 - acc: 0.8634\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 892us/step - loss: 0.3352 - acc: 0.8571\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 770us/step - loss: 0.3293 - acc: 0.8634\n",
            "81/81 [==============================] - 4s 46ms/step\n",
            "161/161 [==============================] - 0s 615us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 9s 53ms/step - loss: 0.7085 - acc: 0.5185\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 773us/step - loss: 0.6887 - acc: 0.5617\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 764us/step - loss: 0.6821 - acc: 0.5617\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 752us/step - loss: 0.6760 - acc: 0.5617\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 758us/step - loss: 0.6706 - acc: 0.5617\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 715us/step - loss: 0.6676 - acc: 0.5617\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 719us/step - loss: 0.6598 - acc: 0.5679\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 849us/step - loss: 0.6513 - acc: 0.5988\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 785us/step - loss: 0.6425 - acc: 0.5926\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 812us/step - loss: 0.6361 - acc: 0.6420\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 786us/step - loss: 0.6207 - acc: 0.7531\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 778us/step - loss: 0.6110 - acc: 0.6790\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 825us/step - loss: 0.5936 - acc: 0.8025\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 777us/step - loss: 0.5763 - acc: 0.7346\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 779us/step - loss: 0.5618 - acc: 0.8025\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 776us/step - loss: 0.5409 - acc: 0.7963\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 847us/step - loss: 0.5260 - acc: 0.8086\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 843us/step - loss: 0.5110 - acc: 0.7901\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 772us/step - loss: 0.4957 - acc: 0.8210\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 829us/step - loss: 0.4778 - acc: 0.8025\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 779us/step - loss: 0.4623 - acc: 0.8148\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 770us/step - loss: 0.4502 - acc: 0.8086\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 885us/step - loss: 0.4401 - acc: 0.8210\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 789us/step - loss: 0.4299 - acc: 0.8148\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 747us/step - loss: 0.4254 - acc: 0.8272\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 789us/step - loss: 0.4170 - acc: 0.8210\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 769us/step - loss: 0.4098 - acc: 0.8210\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 812us/step - loss: 0.4025 - acc: 0.8148\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 792us/step - loss: 0.3981 - acc: 0.8210\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 734us/step - loss: 0.3946 - acc: 0.8272\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 797us/step - loss: 0.3971 - acc: 0.8395\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 839us/step - loss: 0.3898 - acc: 0.8272\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 826us/step - loss: 0.3878 - acc: 0.8148\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 839us/step - loss: 0.3845 - acc: 0.8457\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 839us/step - loss: 0.3835 - acc: 0.8272\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 815us/step - loss: 0.3833 - acc: 0.8333\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 845us/step - loss: 0.3789 - acc: 0.8272\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 824us/step - loss: 0.3787 - acc: 0.8395\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 819us/step - loss: 0.3777 - acc: 0.8457\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 779us/step - loss: 0.3747 - acc: 0.8457\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 805us/step - loss: 0.3758 - acc: 0.8395\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 826us/step - loss: 0.3754 - acc: 0.8457\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 803us/step - loss: 0.3724 - acc: 0.8395\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 840us/step - loss: 0.3717 - acc: 0.8519\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 886us/step - loss: 0.3735 - acc: 0.8457\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 835us/step - loss: 0.3715 - acc: 0.8519\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 834us/step - loss: 0.3690 - acc: 0.8457\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 864us/step - loss: 0.3727 - acc: 0.8457\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 855us/step - loss: 0.3685 - acc: 0.8457\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 832us/step - loss: 0.3683 - acc: 0.8519\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 830us/step - loss: 0.3732 - acc: 0.8457\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 851us/step - loss: 0.3677 - acc: 0.8457\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 844us/step - loss: 0.3704 - acc: 0.8457\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 797us/step - loss: 0.3650 - acc: 0.8519\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 803us/step - loss: 0.3683 - acc: 0.8457\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 872us/step - loss: 0.3641 - acc: 0.8580\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 847us/step - loss: 0.3656 - acc: 0.8519\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 832us/step - loss: 0.3631 - acc: 0.8580\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 848us/step - loss: 0.3671 - acc: 0.8395\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 847us/step - loss: 0.3680 - acc: 0.8457\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 778us/step - loss: 0.3683 - acc: 0.8519\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 788us/step - loss: 0.3801 - acc: 0.8395\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 847us/step - loss: 0.3643 - acc: 0.8580\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 815us/step - loss: 0.3666 - acc: 0.8395\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 899us/step - loss: 0.3638 - acc: 0.8395\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 921us/step - loss: 0.3659 - acc: 0.8580\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3629 - acc: 0.8519\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 864us/step - loss: 0.3616 - acc: 0.8519\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 969us/step - loss: 0.3641 - acc: 0.8457\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 856us/step - loss: 0.3692 - acc: 0.8457\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 787us/step - loss: 0.3609 - acc: 0.8580\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 849us/step - loss: 0.3613 - acc: 0.8519\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 942us/step - loss: 0.3607 - acc: 0.8580\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 790us/step - loss: 0.3668 - acc: 0.8519\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 779us/step - loss: 0.3617 - acc: 0.8580\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 850us/step - loss: 0.3650 - acc: 0.8395\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 858us/step - loss: 0.3612 - acc: 0.8580\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 826us/step - loss: 0.3604 - acc: 0.8519\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 824us/step - loss: 0.3608 - acc: 0.8519\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 816us/step - loss: 0.3661 - acc: 0.8457\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 813us/step - loss: 0.3584 - acc: 0.8519\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 919us/step - loss: 0.3635 - acc: 0.8580\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 865us/step - loss: 0.3598 - acc: 0.8519\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 851us/step - loss: 0.3650 - acc: 0.8519\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 901us/step - loss: 0.3632 - acc: 0.8519\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 902us/step - loss: 0.3622 - acc: 0.8580\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 831us/step - loss: 0.3598 - acc: 0.8580\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 844us/step - loss: 0.3597 - acc: 0.8519\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 929us/step - loss: 0.3633 - acc: 0.8519\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 966us/step - loss: 0.3601 - acc: 0.8580\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 932us/step - loss: 0.3583 - acc: 0.8519\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 896us/step - loss: 0.3625 - acc: 0.8580\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 926us/step - loss: 0.3598 - acc: 0.8519\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 894us/step - loss: 0.3602 - acc: 0.8519\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 982us/step - loss: 0.3654 - acc: 0.8519\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 923us/step - loss: 0.3577 - acc: 0.8580\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3601 - acc: 0.8642\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 955us/step - loss: 0.3590 - acc: 0.8457\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 906us/step - loss: 0.3600 - acc: 0.8580\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 948us/step - loss: 0.3576 - acc: 0.8580\n",
            "80/80 [==============================] - 4s 47ms/step\n",
            "162/162 [==============================] - 0s 614us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 9s 54ms/step - loss: 0.6935 - acc: 0.5031\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 315us/step - loss: 0.6906 - acc: 0.5901\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 277us/step - loss: 0.6831 - acc: 0.5528\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 298us/step - loss: 0.6823 - acc: 0.5528\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 312us/step - loss: 0.6846 - acc: 0.5528\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 287us/step - loss: 0.6868 - acc: 0.5528\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 276us/step - loss: 0.6871 - acc: 0.5528\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 292us/step - loss: 0.6831 - acc: 0.5528\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 291us/step - loss: 0.6802 - acc: 0.5528\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 324us/step - loss: 0.6781 - acc: 0.5528\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 325us/step - loss: 0.6754 - acc: 0.5528\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 318us/step - loss: 0.6736 - acc: 0.5528\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 329us/step - loss: 0.6719 - acc: 0.5528\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 302us/step - loss: 0.6672 - acc: 0.5528\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 336us/step - loss: 0.6667 - acc: 0.6149\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 304us/step - loss: 0.6640 - acc: 0.6832\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 310us/step - loss: 0.6611 - acc: 0.6398\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 319us/step - loss: 0.6588 - acc: 0.7143\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 348us/step - loss: 0.6640 - acc: 0.7578\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 346us/step - loss: 0.6579 - acc: 0.7081\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 319us/step - loss: 0.6518 - acc: 0.7081\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 331us/step - loss: 0.6482 - acc: 0.6584\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 347us/step - loss: 0.6487 - acc: 0.5528\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 322us/step - loss: 0.6473 - acc: 0.5528\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 314us/step - loss: 0.6417 - acc: 0.5776\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 294us/step - loss: 0.6377 - acc: 0.6211\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 291us/step - loss: 0.6343 - acc: 0.7019\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 327us/step - loss: 0.6315 - acc: 0.7329\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 307us/step - loss: 0.6258 - acc: 0.7453\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 298us/step - loss: 0.6233 - acc: 0.7205\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 285us/step - loss: 0.6178 - acc: 0.7391\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 306us/step - loss: 0.6168 - acc: 0.7950\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 312us/step - loss: 0.6101 - acc: 0.8137\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 322us/step - loss: 0.6059 - acc: 0.7826\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 285us/step - loss: 0.6025 - acc: 0.7578\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 293us/step - loss: 0.5964 - acc: 0.7391\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 281us/step - loss: 0.5892 - acc: 0.7516\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 329us/step - loss: 0.5868 - acc: 0.7888\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 317us/step - loss: 0.5849 - acc: 0.7888\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 299us/step - loss: 0.5768 - acc: 0.7826\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 354us/step - loss: 0.5707 - acc: 0.7764\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 355us/step - loss: 0.5650 - acc: 0.7453\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 372us/step - loss: 0.5670 - acc: 0.7143\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 279us/step - loss: 0.5580 - acc: 0.7391\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 335us/step - loss: 0.5444 - acc: 0.7950\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 316us/step - loss: 0.5391 - acc: 0.8137\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 306us/step - loss: 0.5335 - acc: 0.8012\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 375us/step - loss: 0.5275 - acc: 0.8075\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 310us/step - loss: 0.5220 - acc: 0.8075\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 289us/step - loss: 0.5177 - acc: 0.8075\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 285us/step - loss: 0.5106 - acc: 0.8199\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 302us/step - loss: 0.5056 - acc: 0.7702\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 310us/step - loss: 0.5072 - acc: 0.7826\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 317us/step - loss: 0.4996 - acc: 0.7826\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 319us/step - loss: 0.4903 - acc: 0.7950\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 297us/step - loss: 0.4832 - acc: 0.8137\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 308us/step - loss: 0.4785 - acc: 0.7950\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 320us/step - loss: 0.4735 - acc: 0.7826\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 288us/step - loss: 0.4685 - acc: 0.7888\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 319us/step - loss: 0.4629 - acc: 0.7950\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 302us/step - loss: 0.4593 - acc: 0.7950\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 316us/step - loss: 0.4563 - acc: 0.7950\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 276us/step - loss: 0.4524 - acc: 0.8199\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 328us/step - loss: 0.4484 - acc: 0.8199\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 298us/step - loss: 0.4428 - acc: 0.7950\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 290us/step - loss: 0.4391 - acc: 0.7888\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 466us/step - loss: 0.4354 - acc: 0.7826\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 331us/step - loss: 0.4335 - acc: 0.7950\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 302us/step - loss: 0.4317 - acc: 0.8261\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 297us/step - loss: 0.4274 - acc: 0.8075\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 268us/step - loss: 0.4246 - acc: 0.7888\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 349us/step - loss: 0.4252 - acc: 0.7888\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 310us/step - loss: 0.4182 - acc: 0.7950\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 290us/step - loss: 0.4140 - acc: 0.8012\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 309us/step - loss: 0.4129 - acc: 0.8012\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 289us/step - loss: 0.4097 - acc: 0.8075\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 320us/step - loss: 0.4091 - acc: 0.8137\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 305us/step - loss: 0.4081 - acc: 0.8199\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 320us/step - loss: 0.4033 - acc: 0.8137\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 363us/step - loss: 0.4002 - acc: 0.8075\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 329us/step - loss: 0.3992 - acc: 0.8075\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 323us/step - loss: 0.3977 - acc: 0.8199\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 303us/step - loss: 0.3969 - acc: 0.8137\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 307us/step - loss: 0.3944 - acc: 0.8137\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 321us/step - loss: 0.3929 - acc: 0.8137\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 331us/step - loss: 0.3910 - acc: 0.8137\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 329us/step - loss: 0.3896 - acc: 0.8137\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 316us/step - loss: 0.3884 - acc: 0.8199\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 315us/step - loss: 0.3877 - acc: 0.8323\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 332us/step - loss: 0.3858 - acc: 0.8323\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 304us/step - loss: 0.3912 - acc: 0.8075\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 299us/step - loss: 0.3919 - acc: 0.8137\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 298us/step - loss: 0.3836 - acc: 0.8261\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 362us/step - loss: 0.3842 - acc: 0.8323\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 337us/step - loss: 0.3816 - acc: 0.8323\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 331us/step - loss: 0.3780 - acc: 0.8323\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 303us/step - loss: 0.3779 - acc: 0.8199\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 316us/step - loss: 0.3764 - acc: 0.8199\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 301us/step - loss: 0.3755 - acc: 0.8323\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 282us/step - loss: 0.3737 - acc: 0.8261\n",
            "81/81 [==============================] - 4s 48ms/step\n",
            "161/161 [==============================] - 0s 207us/step\n",
            "Epoch 1/100\n",
            "161/161 [==============================] - 9s 55ms/step - loss: 0.6975 - acc: 0.4348\n",
            "Epoch 2/100\n",
            "161/161 [==============================] - 0s 303us/step - loss: 0.6916 - acc: 0.5342\n",
            "Epoch 3/100\n",
            "161/161 [==============================] - 0s 260us/step - loss: 0.6879 - acc: 0.5652\n",
            "Epoch 4/100\n",
            "161/161 [==============================] - 0s 263us/step - loss: 0.6860 - acc: 0.5342\n",
            "Epoch 5/100\n",
            "161/161 [==============================] - 0s 300us/step - loss: 0.6859 - acc: 0.5342\n",
            "Epoch 6/100\n",
            "161/161 [==============================] - 0s 249us/step - loss: 0.6852 - acc: 0.5342\n",
            "Epoch 7/100\n",
            "161/161 [==============================] - 0s 278us/step - loss: 0.6828 - acc: 0.5466\n",
            "Epoch 8/100\n",
            "161/161 [==============================] - 0s 282us/step - loss: 0.6838 - acc: 0.6025\n",
            "Epoch 9/100\n",
            "161/161 [==============================] - 0s 256us/step - loss: 0.6837 - acc: 0.4720\n",
            "Epoch 10/100\n",
            "161/161 [==============================] - 0s 268us/step - loss: 0.6834 - acc: 0.4658\n",
            "Epoch 11/100\n",
            "161/161 [==============================] - 0s 242us/step - loss: 0.6776 - acc: 0.7019\n",
            "Epoch 12/100\n",
            "161/161 [==============================] - 0s 227us/step - loss: 0.6758 - acc: 0.5404\n",
            "Epoch 13/100\n",
            "161/161 [==============================] - 0s 255us/step - loss: 0.6731 - acc: 0.5342\n",
            "Epoch 14/100\n",
            "161/161 [==============================] - 0s 321us/step - loss: 0.6751 - acc: 0.5342\n",
            "Epoch 15/100\n",
            "161/161 [==============================] - 0s 250us/step - loss: 0.6701 - acc: 0.5342\n",
            "Epoch 16/100\n",
            "161/161 [==============================] - 0s 262us/step - loss: 0.6654 - acc: 0.5342\n",
            "Epoch 17/100\n",
            "161/161 [==============================] - 0s 286us/step - loss: 0.6639 - acc: 0.5342\n",
            "Epoch 18/100\n",
            "161/161 [==============================] - 0s 255us/step - loss: 0.6593 - acc: 0.5466\n",
            "Epoch 19/100\n",
            "161/161 [==============================] - 0s 277us/step - loss: 0.6569 - acc: 0.6522\n",
            "Epoch 20/100\n",
            "161/161 [==============================] - 0s 259us/step - loss: 0.6565 - acc: 0.7143\n",
            "Epoch 21/100\n",
            "161/161 [==============================] - 0s 323us/step - loss: 0.6510 - acc: 0.7578\n",
            "Epoch 22/100\n",
            "161/161 [==============================] - 0s 254us/step - loss: 0.6489 - acc: 0.6211\n",
            "Epoch 23/100\n",
            "161/161 [==============================] - 0s 262us/step - loss: 0.6450 - acc: 0.6522\n",
            "Epoch 24/100\n",
            "161/161 [==============================] - 0s 269us/step - loss: 0.6420 - acc: 0.7888\n",
            "Epoch 25/100\n",
            "161/161 [==============================] - 0s 244us/step - loss: 0.6413 - acc: 0.8261\n",
            "Epoch 26/100\n",
            "161/161 [==============================] - 0s 279us/step - loss: 0.6417 - acc: 0.7205\n",
            "Epoch 27/100\n",
            "161/161 [==============================] - 0s 256us/step - loss: 0.6385 - acc: 0.7081\n",
            "Epoch 28/100\n",
            "161/161 [==============================] - 0s 262us/step - loss: 0.6338 - acc: 0.7205\n",
            "Epoch 29/100\n",
            "161/161 [==============================] - 0s 268us/step - loss: 0.6277 - acc: 0.7764\n",
            "Epoch 30/100\n",
            "161/161 [==============================] - 0s 255us/step - loss: 0.6203 - acc: 0.7826\n",
            "Epoch 31/100\n",
            "161/161 [==============================] - 0s 250us/step - loss: 0.6124 - acc: 0.7826\n",
            "Epoch 32/100\n",
            "161/161 [==============================] - 0s 304us/step - loss: 0.6090 - acc: 0.7640\n",
            "Epoch 33/100\n",
            "161/161 [==============================] - 0s 273us/step - loss: 0.6040 - acc: 0.7764\n",
            "Epoch 34/100\n",
            "161/161 [==============================] - 0s 264us/step - loss: 0.6011 - acc: 0.7578\n",
            "Epoch 35/100\n",
            "161/161 [==============================] - 0s 310us/step - loss: 0.5971 - acc: 0.7329\n",
            "Epoch 36/100\n",
            "161/161 [==============================] - 0s 297us/step - loss: 0.5868 - acc: 0.7826\n",
            "Epoch 37/100\n",
            "161/161 [==============================] - 0s 291us/step - loss: 0.5849 - acc: 0.8075\n",
            "Epoch 38/100\n",
            "161/161 [==============================] - 0s 287us/step - loss: 0.5840 - acc: 0.7950\n",
            "Epoch 39/100\n",
            "161/161 [==============================] - 0s 320us/step - loss: 0.5758 - acc: 0.7888\n",
            "Epoch 40/100\n",
            "161/161 [==============================] - 0s 307us/step - loss: 0.5645 - acc: 0.8199\n",
            "Epoch 41/100\n",
            "161/161 [==============================] - 0s 251us/step - loss: 0.5624 - acc: 0.7826\n",
            "Epoch 42/100\n",
            "161/161 [==============================] - 0s 289us/step - loss: 0.5558 - acc: 0.7888\n",
            "Epoch 43/100\n",
            "161/161 [==============================] - 0s 306us/step - loss: 0.5485 - acc: 0.8075\n",
            "Epoch 44/100\n",
            "161/161 [==============================] - 0s 315us/step - loss: 0.5425 - acc: 0.8137\n",
            "Epoch 45/100\n",
            "161/161 [==============================] - 0s 290us/step - loss: 0.5363 - acc: 0.8199\n",
            "Epoch 46/100\n",
            "161/161 [==============================] - 0s 274us/step - loss: 0.5294 - acc: 0.8137\n",
            "Epoch 47/100\n",
            "161/161 [==============================] - 0s 269us/step - loss: 0.5206 - acc: 0.8137\n",
            "Epoch 48/100\n",
            "161/161 [==============================] - 0s 290us/step - loss: 0.5129 - acc: 0.8075\n",
            "Epoch 49/100\n",
            "161/161 [==============================] - 0s 267us/step - loss: 0.5060 - acc: 0.8137\n",
            "Epoch 50/100\n",
            "161/161 [==============================] - 0s 242us/step - loss: 0.4993 - acc: 0.8137\n",
            "Epoch 51/100\n",
            "161/161 [==============================] - 0s 274us/step - loss: 0.4930 - acc: 0.8137\n",
            "Epoch 52/100\n",
            "161/161 [==============================] - 0s 244us/step - loss: 0.4863 - acc: 0.8261\n",
            "Epoch 53/100\n",
            "161/161 [==============================] - 0s 273us/step - loss: 0.4815 - acc: 0.8199\n",
            "Epoch 54/100\n",
            "161/161 [==============================] - 0s 261us/step - loss: 0.4778 - acc: 0.8137\n",
            "Epoch 55/100\n",
            "161/161 [==============================] - 0s 275us/step - loss: 0.4705 - acc: 0.8137\n",
            "Epoch 56/100\n",
            "161/161 [==============================] - 0s 270us/step - loss: 0.4663 - acc: 0.8075\n",
            "Epoch 57/100\n",
            "161/161 [==============================] - 0s 270us/step - loss: 0.4640 - acc: 0.8385\n",
            "Epoch 58/100\n",
            "161/161 [==============================] - 0s 260us/step - loss: 0.4670 - acc: 0.8137\n",
            "Epoch 59/100\n",
            "161/161 [==============================] - 0s 261us/step - loss: 0.4550 - acc: 0.8012\n",
            "Epoch 60/100\n",
            "161/161 [==============================] - 0s 293us/step - loss: 0.4453 - acc: 0.8137\n",
            "Epoch 61/100\n",
            "161/161 [==============================] - 0s 261us/step - loss: 0.4479 - acc: 0.8137\n",
            "Epoch 62/100\n",
            "161/161 [==============================] - 0s 278us/step - loss: 0.4477 - acc: 0.8199\n",
            "Epoch 63/100\n",
            "161/161 [==============================] - 0s 241us/step - loss: 0.4409 - acc: 0.8137\n",
            "Epoch 64/100\n",
            "161/161 [==============================] - 0s 243us/step - loss: 0.4345 - acc: 0.8261\n",
            "Epoch 65/100\n",
            "161/161 [==============================] - 0s 277us/step - loss: 0.4276 - acc: 0.8261\n",
            "Epoch 66/100\n",
            "161/161 [==============================] - 0s 261us/step - loss: 0.4224 - acc: 0.8199\n",
            "Epoch 67/100\n",
            "161/161 [==============================] - 0s 281us/step - loss: 0.4227 - acc: 0.8261\n",
            "Epoch 68/100\n",
            "161/161 [==============================] - 0s 241us/step - loss: 0.4173 - acc: 0.8199\n",
            "Epoch 69/100\n",
            "161/161 [==============================] - 0s 267us/step - loss: 0.4146 - acc: 0.8199\n",
            "Epoch 70/100\n",
            "161/161 [==============================] - 0s 239us/step - loss: 0.4110 - acc: 0.8199\n",
            "Epoch 71/100\n",
            "161/161 [==============================] - 0s 242us/step - loss: 0.4079 - acc: 0.8199\n",
            "Epoch 72/100\n",
            "161/161 [==============================] - 0s 251us/step - loss: 0.4053 - acc: 0.8137\n",
            "Epoch 73/100\n",
            "161/161 [==============================] - 0s 253us/step - loss: 0.4036 - acc: 0.8199\n",
            "Epoch 74/100\n",
            "161/161 [==============================] - 0s 278us/step - loss: 0.4014 - acc: 0.8261\n",
            "Epoch 75/100\n",
            "161/161 [==============================] - 0s 256us/step - loss: 0.4082 - acc: 0.8323\n",
            "Epoch 76/100\n",
            "161/161 [==============================] - 0s 248us/step - loss: 0.4085 - acc: 0.8323\n",
            "Epoch 77/100\n",
            "161/161 [==============================] - 0s 265us/step - loss: 0.3962 - acc: 0.8261\n",
            "Epoch 78/100\n",
            "161/161 [==============================] - 0s 262us/step - loss: 0.3954 - acc: 0.8199\n",
            "Epoch 79/100\n",
            "161/161 [==============================] - 0s 276us/step - loss: 0.3933 - acc: 0.8075\n",
            "Epoch 80/100\n",
            "161/161 [==============================] - 0s 275us/step - loss: 0.3911 - acc: 0.8012\n",
            "Epoch 81/100\n",
            "161/161 [==============================] - 0s 261us/step - loss: 0.3902 - acc: 0.8137\n",
            "Epoch 82/100\n",
            "161/161 [==============================] - 0s 255us/step - loss: 0.3872 - acc: 0.8137\n",
            "Epoch 83/100\n",
            "161/161 [==============================] - 0s 280us/step - loss: 0.3871 - acc: 0.8199\n",
            "Epoch 84/100\n",
            "161/161 [==============================] - 0s 305us/step - loss: 0.3896 - acc: 0.8323\n",
            "Epoch 85/100\n",
            "161/161 [==============================] - 0s 254us/step - loss: 0.3873 - acc: 0.8323\n",
            "Epoch 86/100\n",
            "161/161 [==============================] - 0s 258us/step - loss: 0.3848 - acc: 0.8137\n",
            "Epoch 87/100\n",
            "161/161 [==============================] - 0s 251us/step - loss: 0.3813 - acc: 0.8199\n",
            "Epoch 88/100\n",
            "161/161 [==============================] - 0s 241us/step - loss: 0.3812 - acc: 0.8137\n",
            "Epoch 89/100\n",
            "161/161 [==============================] - 0s 233us/step - loss: 0.3779 - acc: 0.8137\n",
            "Epoch 90/100\n",
            "161/161 [==============================] - 0s 257us/step - loss: 0.3794 - acc: 0.8199\n",
            "Epoch 91/100\n",
            "161/161 [==============================] - 0s 256us/step - loss: 0.3784 - acc: 0.8137\n",
            "Epoch 92/100\n",
            "161/161 [==============================] - 0s 228us/step - loss: 0.3764 - acc: 0.8199\n",
            "Epoch 93/100\n",
            "161/161 [==============================] - 0s 232us/step - loss: 0.3769 - acc: 0.8385\n",
            "Epoch 94/100\n",
            "161/161 [==============================] - 0s 264us/step - loss: 0.3812 - acc: 0.8261\n",
            "Epoch 95/100\n",
            "161/161 [==============================] - 0s 231us/step - loss: 0.3821 - acc: 0.8261\n",
            "Epoch 96/100\n",
            "161/161 [==============================] - 0s 253us/step - loss: 0.3772 - acc: 0.8323\n",
            "Epoch 97/100\n",
            "161/161 [==============================] - 0s 302us/step - loss: 0.3724 - acc: 0.8261\n",
            "Epoch 98/100\n",
            "161/161 [==============================] - 0s 278us/step - loss: 0.3763 - acc: 0.8199\n",
            "Epoch 99/100\n",
            "161/161 [==============================] - 0s 287us/step - loss: 0.3751 - acc: 0.8323\n",
            "Epoch 100/100\n",
            "161/161 [==============================] - 0s 253us/step - loss: 0.3694 - acc: 0.8261\n",
            "81/81 [==============================] - 4s 46ms/step\n",
            "161/161 [==============================] - 0s 199us/step\n",
            "Epoch 1/100\n",
            "162/162 [==============================] - 9s 54ms/step - loss: 0.7397 - acc: 0.5617\n",
            "Epoch 2/100\n",
            "162/162 [==============================] - 0s 249us/step - loss: 0.7014 - acc: 0.5617\n",
            "Epoch 3/100\n",
            "162/162 [==============================] - 0s 246us/step - loss: 0.6889 - acc: 0.5617\n",
            "Epoch 4/100\n",
            "162/162 [==============================] - 0s 253us/step - loss: 0.6870 - acc: 0.5617\n",
            "Epoch 5/100\n",
            "162/162 [==============================] - 0s 270us/step - loss: 0.6869 - acc: 0.5617\n",
            "Epoch 6/100\n",
            "162/162 [==============================] - 0s 279us/step - loss: 0.6843 - acc: 0.5617\n",
            "Epoch 7/100\n",
            "162/162 [==============================] - 0s 306us/step - loss: 0.6841 - acc: 0.5617\n",
            "Epoch 8/100\n",
            "162/162 [==============================] - 0s 268us/step - loss: 0.6820 - acc: 0.5617\n",
            "Epoch 9/100\n",
            "162/162 [==============================] - 0s 276us/step - loss: 0.6806 - acc: 0.5617\n",
            "Epoch 10/100\n",
            "162/162 [==============================] - 0s 261us/step - loss: 0.6811 - acc: 0.5617\n",
            "Epoch 11/100\n",
            "162/162 [==============================] - 0s 280us/step - loss: 0.6804 - acc: 0.5617\n",
            "Epoch 12/100\n",
            "162/162 [==============================] - 0s 268us/step - loss: 0.6755 - acc: 0.5617\n",
            "Epoch 13/100\n",
            "162/162 [==============================] - 0s 316us/step - loss: 0.6747 - acc: 0.5617\n",
            "Epoch 14/100\n",
            "162/162 [==============================] - 0s 271us/step - loss: 0.6729 - acc: 0.5617\n",
            "Epoch 15/100\n",
            "162/162 [==============================] - 0s 272us/step - loss: 0.6700 - acc: 0.5617\n",
            "Epoch 16/100\n",
            "162/162 [==============================] - 0s 275us/step - loss: 0.6689 - acc: 0.5617\n",
            "Epoch 17/100\n",
            "162/162 [==============================] - 0s 259us/step - loss: 0.6676 - acc: 0.5617\n",
            "Epoch 18/100\n",
            "162/162 [==============================] - 0s 275us/step - loss: 0.6648 - acc: 0.5617\n",
            "Epoch 19/100\n",
            "162/162 [==============================] - 0s 262us/step - loss: 0.6618 - acc: 0.5617\n",
            "Epoch 20/100\n",
            "162/162 [==============================] - 0s 249us/step - loss: 0.6602 - acc: 0.5617\n",
            "Epoch 21/100\n",
            "162/162 [==============================] - 0s 256us/step - loss: 0.6551 - acc: 0.5741\n",
            "Epoch 22/100\n",
            "162/162 [==============================] - 0s 247us/step - loss: 0.6556 - acc: 0.7284\n",
            "Epoch 23/100\n",
            "162/162 [==============================] - 0s 313us/step - loss: 0.6565 - acc: 0.8086\n",
            "Epoch 24/100\n",
            "162/162 [==============================] - 0s 289us/step - loss: 0.6476 - acc: 0.7099\n",
            "Epoch 25/100\n",
            "162/162 [==============================] - 0s 278us/step - loss: 0.6482 - acc: 0.5617\n",
            "Epoch 26/100\n",
            "162/162 [==============================] - 0s 248us/step - loss: 0.6452 - acc: 0.5617\n",
            "Epoch 27/100\n",
            "162/162 [==============================] - 0s 276us/step - loss: 0.6405 - acc: 0.5617\n",
            "Epoch 28/100\n",
            "162/162 [==============================] - 0s 324us/step - loss: 0.6365 - acc: 0.5679\n",
            "Epoch 29/100\n",
            "162/162 [==============================] - 0s 272us/step - loss: 0.6342 - acc: 0.5679\n",
            "Epoch 30/100\n",
            "162/162 [==============================] - 0s 248us/step - loss: 0.6270 - acc: 0.6111\n",
            "Epoch 31/100\n",
            "162/162 [==============================] - 0s 248us/step - loss: 0.6207 - acc: 0.6975\n",
            "Epoch 32/100\n",
            "162/162 [==============================] - 0s 240us/step - loss: 0.6204 - acc: 0.7716\n",
            "Epoch 33/100\n",
            "162/162 [==============================] - 0s 255us/step - loss: 0.6153 - acc: 0.7778\n",
            "Epoch 34/100\n",
            "162/162 [==============================] - 0s 261us/step - loss: 0.6073 - acc: 0.7654\n",
            "Epoch 35/100\n",
            "162/162 [==============================] - 0s 251us/step - loss: 0.6030 - acc: 0.7654\n",
            "Epoch 36/100\n",
            "162/162 [==============================] - 0s 256us/step - loss: 0.5967 - acc: 0.7901\n",
            "Epoch 37/100\n",
            "162/162 [==============================] - 0s 222us/step - loss: 0.5917 - acc: 0.8025\n",
            "Epoch 38/100\n",
            "162/162 [==============================] - 0s 259us/step - loss: 0.5830 - acc: 0.7654\n",
            "Epoch 39/100\n",
            "162/162 [==============================] - 0s 227us/step - loss: 0.5790 - acc: 0.7222\n",
            "Epoch 40/100\n",
            "162/162 [==============================] - 0s 247us/step - loss: 0.5758 - acc: 0.7346\n",
            "Epoch 41/100\n",
            "162/162 [==============================] - 0s 297us/step - loss: 0.5667 - acc: 0.7593\n",
            "Epoch 42/100\n",
            "162/162 [==============================] - 0s 233us/step - loss: 0.5613 - acc: 0.7716\n",
            "Epoch 43/100\n",
            "162/162 [==============================] - 0s 262us/step - loss: 0.5554 - acc: 0.7716\n",
            "Epoch 44/100\n",
            "162/162 [==============================] - 0s 247us/step - loss: 0.5505 - acc: 0.7716\n",
            "Epoch 45/100\n",
            "162/162 [==============================] - 0s 235us/step - loss: 0.5462 - acc: 0.7469\n",
            "Epoch 46/100\n",
            "162/162 [==============================] - 0s 237us/step - loss: 0.5349 - acc: 0.7901\n",
            "Epoch 47/100\n",
            "162/162 [==============================] - 0s 258us/step - loss: 0.5321 - acc: 0.7901\n",
            "Epoch 48/100\n",
            "162/162 [==============================] - 0s 268us/step - loss: 0.5295 - acc: 0.7963\n",
            "Epoch 49/100\n",
            "162/162 [==============================] - 0s 234us/step - loss: 0.5198 - acc: 0.8025\n",
            "Epoch 50/100\n",
            "162/162 [==============================] - 0s 235us/step - loss: 0.5149 - acc: 0.7901\n",
            "Epoch 51/100\n",
            "162/162 [==============================] - 0s 234us/step - loss: 0.5092 - acc: 0.8025\n",
            "Epoch 52/100\n",
            "162/162 [==============================] - 0s 273us/step - loss: 0.5025 - acc: 0.8086\n",
            "Epoch 53/100\n",
            "162/162 [==============================] - 0s 303us/step - loss: 0.4972 - acc: 0.7840\n",
            "Epoch 54/100\n",
            "162/162 [==============================] - 0s 282us/step - loss: 0.4913 - acc: 0.8025\n",
            "Epoch 55/100\n",
            "162/162 [==============================] - 0s 244us/step - loss: 0.4873 - acc: 0.8025\n",
            "Epoch 56/100\n",
            "162/162 [==============================] - 0s 250us/step - loss: 0.4815 - acc: 0.8025\n",
            "Epoch 57/100\n",
            "162/162 [==============================] - 0s 272us/step - loss: 0.4755 - acc: 0.7840\n",
            "Epoch 58/100\n",
            "162/162 [==============================] - 0s 284us/step - loss: 0.4716 - acc: 0.8025\n",
            "Epoch 59/100\n",
            "162/162 [==============================] - 0s 265us/step - loss: 0.4682 - acc: 0.8025\n",
            "Epoch 60/100\n",
            "162/162 [==============================] - 0s 267us/step - loss: 0.4636 - acc: 0.8025\n",
            "Epoch 61/100\n",
            "162/162 [==============================] - 0s 278us/step - loss: 0.4604 - acc: 0.8148\n",
            "Epoch 62/100\n",
            "162/162 [==============================] - 0s 284us/step - loss: 0.4572 - acc: 0.8210\n",
            "Epoch 63/100\n",
            "162/162 [==============================] - 0s 262us/step - loss: 0.4512 - acc: 0.8086\n",
            "Epoch 64/100\n",
            "162/162 [==============================] - 0s 273us/step - loss: 0.4465 - acc: 0.8086\n",
            "Epoch 65/100\n",
            "162/162 [==============================] - 0s 263us/step - loss: 0.4446 - acc: 0.8086\n",
            "Epoch 66/100\n",
            "162/162 [==============================] - 0s 284us/step - loss: 0.4395 - acc: 0.8148\n",
            "Epoch 67/100\n",
            "162/162 [==============================] - 0s 262us/step - loss: 0.4366 - acc: 0.8086\n",
            "Epoch 68/100\n",
            "162/162 [==============================] - 0s 235us/step - loss: 0.4337 - acc: 0.8025\n",
            "Epoch 69/100\n",
            "162/162 [==============================] - 0s 263us/step - loss: 0.4309 - acc: 0.8025\n",
            "Epoch 70/100\n",
            "162/162 [==============================] - 0s 254us/step - loss: 0.4285 - acc: 0.8086\n",
            "Epoch 71/100\n",
            "162/162 [==============================] - 0s 251us/step - loss: 0.4251 - acc: 0.8086\n",
            "Epoch 72/100\n",
            "162/162 [==============================] - 0s 243us/step - loss: 0.4247 - acc: 0.8086\n",
            "Epoch 73/100\n",
            "162/162 [==============================] - 0s 251us/step - loss: 0.4242 - acc: 0.8210\n",
            "Epoch 74/100\n",
            "162/162 [==============================] - 0s 245us/step - loss: 0.4209 - acc: 0.8272\n",
            "Epoch 75/100\n",
            "162/162 [==============================] - 0s 276us/step - loss: 0.4169 - acc: 0.8025\n",
            "Epoch 76/100\n",
            "162/162 [==============================] - 0s 243us/step - loss: 0.4145 - acc: 0.8272\n",
            "Epoch 77/100\n",
            "162/162 [==============================] - 0s 241us/step - loss: 0.4143 - acc: 0.8272\n",
            "Epoch 78/100\n",
            "162/162 [==============================] - 0s 253us/step - loss: 0.4128 - acc: 0.8148\n",
            "Epoch 79/100\n",
            "162/162 [==============================] - 0s 265us/step - loss: 0.4116 - acc: 0.8148\n",
            "Epoch 80/100\n",
            "162/162 [==============================] - 0s 247us/step - loss: 0.4085 - acc: 0.8210\n",
            "Epoch 81/100\n",
            "162/162 [==============================] - 0s 238us/step - loss: 0.4073 - acc: 0.8272\n",
            "Epoch 82/100\n",
            "162/162 [==============================] - 0s 251us/step - loss: 0.4066 - acc: 0.8272\n",
            "Epoch 83/100\n",
            "162/162 [==============================] - 0s 260us/step - loss: 0.4043 - acc: 0.8272\n",
            "Epoch 84/100\n",
            "162/162 [==============================] - 0s 258us/step - loss: 0.4022 - acc: 0.8272\n",
            "Epoch 85/100\n",
            "162/162 [==============================] - 0s 248us/step - loss: 0.4025 - acc: 0.8086\n",
            "Epoch 86/100\n",
            "162/162 [==============================] - 0s 238us/step - loss: 0.4020 - acc: 0.8025\n",
            "Epoch 87/100\n",
            "162/162 [==============================] - 0s 243us/step - loss: 0.4009 - acc: 0.8272\n",
            "Epoch 88/100\n",
            "162/162 [==============================] - 0s 236us/step - loss: 0.3975 - acc: 0.8272\n",
            "Epoch 89/100\n",
            "162/162 [==============================] - 0s 255us/step - loss: 0.3970 - acc: 0.8272\n",
            "Epoch 90/100\n",
            "162/162 [==============================] - 0s 251us/step - loss: 0.3963 - acc: 0.8272\n",
            "Epoch 91/100\n",
            "162/162 [==============================] - 0s 297us/step - loss: 0.3957 - acc: 0.8395\n",
            "Epoch 92/100\n",
            "162/162 [==============================] - 0s 282us/step - loss: 0.3961 - acc: 0.8457\n",
            "Epoch 93/100\n",
            "162/162 [==============================] - 0s 289us/step - loss: 0.3941 - acc: 0.8395\n",
            "Epoch 94/100\n",
            "162/162 [==============================] - 0s 258us/step - loss: 0.3927 - acc: 0.8395\n",
            "Epoch 95/100\n",
            "162/162 [==============================] - 0s 263us/step - loss: 0.3899 - acc: 0.8333\n",
            "Epoch 96/100\n",
            "162/162 [==============================] - 0s 272us/step - loss: 0.3893 - acc: 0.8272\n",
            "Epoch 97/100\n",
            "162/162 [==============================] - 0s 280us/step - loss: 0.3881 - acc: 0.8272\n",
            "Epoch 98/100\n",
            "162/162 [==============================] - 0s 274us/step - loss: 0.3877 - acc: 0.8272\n",
            "Epoch 99/100\n",
            "162/162 [==============================] - 0s 258us/step - loss: 0.3864 - acc: 0.8395\n",
            "Epoch 100/100\n",
            "162/162 [==============================] - 0s 258us/step - loss: 0.3887 - acc: 0.8395\n",
            "80/80 [==============================] - 4s 47ms/step\n",
            "162/162 [==============================] - 0s 186us/step\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 9s 37ms/step - loss: 0.7043 - acc: 0.5496\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 242us/step - loss: 0.6916 - acc: 0.5496\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 224us/step - loss: 0.6878 - acc: 0.5496\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 234us/step - loss: 0.6857 - acc: 0.5496\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 220us/step - loss: 0.6839 - acc: 0.5496\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 216us/step - loss: 0.6822 - acc: 0.5496\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 256us/step - loss: 0.6809 - acc: 0.5537\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 215us/step - loss: 0.6771 - acc: 0.5496\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 215us/step - loss: 0.6742 - acc: 0.5496\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 190us/step - loss: 0.6713 - acc: 0.5496\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 215us/step - loss: 0.6688 - acc: 0.5702\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 214us/step - loss: 0.6648 - acc: 0.5826\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 221us/step - loss: 0.6609 - acc: 0.6322\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 214us/step - loss: 0.6554 - acc: 0.5950\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 223us/step - loss: 0.6516 - acc: 0.5579\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 209us/step - loss: 0.6466 - acc: 0.5579\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 214us/step - loss: 0.6411 - acc: 0.7479\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 230us/step - loss: 0.6345 - acc: 0.8099\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 231us/step - loss: 0.6249 - acc: 0.6901\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 234us/step - loss: 0.6181 - acc: 0.6983\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 211us/step - loss: 0.6075 - acc: 0.7355\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 216us/step - loss: 0.5993 - acc: 0.7397\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 221us/step - loss: 0.5889 - acc: 0.7851\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 235us/step - loss: 0.5779 - acc: 0.8058\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 213us/step - loss: 0.5689 - acc: 0.7810\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 211us/step - loss: 0.5594 - acc: 0.7769\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 215us/step - loss: 0.5462 - acc: 0.7975\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 225us/step - loss: 0.5334 - acc: 0.8099\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 218us/step - loss: 0.5212 - acc: 0.8140\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 241us/step - loss: 0.5171 - acc: 0.8017\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 230us/step - loss: 0.5028 - acc: 0.8099\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 229us/step - loss: 0.4919 - acc: 0.8017\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 247us/step - loss: 0.4801 - acc: 0.8140\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 225us/step - loss: 0.4709 - acc: 0.8017\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 230us/step - loss: 0.4619 - acc: 0.8058\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 249us/step - loss: 0.4557 - acc: 0.8099\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 216us/step - loss: 0.4492 - acc: 0.8099\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 214us/step - loss: 0.4413 - acc: 0.8099\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 234us/step - loss: 0.4442 - acc: 0.7934\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 226us/step - loss: 0.4313 - acc: 0.8017\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 222us/step - loss: 0.4261 - acc: 0.8058\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 214us/step - loss: 0.4197 - acc: 0.8058\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 209us/step - loss: 0.4169 - acc: 0.8099\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 230us/step - loss: 0.4132 - acc: 0.8058\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 209us/step - loss: 0.4112 - acc: 0.8140\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 242us/step - loss: 0.4072 - acc: 0.8140\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 229us/step - loss: 0.4033 - acc: 0.8058\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 199us/step - loss: 0.4010 - acc: 0.8058\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 230us/step - loss: 0.3983 - acc: 0.8058\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 245us/step - loss: 0.3983 - acc: 0.8099\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 233us/step - loss: 0.3947 - acc: 0.8140\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 221us/step - loss: 0.3922 - acc: 0.8140\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 228us/step - loss: 0.3913 - acc: 0.8182\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 240us/step - loss: 0.3892 - acc: 0.8182\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 218us/step - loss: 0.3878 - acc: 0.8182\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 242us/step - loss: 0.3867 - acc: 0.8182\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 225us/step - loss: 0.3853 - acc: 0.8223\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 205us/step - loss: 0.3860 - acc: 0.8264\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 224us/step - loss: 0.3814 - acc: 0.8223\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 225us/step - loss: 0.3822 - acc: 0.8182\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 229us/step - loss: 0.3806 - acc: 0.8264\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 213us/step - loss: 0.3818 - acc: 0.8223\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 228us/step - loss: 0.3785 - acc: 0.8264\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 241us/step - loss: 0.3805 - acc: 0.8223\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 211us/step - loss: 0.3787 - acc: 0.8223\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 221us/step - loss: 0.3781 - acc: 0.8264\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 215us/step - loss: 0.3804 - acc: 0.8182\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 234us/step - loss: 0.3759 - acc: 0.8347\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 228us/step - loss: 0.3758 - acc: 0.8223\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 245us/step - loss: 0.3759 - acc: 0.8306\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 233us/step - loss: 0.3738 - acc: 0.8430\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 220us/step - loss: 0.3726 - acc: 0.8347\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 241us/step - loss: 0.3727 - acc: 0.8347\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 220us/step - loss: 0.3726 - acc: 0.8388\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 216us/step - loss: 0.3742 - acc: 0.8223\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 228us/step - loss: 0.3709 - acc: 0.8264\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 223us/step - loss: 0.3716 - acc: 0.8430\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 243us/step - loss: 0.3707 - acc: 0.8347\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 229us/step - loss: 0.3710 - acc: 0.8347\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 221us/step - loss: 0.3681 - acc: 0.8430\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 236us/step - loss: 0.3687 - acc: 0.8430\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 225us/step - loss: 0.3688 - acc: 0.8430\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 225us/step - loss: 0.3675 - acc: 0.8430\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 222us/step - loss: 0.3673 - acc: 0.8471\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 233us/step - loss: 0.3674 - acc: 0.8430\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 243us/step - loss: 0.3688 - acc: 0.8388\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 209us/step - loss: 0.3688 - acc: 0.8388\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 218us/step - loss: 0.3679 - acc: 0.8347\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 228us/step - loss: 0.3659 - acc: 0.8388\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 214us/step - loss: 0.3655 - acc: 0.8471\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 221us/step - loss: 0.3702 - acc: 0.8430\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 221us/step - loss: 0.3653 - acc: 0.8430\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 240us/step - loss: 0.3652 - acc: 0.8471\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 215us/step - loss: 0.3646 - acc: 0.8471\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 226us/step - loss: 0.3717 - acc: 0.8347\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 218us/step - loss: 0.3651 - acc: 0.8306\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 228us/step - loss: 0.3642 - acc: 0.8430\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 232us/step - loss: 0.3654 - acc: 0.8471\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 206us/step - loss: 0.3644 - acc: 0.8430\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 227us/step - loss: 0.3643 - acc: 0.8512\n",
            "Best: 0.797521 using {'batch_size': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HA00NyBJrZ4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17136
        },
        "outputId": "e78103a6-4e3d-48db-8a01-4183d1409f3e"
      },
      "cell_type": "code",
      "source": [
        "# Same as initial, but with all the GridSearched Recommendations. \n",
        "\n",
        "def baseline(optimizer = \"adam\", init = \"uniform\", activation='sigmoid'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(39, input_dim=X.shape[1], activation=activation))\n",
        "  model.add(Dense(39, activation=activation))\n",
        "  model.add(Dense(1, activation=activation))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=baseline, epochs=100, batch_size=20, verbose=1)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "\n",
        "print(\"Before GridSearchCV results were: 56.86% (11.32%) \")\n",
        "print(\"With GridSearchCV finding new results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "193/193 [==============================] - 10s 50ms/step - loss: 0.7674 - acc: 0.4508\n",
            "Epoch 2/100\n",
            "193/193 [==============================] - 0s 234us/step - loss: 0.7096 - acc: 0.4456\n",
            "Epoch 3/100\n",
            "193/193 [==============================] - 0s 220us/step - loss: 0.6902 - acc: 0.5492\n",
            "Epoch 4/100\n",
            "193/193 [==============================] - 0s 234us/step - loss: 0.6876 - acc: 0.5492\n",
            "Epoch 5/100\n",
            "193/193 [==============================] - 0s 226us/step - loss: 0.6851 - acc: 0.5492\n",
            "Epoch 6/100\n",
            "193/193 [==============================] - 0s 224us/step - loss: 0.6832 - acc: 0.5492\n",
            "Epoch 7/100\n",
            "193/193 [==============================] - 0s 236us/step - loss: 0.6814 - acc: 0.5492\n",
            "Epoch 8/100\n",
            "193/193 [==============================] - 0s 241us/step - loss: 0.6797 - acc: 0.5492\n",
            "Epoch 9/100\n",
            "193/193 [==============================] - 0s 234us/step - loss: 0.6786 - acc: 0.5492\n",
            "Epoch 10/100\n",
            "193/193 [==============================] - 0s 250us/step - loss: 0.6764 - acc: 0.5492\n",
            "Epoch 11/100\n",
            "193/193 [==============================] - 0s 322us/step - loss: 0.6748 - acc: 0.5492\n",
            "Epoch 12/100\n",
            "193/193 [==============================] - 0s 226us/step - loss: 0.6725 - acc: 0.5492\n",
            "Epoch 13/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.6695 - acc: 0.5492\n",
            "Epoch 14/100\n",
            "193/193 [==============================] - 0s 263us/step - loss: 0.6672 - acc: 0.5492\n",
            "Epoch 15/100\n",
            "193/193 [==============================] - 0s 245us/step - loss: 0.6647 - acc: 0.5544\n",
            "Epoch 16/100\n",
            "193/193 [==============================] - 0s 258us/step - loss: 0.6627 - acc: 0.6114\n",
            "Epoch 17/100\n",
            "193/193 [==============================] - 0s 265us/step - loss: 0.6590 - acc: 0.5648\n",
            "Epoch 18/100\n",
            "193/193 [==============================] - 0s 289us/step - loss: 0.6541 - acc: 0.5492\n",
            "Epoch 19/100\n",
            "193/193 [==============================] - 0s 233us/step - loss: 0.6502 - acc: 0.5544\n",
            "Epoch 20/100\n",
            "193/193 [==============================] - 0s 281us/step - loss: 0.6447 - acc: 0.6373\n",
            "Epoch 21/100\n",
            "193/193 [==============================] - 0s 250us/step - loss: 0.6397 - acc: 0.7150\n",
            "Epoch 22/100\n",
            "193/193 [==============================] - 0s 291us/step - loss: 0.6348 - acc: 0.7047\n",
            "Epoch 23/100\n",
            "193/193 [==============================] - 0s 217us/step - loss: 0.6284 - acc: 0.7202\n",
            "Epoch 24/100\n",
            "193/193 [==============================] - 0s 254us/step - loss: 0.6214 - acc: 0.7358\n",
            "Epoch 25/100\n",
            "193/193 [==============================] - 0s 248us/step - loss: 0.6146 - acc: 0.7720\n",
            "Epoch 26/100\n",
            "193/193 [==============================] - 0s 262us/step - loss: 0.6068 - acc: 0.7824\n",
            "Epoch 27/100\n",
            "193/193 [==============================] - 0s 274us/step - loss: 0.5988 - acc: 0.7876\n",
            "Epoch 28/100\n",
            "193/193 [==============================] - 0s 287us/step - loss: 0.5900 - acc: 0.7927\n",
            "Epoch 29/100\n",
            "193/193 [==============================] - 0s 246us/step - loss: 0.5829 - acc: 0.7927\n",
            "Epoch 30/100\n",
            "193/193 [==============================] - 0s 271us/step - loss: 0.5722 - acc: 0.8135\n",
            "Epoch 31/100\n",
            "193/193 [==============================] - 0s 286us/step - loss: 0.5636 - acc: 0.8135\n",
            "Epoch 32/100\n",
            "193/193 [==============================] - 0s 257us/step - loss: 0.5530 - acc: 0.8031\n",
            "Epoch 33/100\n",
            "193/193 [==============================] - 0s 271us/step - loss: 0.5426 - acc: 0.8031\n",
            "Epoch 34/100\n",
            "193/193 [==============================] - 0s 236us/step - loss: 0.5320 - acc: 0.8031\n",
            "Epoch 35/100\n",
            "193/193 [==============================] - 0s 245us/step - loss: 0.5224 - acc: 0.8031\n",
            "Epoch 36/100\n",
            "193/193 [==============================] - 0s 259us/step - loss: 0.5125 - acc: 0.8031\n",
            "Epoch 37/100\n",
            "193/193 [==============================] - 0s 283us/step - loss: 0.5022 - acc: 0.8031\n",
            "Epoch 38/100\n",
            "193/193 [==============================] - 0s 239us/step - loss: 0.4920 - acc: 0.7979\n",
            "Epoch 39/100\n",
            "193/193 [==============================] - 0s 254us/step - loss: 0.4833 - acc: 0.7979\n",
            "Epoch 40/100\n",
            "193/193 [==============================] - 0s 248us/step - loss: 0.4759 - acc: 0.7979\n",
            "Epoch 41/100\n",
            "193/193 [==============================] - 0s 291us/step - loss: 0.4662 - acc: 0.7927\n",
            "Epoch 42/100\n",
            "193/193 [==============================] - 0s 240us/step - loss: 0.4598 - acc: 0.8031\n",
            "Epoch 43/100\n",
            "193/193 [==============================] - 0s 241us/step - loss: 0.4513 - acc: 0.8083\n",
            "Epoch 44/100\n",
            "193/193 [==============================] - 0s 277us/step - loss: 0.4446 - acc: 0.7979\n",
            "Epoch 45/100\n",
            "193/193 [==============================] - 0s 229us/step - loss: 0.4387 - acc: 0.8031\n",
            "Epoch 46/100\n",
            "193/193 [==============================] - 0s 258us/step - loss: 0.4316 - acc: 0.8083\n",
            "Epoch 47/100\n",
            "193/193 [==============================] - 0s 236us/step - loss: 0.4281 - acc: 0.8031\n",
            "Epoch 48/100\n",
            "193/193 [==============================] - 0s 303us/step - loss: 0.4215 - acc: 0.8083\n",
            "Epoch 49/100\n",
            "193/193 [==============================] - 0s 243us/step - loss: 0.4180 - acc: 0.8083\n",
            "Epoch 50/100\n",
            "193/193 [==============================] - 0s 238us/step - loss: 0.4169 - acc: 0.8031\n",
            "Epoch 51/100\n",
            "193/193 [==============================] - 0s 260us/step - loss: 0.4136 - acc: 0.8187\n",
            "Epoch 52/100\n",
            "193/193 [==============================] - 0s 309us/step - loss: 0.4078 - acc: 0.8083\n",
            "Epoch 53/100\n",
            "193/193 [==============================] - 0s 256us/step - loss: 0.4040 - acc: 0.8031\n",
            "Epoch 54/100\n",
            "193/193 [==============================] - 0s 250us/step - loss: 0.4015 - acc: 0.8031\n",
            "Epoch 55/100\n",
            "193/193 [==============================] - 0s 223us/step - loss: 0.3987 - acc: 0.8083\n",
            "Epoch 56/100\n",
            "193/193 [==============================] - 0s 333us/step - loss: 0.3966 - acc: 0.8083\n",
            "Epoch 57/100\n",
            "193/193 [==============================] - 0s 242us/step - loss: 0.3941 - acc: 0.8031\n",
            "Epoch 58/100\n",
            "193/193 [==============================] - 0s 272us/step - loss: 0.3926 - acc: 0.8083\n",
            "Epoch 59/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.3908 - acc: 0.8135\n",
            "Epoch 60/100\n",
            "193/193 [==============================] - 0s 247us/step - loss: 0.3883 - acc: 0.8187\n",
            "Epoch 61/100\n",
            "193/193 [==============================] - 0s 282us/step - loss: 0.3868 - acc: 0.8083\n",
            "Epoch 62/100\n",
            "193/193 [==============================] - 0s 222us/step - loss: 0.3859 - acc: 0.8135\n",
            "Epoch 63/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.3838 - acc: 0.8187\n",
            "Epoch 64/100\n",
            "193/193 [==============================] - 0s 272us/step - loss: 0.3828 - acc: 0.8187\n",
            "Epoch 65/100\n",
            "193/193 [==============================] - 0s 253us/step - loss: 0.3816 - acc: 0.8135\n",
            "Epoch 66/100\n",
            "193/193 [==============================] - 0s 260us/step - loss: 0.3807 - acc: 0.8187\n",
            "Epoch 67/100\n",
            "193/193 [==============================] - 0s 261us/step - loss: 0.3801 - acc: 0.8238\n",
            "Epoch 68/100\n",
            "193/193 [==============================] - 0s 281us/step - loss: 0.3786 - acc: 0.8187\n",
            "Epoch 69/100\n",
            "193/193 [==============================] - 0s 210us/step - loss: 0.3779 - acc: 0.8342\n",
            "Epoch 70/100\n",
            "193/193 [==============================] - 0s 235us/step - loss: 0.3768 - acc: 0.8238\n",
            "Epoch 71/100\n",
            "193/193 [==============================] - 0s 253us/step - loss: 0.3772 - acc: 0.8135\n",
            "Epoch 72/100\n",
            "193/193 [==============================] - 0s 260us/step - loss: 0.3749 - acc: 0.8238\n",
            "Epoch 73/100\n",
            "193/193 [==============================] - 0s 231us/step - loss: 0.3743 - acc: 0.8342\n",
            "Epoch 74/100\n",
            "193/193 [==============================] - 0s 243us/step - loss: 0.3754 - acc: 0.8394\n",
            "Epoch 75/100\n",
            "193/193 [==============================] - 0s 290us/step - loss: 0.3727 - acc: 0.8342\n",
            "Epoch 76/100\n",
            "193/193 [==============================] - 0s 238us/step - loss: 0.3730 - acc: 0.8290\n",
            "Epoch 77/100\n",
            "193/193 [==============================] - 0s 237us/step - loss: 0.3728 - acc: 0.8290\n",
            "Epoch 78/100\n",
            "193/193 [==============================] - 0s 235us/step - loss: 0.3719 - acc: 0.8342\n",
            "Epoch 79/100\n",
            "193/193 [==============================] - 0s 218us/step - loss: 0.3715 - acc: 0.8342\n",
            "Epoch 80/100\n",
            "193/193 [==============================] - 0s 228us/step - loss: 0.3723 - acc: 0.8394\n",
            "Epoch 81/100\n",
            "193/193 [==============================] - 0s 243us/step - loss: 0.3701 - acc: 0.8342\n",
            "Epoch 82/100\n",
            "193/193 [==============================] - 0s 286us/step - loss: 0.3693 - acc: 0.8342\n",
            "Epoch 83/100\n",
            "193/193 [==============================] - 0s 291us/step - loss: 0.3711 - acc: 0.8394\n",
            "Epoch 84/100\n",
            "193/193 [==============================] - 0s 244us/step - loss: 0.3693 - acc: 0.8342\n",
            "Epoch 85/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.3685 - acc: 0.8394\n",
            "Epoch 86/100\n",
            "193/193 [==============================] - 0s 276us/step - loss: 0.3684 - acc: 0.8342\n",
            "Epoch 87/100\n",
            "193/193 [==============================] - 0s 295us/step - loss: 0.3678 - acc: 0.8342\n",
            "Epoch 88/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.3687 - acc: 0.8497\n",
            "Epoch 89/100\n",
            "193/193 [==============================] - 0s 247us/step - loss: 0.3681 - acc: 0.8394\n",
            "Epoch 90/100\n",
            "193/193 [==============================] - 0s 232us/step - loss: 0.3669 - acc: 0.8394\n",
            "Epoch 91/100\n",
            "193/193 [==============================] - 0s 242us/step - loss: 0.3671 - acc: 0.8394\n",
            "Epoch 92/100\n",
            "193/193 [==============================] - 0s 297us/step - loss: 0.3693 - acc: 0.8446\n",
            "Epoch 93/100\n",
            "193/193 [==============================] - 0s 253us/step - loss: 0.3670 - acc: 0.8394\n",
            "Epoch 94/100\n",
            "193/193 [==============================] - 0s 272us/step - loss: 0.3660 - acc: 0.8446\n",
            "Epoch 95/100\n",
            "193/193 [==============================] - 0s 279us/step - loss: 0.3662 - acc: 0.8394\n",
            "Epoch 96/100\n",
            "193/193 [==============================] - 0s 256us/step - loss: 0.3649 - acc: 0.8497\n",
            "Epoch 97/100\n",
            "193/193 [==============================] - 0s 238us/step - loss: 0.3666 - acc: 0.8497\n",
            "Epoch 98/100\n",
            "193/193 [==============================] - 0s 273us/step - loss: 0.3658 - acc: 0.8446\n",
            "Epoch 99/100\n",
            "193/193 [==============================] - 0s 254us/step - loss: 0.3649 - acc: 0.8446\n",
            "Epoch 100/100\n",
            "193/193 [==============================] - 0s 280us/step - loss: 0.3652 - acc: 0.8446\n",
            "49/49 [==============================] - 4s 81ms/step\n",
            "Epoch 1/100\n",
            "193/193 [==============================] - 10s 50ms/step - loss: 0.6909 - acc: 0.5492\n",
            "Epoch 2/100\n",
            "193/193 [==============================] - 0s 276us/step - loss: 0.6857 - acc: 0.5492\n",
            "Epoch 3/100\n",
            "193/193 [==============================] - 0s 282us/step - loss: 0.6819 - acc: 0.5492\n",
            "Epoch 4/100\n",
            "193/193 [==============================] - 0s 326us/step - loss: 0.6800 - acc: 0.5492\n",
            "Epoch 5/100\n",
            "193/193 [==============================] - 0s 317us/step - loss: 0.6778 - acc: 0.5492\n",
            "Epoch 6/100\n",
            "193/193 [==============================] - 0s 306us/step - loss: 0.6748 - acc: 0.5492\n",
            "Epoch 7/100\n",
            "193/193 [==============================] - 0s 340us/step - loss: 0.6724 - acc: 0.5492\n",
            "Epoch 8/100\n",
            "193/193 [==============================] - 0s 298us/step - loss: 0.6688 - acc: 0.5492\n",
            "Epoch 9/100\n",
            "193/193 [==============================] - 0s 281us/step - loss: 0.6659 - acc: 0.5492\n",
            "Epoch 10/100\n",
            "193/193 [==============================] - 0s 282us/step - loss: 0.6620 - acc: 0.5596\n",
            "Epoch 11/100\n",
            "193/193 [==============================] - 0s 303us/step - loss: 0.6579 - acc: 0.5855\n",
            "Epoch 12/100\n",
            "193/193 [==============================] - 0s 266us/step - loss: 0.6546 - acc: 0.5699\n",
            "Epoch 13/100\n",
            "193/193 [==============================] - 0s 281us/step - loss: 0.6495 - acc: 0.6373\n",
            "Epoch 14/100\n",
            "193/193 [==============================] - 0s 269us/step - loss: 0.6455 - acc: 0.6632\n",
            "Epoch 15/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.6387 - acc: 0.6995\n",
            "Epoch 16/100\n",
            "193/193 [==============================] - 0s 284us/step - loss: 0.6335 - acc: 0.7513\n",
            "Epoch 17/100\n",
            "193/193 [==============================] - 0s 270us/step - loss: 0.6275 - acc: 0.7513\n",
            "Epoch 18/100\n",
            "193/193 [==============================] - 0s 305us/step - loss: 0.6204 - acc: 0.7565\n",
            "Epoch 19/100\n",
            "193/193 [==============================] - 0s 275us/step - loss: 0.6139 - acc: 0.7513\n",
            "Epoch 20/100\n",
            "193/193 [==============================] - 0s 272us/step - loss: 0.6057 - acc: 0.7668\n",
            "Epoch 21/100\n",
            "193/193 [==============================] - 0s 263us/step - loss: 0.5988 - acc: 0.7876\n",
            "Epoch 22/100\n",
            "193/193 [==============================] - 0s 286us/step - loss: 0.5883 - acc: 0.8135\n",
            "Epoch 23/100\n",
            "193/193 [==============================] - 0s 278us/step - loss: 0.5802 - acc: 0.8031\n",
            "Epoch 24/100\n",
            "193/193 [==============================] - 0s 286us/step - loss: 0.5747 - acc: 0.7720\n",
            "Epoch 25/100\n",
            "193/193 [==============================] - 0s 309us/step - loss: 0.5632 - acc: 0.7927\n",
            "Epoch 26/100\n",
            "193/193 [==============================] - 0s 323us/step - loss: 0.5538 - acc: 0.8031\n",
            "Epoch 27/100\n",
            "193/193 [==============================] - 0s 366us/step - loss: 0.5426 - acc: 0.8135\n",
            "Epoch 28/100\n",
            "193/193 [==============================] - 0s 305us/step - loss: 0.5339 - acc: 0.8083\n",
            "Epoch 29/100\n",
            "193/193 [==============================] - 0s 299us/step - loss: 0.5239 - acc: 0.8083\n",
            "Epoch 30/100\n",
            "193/193 [==============================] - 0s 310us/step - loss: 0.5158 - acc: 0.7979\n",
            "Epoch 31/100\n",
            "193/193 [==============================] - 0s 327us/step - loss: 0.5060 - acc: 0.8187\n",
            "Epoch 32/100\n",
            "193/193 [==============================] - 0s 308us/step - loss: 0.4964 - acc: 0.8187\n",
            "Epoch 33/100\n",
            "193/193 [==============================] - 0s 414us/step - loss: 0.4870 - acc: 0.8031\n",
            "Epoch 34/100\n",
            "193/193 [==============================] - 0s 282us/step - loss: 0.4799 - acc: 0.8031\n",
            "Epoch 35/100\n",
            "193/193 [==============================] - 0s 304us/step - loss: 0.4724 - acc: 0.7876\n",
            "Epoch 36/100\n",
            "193/193 [==============================] - 0s 425us/step - loss: 0.4652 - acc: 0.8083\n",
            "Epoch 37/100\n",
            "193/193 [==============================] - 0s 299us/step - loss: 0.4564 - acc: 0.8031\n",
            "Epoch 38/100\n",
            "193/193 [==============================] - 0s 298us/step - loss: 0.4507 - acc: 0.8031\n",
            "Epoch 39/100\n",
            "193/193 [==============================] - 0s 362us/step - loss: 0.4436 - acc: 0.8031\n",
            "Epoch 40/100\n",
            "193/193 [==============================] - 0s 344us/step - loss: 0.4377 - acc: 0.8031\n",
            "Epoch 41/100\n",
            "193/193 [==============================] - 0s 302us/step - loss: 0.4322 - acc: 0.8083\n",
            "Epoch 42/100\n",
            "193/193 [==============================] - 0s 312us/step - loss: 0.4269 - acc: 0.8031\n",
            "Epoch 43/100\n",
            "193/193 [==============================] - 0s 306us/step - loss: 0.4231 - acc: 0.8031\n",
            "Epoch 44/100\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.4181 - acc: 0.8031\n",
            "Epoch 45/100\n",
            "193/193 [==============================] - 0s 330us/step - loss: 0.4141 - acc: 0.8135\n",
            "Epoch 46/100\n",
            "193/193 [==============================] - 0s 295us/step - loss: 0.4104 - acc: 0.8031\n",
            "Epoch 47/100\n",
            "193/193 [==============================] - 0s 336us/step - loss: 0.4065 - acc: 0.8135\n",
            "Epoch 48/100\n",
            "193/193 [==============================] - 0s 314us/step - loss: 0.4039 - acc: 0.8187\n",
            "Epoch 49/100\n",
            "193/193 [==============================] - 0s 276us/step - loss: 0.4002 - acc: 0.8187\n",
            "Epoch 50/100\n",
            "193/193 [==============================] - 0s 313us/step - loss: 0.3969 - acc: 0.8135\n",
            "Epoch 51/100\n",
            "193/193 [==============================] - 0s 300us/step - loss: 0.3928 - acc: 0.8187\n",
            "Epoch 52/100\n",
            "193/193 [==============================] - 0s 261us/step - loss: 0.3910 - acc: 0.8187\n",
            "Epoch 53/100\n",
            "193/193 [==============================] - 0s 291us/step - loss: 0.3905 - acc: 0.8238\n",
            "Epoch 54/100\n",
            "193/193 [==============================] - 0s 277us/step - loss: 0.3885 - acc: 0.8187\n",
            "Epoch 55/100\n",
            "193/193 [==============================] - 0s 278us/step - loss: 0.3836 - acc: 0.8290\n",
            "Epoch 56/100\n",
            "193/193 [==============================] - 0s 285us/step - loss: 0.3841 - acc: 0.8238\n",
            "Epoch 57/100\n",
            "193/193 [==============================] - 0s 315us/step - loss: 0.3790 - acc: 0.8342\n",
            "Epoch 58/100\n",
            "193/193 [==============================] - 0s 347us/step - loss: 0.3783 - acc: 0.8187\n",
            "Epoch 59/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.3768 - acc: 0.8290\n",
            "Epoch 60/100\n",
            "193/193 [==============================] - 0s 277us/step - loss: 0.3755 - acc: 0.8290\n",
            "Epoch 61/100\n",
            "193/193 [==============================] - 0s 274us/step - loss: 0.3717 - acc: 0.8342\n",
            "Epoch 62/100\n",
            "193/193 [==============================] - 0s 306us/step - loss: 0.3711 - acc: 0.8187\n",
            "Epoch 63/100\n",
            "193/193 [==============================] - 0s 275us/step - loss: 0.3719 - acc: 0.8290\n",
            "Epoch 64/100\n",
            "193/193 [==============================] - 0s 266us/step - loss: 0.3680 - acc: 0.8238\n",
            "Epoch 65/100\n",
            "193/193 [==============================] - 0s 254us/step - loss: 0.3653 - acc: 0.8290\n",
            "Epoch 66/100\n",
            "193/193 [==============================] - 0s 273us/step - loss: 0.3643 - acc: 0.8290\n",
            "Epoch 67/100\n",
            "193/193 [==============================] - 0s 307us/step - loss: 0.3625 - acc: 0.8394\n",
            "Epoch 68/100\n",
            "193/193 [==============================] - 0s 260us/step - loss: 0.3614 - acc: 0.8446\n",
            "Epoch 69/100\n",
            "193/193 [==============================] - 0s 333us/step - loss: 0.3601 - acc: 0.8446\n",
            "Epoch 70/100\n",
            "193/193 [==============================] - 0s 299us/step - loss: 0.3613 - acc: 0.8446\n",
            "Epoch 71/100\n",
            "193/193 [==============================] - 0s 301us/step - loss: 0.3617 - acc: 0.8394\n",
            "Epoch 72/100\n",
            "193/193 [==============================] - 0s 286us/step - loss: 0.3562 - acc: 0.8446\n",
            "Epoch 73/100\n",
            "193/193 [==============================] - 0s 263us/step - loss: 0.3552 - acc: 0.8497\n",
            "Epoch 74/100\n",
            "193/193 [==============================] - 0s 297us/step - loss: 0.3543 - acc: 0.8497\n",
            "Epoch 75/100\n",
            "193/193 [==============================] - 0s 273us/step - loss: 0.3542 - acc: 0.8394\n",
            "Epoch 76/100\n",
            "193/193 [==============================] - 0s 364us/step - loss: 0.3533 - acc: 0.8446\n",
            "Epoch 77/100\n",
            "193/193 [==============================] - 0s 309us/step - loss: 0.3524 - acc: 0.8394\n",
            "Epoch 78/100\n",
            "193/193 [==============================] - 0s 299us/step - loss: 0.3504 - acc: 0.8549\n",
            "Epoch 79/100\n",
            "193/193 [==============================] - 0s 323us/step - loss: 0.3496 - acc: 0.8446\n",
            "Epoch 80/100\n",
            "193/193 [==============================] - 0s 302us/step - loss: 0.3485 - acc: 0.8394\n",
            "Epoch 81/100\n",
            "193/193 [==============================] - 0s 270us/step - loss: 0.3472 - acc: 0.8394\n",
            "Epoch 82/100\n",
            "193/193 [==============================] - 0s 300us/step - loss: 0.3474 - acc: 0.8549\n",
            "Epoch 83/100\n",
            "193/193 [==============================] - 0s 263us/step - loss: 0.3478 - acc: 0.8601\n",
            "Epoch 84/100\n",
            "193/193 [==============================] - 0s 268us/step - loss: 0.3445 - acc: 0.8497\n",
            "Epoch 85/100\n",
            "193/193 [==============================] - 0s 284us/step - loss: 0.3448 - acc: 0.8653\n",
            "Epoch 86/100\n",
            "193/193 [==============================] - 0s 285us/step - loss: 0.3437 - acc: 0.8497\n",
            "Epoch 87/100\n",
            "193/193 [==============================] - 0s 257us/step - loss: 0.3432 - acc: 0.8549\n",
            "Epoch 88/100\n",
            "193/193 [==============================] - 0s 263us/step - loss: 0.3421 - acc: 0.8601\n",
            "Epoch 89/100\n",
            "193/193 [==============================] - 0s 264us/step - loss: 0.3414 - acc: 0.8549\n",
            "Epoch 90/100\n",
            "193/193 [==============================] - 0s 282us/step - loss: 0.3415 - acc: 0.8601\n",
            "Epoch 91/100\n",
            "193/193 [==============================] - 0s 306us/step - loss: 0.3421 - acc: 0.8497\n",
            "Epoch 92/100\n",
            "193/193 [==============================] - 0s 359us/step - loss: 0.3404 - acc: 0.8601\n",
            "Epoch 93/100\n",
            "193/193 [==============================] - 0s 309us/step - loss: 0.3412 - acc: 0.8394\n",
            "Epoch 94/100\n",
            "193/193 [==============================] - 0s 298us/step - loss: 0.3409 - acc: 0.8653\n",
            "Epoch 95/100\n",
            "193/193 [==============================] - 0s 253us/step - loss: 0.3380 - acc: 0.8601\n",
            "Epoch 96/100\n",
            "193/193 [==============================] - 0s 226us/step - loss: 0.3387 - acc: 0.8601\n",
            "Epoch 97/100\n",
            "193/193 [==============================] - 0s 244us/step - loss: 0.3368 - acc: 0.8549\n",
            "Epoch 98/100\n",
            "193/193 [==============================] - 0s 282us/step - loss: 0.3380 - acc: 0.8653\n",
            "Epoch 99/100\n",
            "193/193 [==============================] - 0s 265us/step - loss: 0.3358 - acc: 0.8653\n",
            "Epoch 100/100\n",
            "193/193 [==============================] - 0s 244us/step - loss: 0.3360 - acc: 0.8549\n",
            "49/49 [==============================] - 4s 83ms/step\n",
            "Epoch 1/100\n",
            "193/193 [==============================] - 9s 49ms/step - loss: 0.6904 - acc: 0.5544\n",
            "Epoch 2/100\n",
            "193/193 [==============================] - 0s 215us/step - loss: 0.6842 - acc: 0.5492\n",
            "Epoch 3/100\n",
            "193/193 [==============================] - 0s 215us/step - loss: 0.6816 - acc: 0.5492\n",
            "Epoch 4/100\n",
            "193/193 [==============================] - 0s 256us/step - loss: 0.6809 - acc: 0.5492\n",
            "Epoch 5/100\n",
            "193/193 [==============================] - 0s 225us/step - loss: 0.6780 - acc: 0.5492\n",
            "Epoch 6/100\n",
            "193/193 [==============================] - 0s 223us/step - loss: 0.6740 - acc: 0.5492\n",
            "Epoch 7/100\n",
            "193/193 [==============================] - 0s 228us/step - loss: 0.6715 - acc: 0.5492\n",
            "Epoch 8/100\n",
            "193/193 [==============================] - 0s 241us/step - loss: 0.6686 - acc: 0.5492\n",
            "Epoch 9/100\n",
            "193/193 [==============================] - 0s 231us/step - loss: 0.6654 - acc: 0.5492\n",
            "Epoch 10/100\n",
            "193/193 [==============================] - 0s 218us/step - loss: 0.6613 - acc: 0.5596\n",
            "Epoch 11/100\n",
            "193/193 [==============================] - 0s 231us/step - loss: 0.6582 - acc: 0.6269\n",
            "Epoch 12/100\n",
            "193/193 [==============================] - 0s 245us/step - loss: 0.6532 - acc: 0.5855\n",
            "Epoch 13/100\n",
            "193/193 [==============================] - 0s 232us/step - loss: 0.6508 - acc: 0.5492\n",
            "Epoch 14/100\n",
            "193/193 [==============================] - 0s 253us/step - loss: 0.6435 - acc: 0.6995\n",
            "Epoch 15/100\n",
            "193/193 [==============================] - 0s 258us/step - loss: 0.6353 - acc: 0.7876\n",
            "Epoch 16/100\n",
            "193/193 [==============================] - 0s 245us/step - loss: 0.6293 - acc: 0.7306\n",
            "Epoch 17/100\n",
            "193/193 [==============================] - 0s 232us/step - loss: 0.6211 - acc: 0.7358\n",
            "Epoch 18/100\n",
            "193/193 [==============================] - 0s 268us/step - loss: 0.6147 - acc: 0.7927\n",
            "Epoch 19/100\n",
            "193/193 [==============================] - 0s 213us/step - loss: 0.6067 - acc: 0.7979\n",
            "Epoch 20/100\n",
            "193/193 [==============================] - 0s 224us/step - loss: 0.5989 - acc: 0.7617\n",
            "Epoch 21/100\n",
            "193/193 [==============================] - 0s 232us/step - loss: 0.5884 - acc: 0.7979\n",
            "Epoch 22/100\n",
            "193/193 [==============================] - 0s 250us/step - loss: 0.5789 - acc: 0.8083\n",
            "Epoch 23/100\n",
            "193/193 [==============================] - 0s 251us/step - loss: 0.5706 - acc: 0.8031\n",
            "Epoch 24/100\n",
            "193/193 [==============================] - 0s 294us/step - loss: 0.5615 - acc: 0.8031\n",
            "Epoch 25/100\n",
            "193/193 [==============================] - 0s 248us/step - loss: 0.5501 - acc: 0.8031\n",
            "Epoch 26/100\n",
            "193/193 [==============================] - 0s 226us/step - loss: 0.5400 - acc: 0.8083\n",
            "Epoch 27/100\n",
            "193/193 [==============================] - 0s 224us/step - loss: 0.5295 - acc: 0.7876\n",
            "Epoch 28/100\n",
            "193/193 [==============================] - 0s 210us/step - loss: 0.5202 - acc: 0.8031\n",
            "Epoch 29/100\n",
            "193/193 [==============================] - 0s 257us/step - loss: 0.5109 - acc: 0.7876\n",
            "Epoch 30/100\n",
            "193/193 [==============================] - 0s 239us/step - loss: 0.5009 - acc: 0.7927\n",
            "Epoch 31/100\n",
            "193/193 [==============================] - 0s 240us/step - loss: 0.4918 - acc: 0.7876\n",
            "Epoch 32/100\n",
            "193/193 [==============================] - 0s 243us/step - loss: 0.4835 - acc: 0.7927\n",
            "Epoch 33/100\n",
            "193/193 [==============================] - 0s 295us/step - loss: 0.4746 - acc: 0.7927\n",
            "Epoch 34/100\n",
            "193/193 [==============================] - 0s 221us/step - loss: 0.4671 - acc: 0.7927\n",
            "Epoch 35/100\n",
            "193/193 [==============================] - 0s 284us/step - loss: 0.4604 - acc: 0.7927\n",
            "Epoch 36/100\n",
            "193/193 [==============================] - 0s 228us/step - loss: 0.4528 - acc: 0.7927\n",
            "Epoch 37/100\n",
            "193/193 [==============================] - 0s 248us/step - loss: 0.4491 - acc: 0.7927\n",
            "Epoch 38/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.4414 - acc: 0.7979\n",
            "Epoch 39/100\n",
            "193/193 [==============================] - 0s 224us/step - loss: 0.4366 - acc: 0.7979\n",
            "Epoch 40/100\n",
            "193/193 [==============================] - 0s 284us/step - loss: 0.4309 - acc: 0.7979\n",
            "Epoch 41/100\n",
            "193/193 [==============================] - 0s 221us/step - loss: 0.4267 - acc: 0.7979\n",
            "Epoch 42/100\n",
            "193/193 [==============================] - 0s 268us/step - loss: 0.4226 - acc: 0.7927\n",
            "Epoch 43/100\n",
            "193/193 [==============================] - 0s 263us/step - loss: 0.4193 - acc: 0.7979\n",
            "Epoch 44/100\n",
            "193/193 [==============================] - 0s 262us/step - loss: 0.4164 - acc: 0.7927\n",
            "Epoch 45/100\n",
            "193/193 [==============================] - 0s 257us/step - loss: 0.4125 - acc: 0.7979\n",
            "Epoch 46/100\n",
            "193/193 [==============================] - 0s 250us/step - loss: 0.4094 - acc: 0.7979\n",
            "Epoch 47/100\n",
            "193/193 [==============================] - 0s 275us/step - loss: 0.4074 - acc: 0.7979\n",
            "Epoch 48/100\n",
            "193/193 [==============================] - 0s 232us/step - loss: 0.4044 - acc: 0.7979\n",
            "Epoch 49/100\n",
            "193/193 [==============================] - 0s 274us/step - loss: 0.4024 - acc: 0.8135\n",
            "Epoch 50/100\n",
            "193/193 [==============================] - 0s 229us/step - loss: 0.4005 - acc: 0.8031\n",
            "Epoch 51/100\n",
            "193/193 [==============================] - 0s 255us/step - loss: 0.3984 - acc: 0.8083\n",
            "Epoch 52/100\n",
            "193/193 [==============================] - 0s 241us/step - loss: 0.3965 - acc: 0.8083\n",
            "Epoch 53/100\n",
            "193/193 [==============================] - 0s 275us/step - loss: 0.3953 - acc: 0.8031\n",
            "Epoch 54/100\n",
            "193/193 [==============================] - 0s 269us/step - loss: 0.3960 - acc: 0.8187\n",
            "Epoch 55/100\n",
            "193/193 [==============================] - 0s 312us/step - loss: 0.3944 - acc: 0.8031\n",
            "Epoch 56/100\n",
            "193/193 [==============================] - 0s 240us/step - loss: 0.3913 - acc: 0.8135\n",
            "Epoch 57/100\n",
            "193/193 [==============================] - 0s 208us/step - loss: 0.3895 - acc: 0.8187\n",
            "Epoch 58/100\n",
            "193/193 [==============================] - 0s 240us/step - loss: 0.3895 - acc: 0.8187\n",
            "Epoch 59/100\n",
            "193/193 [==============================] - 0s 281us/step - loss: 0.3880 - acc: 0.8187\n",
            "Epoch 60/100\n",
            "193/193 [==============================] - 0s 280us/step - loss: 0.3871 - acc: 0.8187\n",
            "Epoch 61/100\n",
            "193/193 [==============================] - 0s 259us/step - loss: 0.3855 - acc: 0.8187\n",
            "Epoch 62/100\n",
            "193/193 [==============================] - 0s 225us/step - loss: 0.3857 - acc: 0.8135\n",
            "Epoch 63/100\n",
            "193/193 [==============================] - 0s 314us/step - loss: 0.3842 - acc: 0.8187\n",
            "Epoch 64/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.3826 - acc: 0.8238\n",
            "Epoch 65/100\n",
            "193/193 [==============================] - 0s 224us/step - loss: 0.3823 - acc: 0.8187\n",
            "Epoch 66/100\n",
            "193/193 [==============================] - 0s 257us/step - loss: 0.3806 - acc: 0.8238\n",
            "Epoch 67/100\n",
            "193/193 [==============================] - 0s 272us/step - loss: 0.3801 - acc: 0.8238\n",
            "Epoch 68/100\n",
            "193/193 [==============================] - 0s 264us/step - loss: 0.3813 - acc: 0.8290\n",
            "Epoch 69/100\n",
            "193/193 [==============================] - 0s 247us/step - loss: 0.3788 - acc: 0.8238\n",
            "Epoch 70/100\n",
            "193/193 [==============================] - 0s 277us/step - loss: 0.3795 - acc: 0.8238\n",
            "Epoch 71/100\n",
            "193/193 [==============================] - 0s 236us/step - loss: 0.3782 - acc: 0.8238\n",
            "Epoch 72/100\n",
            "193/193 [==============================] - 0s 238us/step - loss: 0.3768 - acc: 0.8342\n",
            "Epoch 73/100\n",
            "193/193 [==============================] - 0s 247us/step - loss: 0.3779 - acc: 0.8238\n",
            "Epoch 74/100\n",
            "193/193 [==============================] - 0s 260us/step - loss: 0.3753 - acc: 0.8290\n",
            "Epoch 75/100\n",
            "193/193 [==============================] - 0s 253us/step - loss: 0.3758 - acc: 0.8342\n",
            "Epoch 76/100\n",
            "193/193 [==============================] - 0s 259us/step - loss: 0.3773 - acc: 0.8238\n",
            "Epoch 77/100\n",
            "193/193 [==============================] - 0s 256us/step - loss: 0.3745 - acc: 0.8394\n",
            "Epoch 78/100\n",
            "193/193 [==============================] - 0s 250us/step - loss: 0.3755 - acc: 0.8238\n",
            "Epoch 79/100\n",
            "193/193 [==============================] - 0s 257us/step - loss: 0.3738 - acc: 0.8238\n",
            "Epoch 80/100\n",
            "193/193 [==============================] - 0s 282us/step - loss: 0.3735 - acc: 0.8446\n",
            "Epoch 81/100\n",
            "193/193 [==============================] - 0s 251us/step - loss: 0.3734 - acc: 0.8342\n",
            "Epoch 82/100\n",
            "193/193 [==============================] - 0s 262us/step - loss: 0.3724 - acc: 0.8290\n",
            "Epoch 83/100\n",
            "193/193 [==============================] - 0s 259us/step - loss: 0.3727 - acc: 0.8394\n",
            "Epoch 84/100\n",
            "193/193 [==============================] - 0s 264us/step - loss: 0.3717 - acc: 0.8394\n",
            "Epoch 85/100\n",
            "193/193 [==============================] - 0s 278us/step - loss: 0.3727 - acc: 0.8446\n",
            "Epoch 86/100\n",
            "193/193 [==============================] - 0s 234us/step - loss: 0.3709 - acc: 0.8497\n",
            "Epoch 87/100\n",
            "193/193 [==============================] - 0s 214us/step - loss: 0.3719 - acc: 0.8446\n",
            "Epoch 88/100\n",
            "193/193 [==============================] - 0s 249us/step - loss: 0.3731 - acc: 0.8342\n",
            "Epoch 89/100\n",
            "193/193 [==============================] - 0s 285us/step - loss: 0.3712 - acc: 0.8394\n",
            "Epoch 90/100\n",
            "193/193 [==============================] - 0s 273us/step - loss: 0.3709 - acc: 0.8497\n",
            "Epoch 91/100\n",
            "193/193 [==============================] - 0s 240us/step - loss: 0.3706 - acc: 0.8342\n",
            "Epoch 92/100\n",
            "193/193 [==============================] - 0s 238us/step - loss: 0.3689 - acc: 0.8446\n",
            "Epoch 93/100\n",
            "193/193 [==============================] - 0s 260us/step - loss: 0.3711 - acc: 0.8497\n",
            "Epoch 94/100\n",
            "193/193 [==============================] - 0s 273us/step - loss: 0.3681 - acc: 0.8497\n",
            "Epoch 95/100\n",
            "193/193 [==============================] - 0s 265us/step - loss: 0.3687 - acc: 0.8446\n",
            "Epoch 96/100\n",
            "193/193 [==============================] - 0s 243us/step - loss: 0.3721 - acc: 0.8290\n",
            "Epoch 97/100\n",
            "193/193 [==============================] - 0s 254us/step - loss: 0.3677 - acc: 0.8497\n",
            "Epoch 98/100\n",
            "193/193 [==============================] - 0s 254us/step - loss: 0.3760 - acc: 0.8342\n",
            "Epoch 99/100\n",
            "193/193 [==============================] - 0s 251us/step - loss: 0.3679 - acc: 0.8342\n",
            "Epoch 100/100\n",
            "193/193 [==============================] - 0s 287us/step - loss: 0.3677 - acc: 0.8446\n",
            "49/49 [==============================] - 4s 83ms/step\n",
            "Epoch 1/100\n",
            "194/194 [==============================] - 10s 49ms/step - loss: 0.6979 - acc: 0.4536\n",
            "Epoch 2/100\n",
            "194/194 [==============================] - 0s 288us/step - loss: 0.6845 - acc: 0.5515\n",
            "Epoch 3/100\n",
            "194/194 [==============================] - 0s 236us/step - loss: 0.6818 - acc: 0.5515\n",
            "Epoch 4/100\n",
            "194/194 [==============================] - 0s 238us/step - loss: 0.6792 - acc: 0.5515\n",
            "Epoch 5/100\n",
            "194/194 [==============================] - 0s 221us/step - loss: 0.6771 - acc: 0.5515\n",
            "Epoch 6/100\n",
            "194/194 [==============================] - 0s 255us/step - loss: 0.6738 - acc: 0.5515\n",
            "Epoch 7/100\n",
            "194/194 [==============================] - 0s 244us/step - loss: 0.6709 - acc: 0.5515\n",
            "Epoch 8/100\n",
            "194/194 [==============================] - 0s 257us/step - loss: 0.6677 - acc: 0.5515\n",
            "Epoch 9/100\n",
            "194/194 [==============================] - 0s 237us/step - loss: 0.6644 - acc: 0.5515\n",
            "Epoch 10/100\n",
            "194/194 [==============================] - 0s 247us/step - loss: 0.6604 - acc: 0.5515\n",
            "Epoch 11/100\n",
            "194/194 [==============================] - 0s 237us/step - loss: 0.6558 - acc: 0.5928\n",
            "Epoch 12/100\n",
            "194/194 [==============================] - 0s 244us/step - loss: 0.6510 - acc: 0.6340\n",
            "Epoch 13/100\n",
            "194/194 [==============================] - 0s 329us/step - loss: 0.6458 - acc: 0.6443\n",
            "Epoch 14/100\n",
            "194/194 [==============================] - 0s 247us/step - loss: 0.6402 - acc: 0.6649\n",
            "Epoch 15/100\n",
            "194/194 [==============================] - 0s 316us/step - loss: 0.6359 - acc: 0.6546\n",
            "Epoch 16/100\n",
            "194/194 [==============================] - 0s 266us/step - loss: 0.6289 - acc: 0.7423\n",
            "Epoch 17/100\n",
            "194/194 [==============================] - 0s 294us/step - loss: 0.6206 - acc: 0.7629\n",
            "Epoch 18/100\n",
            "194/194 [==============================] - 0s 277us/step - loss: 0.6139 - acc: 0.7474\n",
            "Epoch 19/100\n",
            "194/194 [==============================] - 0s 244us/step - loss: 0.6059 - acc: 0.7732\n",
            "Epoch 20/100\n",
            "194/194 [==============================] - 0s 255us/step - loss: 0.5969 - acc: 0.8041\n",
            "Epoch 21/100\n",
            "194/194 [==============================] - 0s 252us/step - loss: 0.5893 - acc: 0.7938\n",
            "Epoch 22/100\n",
            "194/194 [==============================] - 0s 229us/step - loss: 0.5790 - acc: 0.7990\n",
            "Epoch 23/100\n",
            "194/194 [==============================] - 0s 242us/step - loss: 0.5713 - acc: 0.7680\n",
            "Epoch 24/100\n",
            "194/194 [==============================] - 0s 275us/step - loss: 0.5615 - acc: 0.7938\n",
            "Epoch 25/100\n",
            "194/194 [==============================] - 0s 257us/step - loss: 0.5510 - acc: 0.7990\n",
            "Epoch 26/100\n",
            "194/194 [==============================] - 0s 253us/step - loss: 0.5418 - acc: 0.8093\n",
            "Epoch 27/100\n",
            "194/194 [==============================] - 0s 252us/step - loss: 0.5320 - acc: 0.8144\n",
            "Epoch 28/100\n",
            "194/194 [==============================] - 0s 256us/step - loss: 0.5230 - acc: 0.8093\n",
            "Epoch 29/100\n",
            "194/194 [==============================] - 0s 266us/step - loss: 0.5131 - acc: 0.8144\n",
            "Epoch 30/100\n",
            "194/194 [==============================] - 0s 243us/step - loss: 0.5031 - acc: 0.8144\n",
            "Epoch 31/100\n",
            "194/194 [==============================] - 0s 296us/step - loss: 0.4934 - acc: 0.8144\n",
            "Epoch 32/100\n",
            "194/194 [==============================] - 0s 249us/step - loss: 0.4853 - acc: 0.8144\n",
            "Epoch 33/100\n",
            "194/194 [==============================] - 0s 270us/step - loss: 0.4780 - acc: 0.8196\n",
            "Epoch 34/100\n",
            "194/194 [==============================] - 0s 286us/step - loss: 0.4686 - acc: 0.8196\n",
            "Epoch 35/100\n",
            "194/194 [==============================] - 0s 281us/step - loss: 0.4608 - acc: 0.8144\n",
            "Epoch 36/100\n",
            "194/194 [==============================] - 0s 249us/step - loss: 0.4531 - acc: 0.8196\n",
            "Epoch 37/100\n",
            "194/194 [==============================] - 0s 243us/step - loss: 0.4468 - acc: 0.8196\n",
            "Epoch 38/100\n",
            "194/194 [==============================] - 0s 244us/step - loss: 0.4415 - acc: 0.8144\n",
            "Epoch 39/100\n",
            "194/194 [==============================] - 0s 246us/step - loss: 0.4336 - acc: 0.8247\n",
            "Epoch 40/100\n",
            "194/194 [==============================] - 0s 308us/step - loss: 0.4289 - acc: 0.8196\n",
            "Epoch 41/100\n",
            "194/194 [==============================] - 0s 240us/step - loss: 0.4275 - acc: 0.8093\n",
            "Epoch 42/100\n",
            "194/194 [==============================] - 0s 289us/step - loss: 0.4204 - acc: 0.8196\n",
            "Epoch 43/100\n",
            "194/194 [==============================] - 0s 241us/step - loss: 0.4144 - acc: 0.8196\n",
            "Epoch 44/100\n",
            "194/194 [==============================] - 0s 270us/step - loss: 0.4102 - acc: 0.8247\n",
            "Epoch 45/100\n",
            "194/194 [==============================] - 0s 273us/step - loss: 0.4076 - acc: 0.8247\n",
            "Epoch 46/100\n",
            "194/194 [==============================] - 0s 283us/step - loss: 0.4045 - acc: 0.8299\n",
            "Epoch 47/100\n",
            "194/194 [==============================] - 0s 254us/step - loss: 0.4006 - acc: 0.8247\n",
            "Epoch 48/100\n",
            "194/194 [==============================] - 0s 238us/step - loss: 0.3972 - acc: 0.8247\n",
            "Epoch 49/100\n",
            "194/194 [==============================] - 0s 263us/step - loss: 0.3950 - acc: 0.8247\n",
            "Epoch 50/100\n",
            "194/194 [==============================] - 0s 378us/step - loss: 0.3923 - acc: 0.8247\n",
            "Epoch 51/100\n",
            "194/194 [==============================] - 0s 259us/step - loss: 0.3912 - acc: 0.8299\n",
            "Epoch 52/100\n",
            "194/194 [==============================] - 0s 268us/step - loss: 0.3870 - acc: 0.8247\n",
            "Epoch 53/100\n",
            "194/194 [==============================] - 0s 262us/step - loss: 0.3869 - acc: 0.8299\n",
            "Epoch 54/100\n",
            "194/194 [==============================] - 0s 255us/step - loss: 0.3842 - acc: 0.8299\n",
            "Epoch 55/100\n",
            "194/194 [==============================] - 0s 239us/step - loss: 0.3835 - acc: 0.8299\n",
            "Epoch 56/100\n",
            "194/194 [==============================] - 0s 257us/step - loss: 0.3803 - acc: 0.8247\n",
            "Epoch 57/100\n",
            "194/194 [==============================] - 0s 287us/step - loss: 0.3800 - acc: 0.8299\n",
            "Epoch 58/100\n",
            "194/194 [==============================] - 0s 295us/step - loss: 0.3772 - acc: 0.8299\n",
            "Epoch 59/100\n",
            "194/194 [==============================] - 0s 248us/step - loss: 0.3803 - acc: 0.8299\n",
            "Epoch 60/100\n",
            "194/194 [==============================] - 0s 264us/step - loss: 0.3772 - acc: 0.8299\n",
            "Epoch 61/100\n",
            "194/194 [==============================] - 0s 257us/step - loss: 0.3757 - acc: 0.8299\n",
            "Epoch 62/100\n",
            "194/194 [==============================] - 0s 260us/step - loss: 0.3746 - acc: 0.8299\n",
            "Epoch 63/100\n",
            "194/194 [==============================] - 0s 255us/step - loss: 0.3743 - acc: 0.8299\n",
            "Epoch 64/100\n",
            "194/194 [==============================] - 0s 264us/step - loss: 0.3709 - acc: 0.8299\n",
            "Epoch 65/100\n",
            "194/194 [==============================] - 0s 259us/step - loss: 0.3703 - acc: 0.8299\n",
            "Epoch 66/100\n",
            "194/194 [==============================] - 0s 239us/step - loss: 0.3696 - acc: 0.8299\n",
            "Epoch 67/100\n",
            "194/194 [==============================] - 0s 256us/step - loss: 0.3680 - acc: 0.8351\n",
            "Epoch 68/100\n",
            "194/194 [==============================] - 0s 282us/step - loss: 0.3672 - acc: 0.8351\n",
            "Epoch 69/100\n",
            "194/194 [==============================] - 0s 261us/step - loss: 0.3684 - acc: 0.8299\n",
            "Epoch 70/100\n",
            "194/194 [==============================] - 0s 259us/step - loss: 0.3662 - acc: 0.8351\n",
            "Epoch 71/100\n",
            "194/194 [==============================] - 0s 284us/step - loss: 0.3663 - acc: 0.8351\n",
            "Epoch 72/100\n",
            "194/194 [==============================] - 0s 300us/step - loss: 0.3645 - acc: 0.8351\n",
            "Epoch 73/100\n",
            "194/194 [==============================] - 0s 262us/step - loss: 0.3641 - acc: 0.8351\n",
            "Epoch 74/100\n",
            "194/194 [==============================] - 0s 270us/step - loss: 0.3640 - acc: 0.8402\n",
            "Epoch 75/100\n",
            "194/194 [==============================] - 0s 250us/step - loss: 0.3627 - acc: 0.8402\n",
            "Epoch 76/100\n",
            "194/194 [==============================] - 0s 285us/step - loss: 0.3626 - acc: 0.8351\n",
            "Epoch 77/100\n",
            "194/194 [==============================] - 0s 296us/step - loss: 0.3659 - acc: 0.8299\n",
            "Epoch 78/100\n",
            "194/194 [==============================] - 0s 293us/step - loss: 0.3606 - acc: 0.8351\n",
            "Epoch 79/100\n",
            "194/194 [==============================] - 0s 282us/step - loss: 0.3606 - acc: 0.8454\n",
            "Epoch 80/100\n",
            "194/194 [==============================] - 0s 271us/step - loss: 0.3628 - acc: 0.8402\n",
            "Epoch 81/100\n",
            "194/194 [==============================] - 0s 236us/step - loss: 0.3601 - acc: 0.8402\n",
            "Epoch 82/100\n",
            "194/194 [==============================] - 0s 327us/step - loss: 0.3607 - acc: 0.8454\n",
            "Epoch 83/100\n",
            "194/194 [==============================] - 0s 253us/step - loss: 0.3594 - acc: 0.8454\n",
            "Epoch 84/100\n",
            "194/194 [==============================] - 0s 264us/step - loss: 0.3594 - acc: 0.8402\n",
            "Epoch 85/100\n",
            "194/194 [==============================] - 0s 261us/step - loss: 0.3586 - acc: 0.8299\n",
            "Epoch 86/100\n",
            "194/194 [==============================] - 0s 269us/step - loss: 0.3581 - acc: 0.8351\n",
            "Epoch 87/100\n",
            "194/194 [==============================] - 0s 239us/step - loss: 0.3576 - acc: 0.8402\n",
            "Epoch 88/100\n",
            "194/194 [==============================] - 0s 263us/step - loss: 0.3587 - acc: 0.8402\n",
            "Epoch 89/100\n",
            "194/194 [==============================] - 0s 230us/step - loss: 0.3589 - acc: 0.8505\n",
            "Epoch 90/100\n",
            "194/194 [==============================] - 0s 305us/step - loss: 0.3587 - acc: 0.8402\n",
            "Epoch 91/100\n",
            "194/194 [==============================] - 0s 270us/step - loss: 0.3564 - acc: 0.8351\n",
            "Epoch 92/100\n",
            "194/194 [==============================] - 0s 240us/step - loss: 0.3587 - acc: 0.8351\n",
            "Epoch 93/100\n",
            "194/194 [==============================] - 0s 263us/step - loss: 0.3563 - acc: 0.8402\n",
            "Epoch 94/100\n",
            "194/194 [==============================] - 0s 244us/step - loss: 0.3566 - acc: 0.8454\n",
            "Epoch 95/100\n",
            "194/194 [==============================] - 0s 237us/step - loss: 0.3567 - acc: 0.8351\n",
            "Epoch 96/100\n",
            "194/194 [==============================] - 0s 261us/step - loss: 0.3553 - acc: 0.8299\n",
            "Epoch 97/100\n",
            "194/194 [==============================] - 0s 234us/step - loss: 0.3550 - acc: 0.8351\n",
            "Epoch 98/100\n",
            "194/194 [==============================] - 0s 274us/step - loss: 0.3577 - acc: 0.8454\n",
            "Epoch 99/100\n",
            "194/194 [==============================] - 0s 243us/step - loss: 0.3545 - acc: 0.8299\n",
            "Epoch 100/100\n",
            "194/194 [==============================] - 0s 257us/step - loss: 0.3549 - acc: 0.8299\n",
            "48/48 [==============================] - 4s 86ms/step\n",
            "Epoch 1/100\n",
            "195/195 [==============================] - 10s 50ms/step - loss: 0.7223 - acc: 0.4513\n",
            "Epoch 2/100\n",
            "195/195 [==============================] - 0s 242us/step - loss: 0.6872 - acc: 0.5436\n",
            "Epoch 3/100\n",
            "195/195 [==============================] - 0s 266us/step - loss: 0.6866 - acc: 0.5487\n",
            "Epoch 4/100\n",
            "195/195 [==============================] - 0s 265us/step - loss: 0.6875 - acc: 0.5487\n",
            "Epoch 5/100\n",
            "195/195 [==============================] - 0s 268us/step - loss: 0.6824 - acc: 0.5487\n",
            "Epoch 6/100\n",
            "195/195 [==============================] - 0s 271us/step - loss: 0.6802 - acc: 0.5487\n",
            "Epoch 7/100\n",
            "195/195 [==============================] - 0s 267us/step - loss: 0.6774 - acc: 0.5487\n",
            "Epoch 8/100\n",
            "195/195 [==============================] - 0s 266us/step - loss: 0.6754 - acc: 0.5487\n",
            "Epoch 9/100\n",
            "195/195 [==============================] - 0s 288us/step - loss: 0.6735 - acc: 0.5487\n",
            "Epoch 10/100\n",
            "195/195 [==============================] - 0s 246us/step - loss: 0.6695 - acc: 0.5487\n",
            "Epoch 11/100\n",
            "195/195 [==============================] - 0s 262us/step - loss: 0.6666 - acc: 0.5487\n",
            "Epoch 12/100\n",
            "195/195 [==============================] - 0s 295us/step - loss: 0.6630 - acc: 0.5487\n",
            "Epoch 13/100\n",
            "195/195 [==============================] - 0s 277us/step - loss: 0.6593 - acc: 0.5538\n",
            "Epoch 14/100\n",
            "195/195 [==============================] - 0s 290us/step - loss: 0.6552 - acc: 0.5949\n",
            "Epoch 15/100\n",
            "195/195 [==============================] - 0s 292us/step - loss: 0.6502 - acc: 0.6256\n",
            "Epoch 16/100\n",
            "195/195 [==============================] - 0s 278us/step - loss: 0.6457 - acc: 0.6154\n",
            "Epoch 17/100\n",
            "195/195 [==============================] - 0s 283us/step - loss: 0.6402 - acc: 0.6718\n",
            "Epoch 18/100\n",
            "195/195 [==============================] - 0s 296us/step - loss: 0.6340 - acc: 0.7282\n",
            "Epoch 19/100\n",
            "195/195 [==============================] - 0s 305us/step - loss: 0.6281 - acc: 0.7026\n",
            "Epoch 20/100\n",
            "195/195 [==============================] - 0s 291us/step - loss: 0.6199 - acc: 0.7128\n",
            "Epoch 21/100\n",
            "195/195 [==============================] - 0s 260us/step - loss: 0.6146 - acc: 0.7897\n",
            "Epoch 22/100\n",
            "195/195 [==============================] - 0s 277us/step - loss: 0.6054 - acc: 0.7744\n",
            "Epoch 23/100\n",
            "195/195 [==============================] - 0s 288us/step - loss: 0.5983 - acc: 0.7692\n",
            "Epoch 24/100\n",
            "195/195 [==============================] - 0s 291us/step - loss: 0.5889 - acc: 0.7641\n",
            "Epoch 25/100\n",
            "195/195 [==============================] - 0s 368us/step - loss: 0.5803 - acc: 0.7897\n",
            "Epoch 26/100\n",
            "195/195 [==============================] - 0s 314us/step - loss: 0.5708 - acc: 0.7846\n",
            "Epoch 27/100\n",
            "195/195 [==============================] - 0s 318us/step - loss: 0.5615 - acc: 0.8000\n",
            "Epoch 28/100\n",
            "195/195 [==============================] - 0s 319us/step - loss: 0.5503 - acc: 0.8000\n",
            "Epoch 29/100\n",
            "195/195 [==============================] - 0s 387us/step - loss: 0.5425 - acc: 0.7949\n",
            "Epoch 30/100\n",
            "195/195 [==============================] - 0s 396us/step - loss: 0.5310 - acc: 0.7949\n",
            "Epoch 31/100\n",
            "195/195 [==============================] - 0s 400us/step - loss: 0.5218 - acc: 0.8051\n",
            "Epoch 32/100\n",
            "195/195 [==============================] - 0s 334us/step - loss: 0.5124 - acc: 0.8000\n",
            "Epoch 33/100\n",
            "195/195 [==============================] - 0s 312us/step - loss: 0.5031 - acc: 0.8000\n",
            "Epoch 34/100\n",
            "195/195 [==============================] - 0s 366us/step - loss: 0.4943 - acc: 0.8051\n",
            "Epoch 35/100\n",
            "195/195 [==============================] - 0s 373us/step - loss: 0.4874 - acc: 0.7897\n",
            "Epoch 36/100\n",
            "195/195 [==============================] - 0s 289us/step - loss: 0.4772 - acc: 0.7949\n",
            "Epoch 37/100\n",
            "195/195 [==============================] - 0s 297us/step - loss: 0.4696 - acc: 0.7897\n",
            "Epoch 38/100\n",
            "195/195 [==============================] - 0s 366us/step - loss: 0.4612 - acc: 0.7949\n",
            "Epoch 39/100\n",
            "195/195 [==============================] - 0s 358us/step - loss: 0.4547 - acc: 0.8000\n",
            "Epoch 40/100\n",
            "195/195 [==============================] - 0s 305us/step - loss: 0.4487 - acc: 0.8000\n",
            "Epoch 41/100\n",
            "195/195 [==============================] - 0s 321us/step - loss: 0.4421 - acc: 0.8000\n",
            "Epoch 42/100\n",
            "195/195 [==============================] - 0s 366us/step - loss: 0.4371 - acc: 0.7795\n",
            "Epoch 43/100\n",
            "195/195 [==============================] - 0s 337us/step - loss: 0.4351 - acc: 0.8000\n",
            "Epoch 44/100\n",
            "195/195 [==============================] - 0s 304us/step - loss: 0.4300 - acc: 0.8000\n",
            "Epoch 45/100\n",
            "195/195 [==============================] - 0s 363us/step - loss: 0.4219 - acc: 0.8000\n",
            "Epoch 46/100\n",
            "195/195 [==============================] - 0s 356us/step - loss: 0.4178 - acc: 0.7897\n",
            "Epoch 47/100\n",
            "195/195 [==============================] - 0s 315us/step - loss: 0.4139 - acc: 0.7846\n",
            "Epoch 48/100\n",
            "195/195 [==============================] - 0s 424us/step - loss: 0.4107 - acc: 0.7846\n",
            "Epoch 49/100\n",
            "195/195 [==============================] - 0s 390us/step - loss: 0.4079 - acc: 0.7949\n",
            "Epoch 50/100\n",
            "195/195 [==============================] - 0s 322us/step - loss: 0.4038 - acc: 0.7897\n",
            "Epoch 51/100\n",
            "195/195 [==============================] - 0s 322us/step - loss: 0.4020 - acc: 0.8000\n",
            "Epoch 52/100\n",
            "195/195 [==============================] - 0s 352us/step - loss: 0.3997 - acc: 0.7949\n",
            "Epoch 53/100\n",
            "195/195 [==============================] - 0s 326us/step - loss: 0.3961 - acc: 0.8051\n",
            "Epoch 54/100\n",
            "195/195 [==============================] - 0s 300us/step - loss: 0.3957 - acc: 0.8103\n",
            "Epoch 55/100\n",
            "195/195 [==============================] - 0s 372us/step - loss: 0.3936 - acc: 0.8051\n",
            "Epoch 56/100\n",
            "195/195 [==============================] - 0s 307us/step - loss: 0.3893 - acc: 0.8000\n",
            "Epoch 57/100\n",
            "195/195 [==============================] - 0s 383us/step - loss: 0.3878 - acc: 0.8103\n",
            "Epoch 58/100\n",
            "195/195 [==============================] - 0s 397us/step - loss: 0.3869 - acc: 0.8103\n",
            "Epoch 59/100\n",
            "195/195 [==============================] - 0s 353us/step - loss: 0.3846 - acc: 0.8154\n",
            "Epoch 60/100\n",
            "195/195 [==============================] - 0s 361us/step - loss: 0.3825 - acc: 0.8103\n",
            "Epoch 61/100\n",
            "195/195 [==============================] - 0s 374us/step - loss: 0.3822 - acc: 0.8000\n",
            "Epoch 62/100\n",
            "195/195 [==============================] - 0s 400us/step - loss: 0.3829 - acc: 0.8051\n",
            "Epoch 63/100\n",
            "195/195 [==============================] - 0s 372us/step - loss: 0.3803 - acc: 0.8051\n",
            "Epoch 64/100\n",
            "195/195 [==============================] - 0s 369us/step - loss: 0.3782 - acc: 0.8205\n",
            "Epoch 65/100\n",
            "195/195 [==============================] - 0s 295us/step - loss: 0.3776 - acc: 0.8154\n",
            "Epoch 66/100\n",
            "195/195 [==============================] - 0s 295us/step - loss: 0.3764 - acc: 0.8154\n",
            "Epoch 67/100\n",
            "195/195 [==============================] - 0s 321us/step - loss: 0.3737 - acc: 0.8154\n",
            "Epoch 68/100\n",
            "195/195 [==============================] - 0s 373us/step - loss: 0.3726 - acc: 0.8154\n",
            "Epoch 69/100\n",
            "195/195 [==============================] - 0s 326us/step - loss: 0.3720 - acc: 0.8205\n",
            "Epoch 70/100\n",
            "195/195 [==============================] - 0s 320us/step - loss: 0.3711 - acc: 0.8256\n",
            "Epoch 71/100\n",
            "195/195 [==============================] - 0s 336us/step - loss: 0.3705 - acc: 0.8154\n",
            "Epoch 72/100\n",
            "195/195 [==============================] - 0s 284us/step - loss: 0.3705 - acc: 0.8256\n",
            "Epoch 73/100\n",
            "195/195 [==============================] - 0s 296us/step - loss: 0.3682 - acc: 0.8308\n",
            "Epoch 74/100\n",
            "195/195 [==============================] - 0s 340us/step - loss: 0.3699 - acc: 0.8154\n",
            "Epoch 75/100\n",
            "195/195 [==============================] - 0s 330us/step - loss: 0.3664 - acc: 0.8154\n",
            "Epoch 76/100\n",
            "195/195 [==============================] - 0s 295us/step - loss: 0.3669 - acc: 0.8154\n",
            "Epoch 77/100\n",
            "195/195 [==============================] - 0s 427us/step - loss: 0.3685 - acc: 0.8410\n",
            "Epoch 78/100\n",
            "195/195 [==============================] - 0s 302us/step - loss: 0.3671 - acc: 0.8359\n",
            "Epoch 79/100\n",
            "195/195 [==============================] - 0s 289us/step - loss: 0.3655 - acc: 0.8256\n",
            "Epoch 80/100\n",
            "195/195 [==============================] - 0s 330us/step - loss: 0.3623 - acc: 0.8256\n",
            "Epoch 81/100\n",
            "195/195 [==============================] - 0s 317us/step - loss: 0.3619 - acc: 0.8410\n",
            "Epoch 82/100\n",
            "195/195 [==============================] - 0s 376us/step - loss: 0.3620 - acc: 0.8462\n",
            "Epoch 83/100\n",
            "195/195 [==============================] - 0s 397us/step - loss: 0.3618 - acc: 0.8359\n",
            "Epoch 84/100\n",
            "195/195 [==============================] - 0s 376us/step - loss: 0.3608 - acc: 0.8410\n",
            "Epoch 85/100\n",
            "195/195 [==============================] - 0s 354us/step - loss: 0.3606 - acc: 0.8410\n",
            "Epoch 86/100\n",
            "195/195 [==============================] - 0s 333us/step - loss: 0.3613 - acc: 0.8410\n",
            "Epoch 87/100\n",
            "195/195 [==============================] - 0s 318us/step - loss: 0.3594 - acc: 0.8462\n",
            "Epoch 88/100\n",
            "195/195 [==============================] - 0s 290us/step - loss: 0.3605 - acc: 0.8410\n",
            "Epoch 89/100\n",
            "195/195 [==============================] - 0s 320us/step - loss: 0.3581 - acc: 0.8462\n",
            "Epoch 90/100\n",
            "195/195 [==============================] - 0s 374us/step - loss: 0.3575 - acc: 0.8462\n",
            "Epoch 91/100\n",
            "195/195 [==============================] - 0s 362us/step - loss: 0.3578 - acc: 0.8462\n",
            "Epoch 92/100\n",
            "195/195 [==============================] - 0s 357us/step - loss: 0.3574 - acc: 0.8513\n",
            "Epoch 93/100\n",
            "195/195 [==============================] - 0s 320us/step - loss: 0.3587 - acc: 0.8513\n",
            "Epoch 94/100\n",
            "195/195 [==============================] - 0s 379us/step - loss: 0.3558 - acc: 0.8513\n",
            "Epoch 95/100\n",
            "195/195 [==============================] - 0s 365us/step - loss: 0.3558 - acc: 0.8615\n",
            "Epoch 96/100\n",
            "195/195 [==============================] - 0s 305us/step - loss: 0.3556 - acc: 0.8513\n",
            "Epoch 97/100\n",
            "195/195 [==============================] - 0s 292us/step - loss: 0.3551 - acc: 0.8462\n",
            "Epoch 98/100\n",
            "195/195 [==============================] - 0s 355us/step - loss: 0.3550 - acc: 0.8615\n",
            "Epoch 99/100\n",
            "195/195 [==============================] - 0s 294us/step - loss: 0.3542 - acc: 0.8564\n",
            "Epoch 100/100\n",
            "195/195 [==============================] - 0s 304us/step - loss: 0.3545 - acc: 0.8513\n",
            "47/47 [==============================] - 4s 89ms/step\n",
            "Before GridSearchCV results were: 56.86% (11.32%) \n",
            "With GridSearchCV finding new results: 83.46% (3.47%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VD7-oJERsl0u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}